[{"title":"【GitHub Actions】GitHubのプロフィールを自動更新する仕組みを作った","date":"","description":"技術的な説明はなく、ただの独り言です","body":"おもしろいツイートを見つけた GitHub ActionsでQiita/Zennの投稿をGitHubプロフィールに自動反映できるようにした pic.twitter.com/o47E7YHSsx\n\u0026mdash; mikkame (@mikkameee) February 14, 2021  とても便利そうだったので僕もやってみました。\n作った ↑こんな感じで Recent posts - Blog 📝 に直近5個の記事を表示するようにして、\nなおかつ自動更新されるようにしました。\nコードはこちら に置いてあります。\nやっていることはとてもシンプルで、\nGoで書いたREADME更新スクリプトをGitHub Actionsで実行しているだけです。\n興味あったらコードを覗いてみてください。\n","ref":"/tech-blog/blog/profile-readme-updater/"},{"title":"The Go Programming Language Specificationで知った「こんなことできるだ」を紹介","date":"","description":"Go 5 Advent Calendar 2020 8日目","body":"本記事は『Go 5 Advent Calendar 2020 8日目 』の記事です。\nGo Language Specification輪読会 現在、Go Language Specification輪読会 という、 Goの言語仕様 を読んでいく会に参加しています。\n今回は、そんな輪読会で「こんなことできるんだ」と驚いたコードを紹介します。\n（振り返ると結構たくさんあったので、今回はその中から5個選んで紹介します）\nちなみに、だいたいのコードは現場で使うと怒られそうです😇 （いや、まず間違いなく怒られる）\n1. Comments package main import ( \u0026quot;fmt\u0026quot; ) func main() { var/*comment*/a = 1 fmt.Println(a) }  https://play.golang.org/p/9Dun0LiT5N5\nまずはこちら。\n変な位置にコメントが挿入されています。\nコメント部分を消すとvara = 1となるのでエラーになりそうです。\nしかし、実行してみると、すんなりと変数aを表示してくれます。\n解説 Spec を参照すると以下の一文があります。\n A general comment containing no newlines acts like a space.\n改行を含まないgeneral commentはスペースのように作用する。\n （general commentとは/**/で囲われたコメントのことを指します）\nよって、先程のコードは以下と同じということです。\npackage main import ( \u0026quot;fmt\u0026quot; ) func main() { var a = 1 fmt.Println(a) }  こうして変換してみると、エラーでないことは明白ですね。\nちなみに、「改行を含まない」ことが条件なので、以下のコードはエラーとなります。\npackage main import ( \u0026quot;fmt\u0026quot; ) func main() { var a/*comment*/= 1 // こっちはOKだけど var b/*com ment*/= 1 // こっちはNG fmt.Println(a) fmt.Println(b) }  https://play.golang.org/p/_IFGaJ4VK4w\n2. Identifiers 続いてはこちらです。\npackage main import \u0026quot;fmt\u0026quot; func main() { false := true if false { fmt.Println(\u0026quot;false is true\u0026quot;) } }  https://play.golang.org/p/kzf4fwRxyAJ\nこれはGoクイズでもよく出てくるので、ご存じの方も多いかと思います。\n解説 ここで重要になってくる単語として以下の2つがあります。\n Identifier Keyword  Identifierについて、Spec を参照すると、\n Identifiers name program entities such as variables and types.\n識別子は、変数や型などのプログラムエンティティの名前を付けます。\n とあります。\nIdentifierは、ただ単に名前を付けるためのものなんですね。\n加えて、以下の一文から、事前に宣言されているIdentifierがあると分かります。\n Some identifiers are predeclared.\nいくつかの識別子は事前に宣言されています。\n 今回取り上げたfalseはこの事前宣言されたIdentifierに該当します。\n（事前宣言されているIdentifier一覧はこちら ）\n次に、Keywordについて見ていきます。\nSpec を参照すると、\n The following keywords are reserved and may not be used as identifiers.\n以下のキーワードは予約されており、識別子として使用することはできません。\n とあります。\nよって、下記のとおりdefaultをIdentifierとして使用できません。\n（defaultはKeywordです）\npackage main import \u0026quot;fmt\u0026quot; func main() { default := true fmt.Println(default) }  https://play.golang.org/p/Cxuolg_b7Xx\nfalseの話に戻しますが、falseはIdentifierであり、Keywordではありません。\nしたがって、最初に示したコードのとおり、別の対象に対してfalseと名付けることが可能です。\n3. Slice types 次はSlice関連です。\npackage main import \u0026quot;fmt\u0026quot; func main() { a := [5]int{0, 1, 2, 3, 4} b := a[1:3] fmt.Println(b) fmt.Println(b[0:4]) }  https://play.golang.org/p/inbRV8SWfNO\n一度実行してみてください。\nfmt.Println(b[0:4])の出力結果に違和感がないでしょうか。\nb＝a[1:3]＝{1, 2}のはずです。\n実際、fmt.Println(b)の出力結果はそうなっています。\nよって、b[0:4]は取れないはずです。\nしかし、実行してみるとb[0:4]が取れています。\n解説 Spec を見ると、\n A slice is a descriptor for a contiguous segment of an underlying array and provides access to a numbered sequence of elements from that array.\nスライスは、underlying arrayの連続したセグメントの記述子であり、そのunderlying arrayの要素の番号付きシーケンスへのアクセスを提供します。\n とあります。\nつまり、Sliceの後ろにはArrayがいて、SliceはそのArrayに対してよしなにアクセスすることで、\nあたかもSliceであるかのように見せています。\nよって、\nb := a[1:3]  こうしたときにbの後ろには[5]int{0, 1, 2, 3, 4}がいることになります。\n実際にアクセスできるのは{1, 2, 3, 4}だけなので、\n厳密には背後に{1, 2, 3, 4}という要素を持った配列がいるように思えるでしょう。\nここまでくると、最初のコードでb[0:4]の範囲にアクセスできたのも納得ですね。\n4. Method declarations 続いてはこちらです。\npackage main type S int func(S) _() {} func(S) _() {} func _() {} func _() {} func main() {}  https://play.golang.org/p/sHq9NZvlPsL\n同じ関数名が乱立しています。\nもうなんとなく察してる方もおられると思いますが、\nこれはブランク（_）が使用されているために成り立っています。\n解説 Spec に以下の一文があります。\n For a base type, the non-blank names of methods bound to it must be unique.\nBase typeにバインドされているブランクではないメソッド名は一意である必要があります。\n 言い換えると、関数名がブランクである場合は、ユニークでなくても良いということになります。\n5. Composite literals 最後はこちらです。\npackage main import \u0026quot;fmt\u0026quot; var arr = [3]int{2: 2} var slice = []int{3: 3} func main() { fmt.Println(arr) fmt.Println(slice) }  https://play.golang.org/p/7vfUjbDEeCZ\n5, 6行目の中括弧の中を見ると、一瞬、mapかなと思った人がいるかもしれません。\nしかし、これはArrayとSliceの初期化です。\n解説 ArrayとSliceでもキー（インデックス）指定で初期化できます。\nSpec には、 ArrayとSliceに対して以下の一文が記載されています。\n An element with a key uses the key as its index. The key must be a non-negative constant representable by a value of type int; and if it is typed it must be of integer type.\nキーを持つ要素は、そのキーをインデックスとして使用します。キーは int 型の値で表すことができる非負の定数でなければならず、型付けされている場合は整数型でなければなりません。\n まぁ、あまり見ることはないコードでしょう🙈\nまとめ Goの言語仕様をちゃんと勉強し始めたことで、\nこういう仕様だから、こうやって処理されていたのかというのが理解できてきました。\n個人的には、ここを理解してくると、\nなぜCompilerやLinterが怒っていたのかが分かるようになってきて、\n言語仕様を読むのがさらにおもしろくなりました。\n今回の内容は、個人的に「おおお、、、」っとなったものを中心に取り上げたのですが、\n実務では使えないであろうコードばかりになってしまいました😇\nしかし、実際に役に立つ発見も多くあるので、ぜひ一緒に言語仕様を読み進められればなと思っています！\n▶▶▶ Go Language Specification輪読会 明日は、、、 Go 5 Advent Calendar 2020 の明日の枠はまだ空いていますね〜🎅\n","ref":"/tech-blog/blog/uncredible-codes-from-go-spec/"},{"title":"ブログの画像をWebPに変えた話とSafariで表示されない件について","date":"","description":"Safariはv14からじゃないと表示できない😇","body":"画像の形式をWebPに変えた 本ブログにて、Lighthouse使ってみると、表示速度あたりで怒られていたので、\nまずはサムネ画像をWebPに変えてみました。\nWebPとは、Googleが開発しているオープンな静止画像フォーマットで、\nトラフィック量軽減と表示速度短縮を目的しています。 （wikiから拝借 ）\nWebPを採用した結果 以下のツイートのとおりです。\nたまたま100が撮れただけで、もう一回テストしみると少し落ちました。\nそれでも90台はキープできていそうです。\n個人ブログ（Desktop版）のPerformanceが78だったので、画像をwebpに変えたら一気に100になった🎊\n（モバイルは未だに70切ってる😇） pic.twitter.com/VNxztIsR28\n\u0026mdash; hon-D (@yyh_gl) November 19, 2020  Safariでは注意が必要 多くのブラウザでWebPへの対応が既に完了しています。\nただし、Safariに関してはv14でようやく対応しました。\n対応状況 Safari v14は2020年9月17日（日本時間）にリリースされたばかりなので、\nまだ画像をちゃんと見れないユーザが多く存在すると思われます。\nリリースノート Safariのwebp対応ってバージョン14からだったんだ😇\n自分のブログに来る人の90%弱がSafariじゃないから、まぁいいか←\n\u0026mdash; hon-D (@yyh_gl) November 26, 2020   自分のブログに来る人の90%弱がSafariじゃないから、まぁいいか←\n 嘘です、10%ほどの方々すみません🙇‍♂ WebPにしたのはサムネ画像だけで、記事本文内の画像はWebPじゃないので許してください。。。\n","ref":"/tech-blog/blog/support-webp/"},{"title":"【Go】Switch文のfallthroughに関するまとめ","date":"","description":"忘れがちじゃないですか？？","body":"fallthrough とは GoではSwitch文でfallthroughというキーワード が使用可能です。\n機能としては、Switch文における次の節（caseやdefault）に移動するというものです。（参考 ）\n言葉で説明するよりも、サンプルコードを見てもらった方がイメージがつきやすいと思います。\npackage main import \u0026quot;fmt\u0026quot; func main() { num := 1 switch num { case 1: fmt.Print(\u0026quot;I \u0026quot;) fallthrough case 2: fmt.Print(\u0026quot;am \u0026quot;) fallthrough case 3: fmt.Println(\u0026quot;yyh-gl.\u0026quot;) // fallthrough // 次の節がなければコンパイルエラー } } // 実行結果： // I am yyh-gl.  Playground defaultにも飛べるという例 fallthroughは、Go言語のORMライブラリとして有名な『GORM』でも使用されています。(使用箇所 ))\n","ref":"/tech-blog/blog/go-switch-fallthrough/"},{"title":"texta.fm #1 まとめ","date":"","description":"2020年8月27日放送分のまとめです","body":"texta.fm texta.fm #1（2020年8月27日放送分） を聞いて、特にDDDについて学びが多かったのでまとめました。\nエヴァンス本を読む前に知っておいた方がいい時代背景、そして、意識すべき点を知ることができるので、\n時間があればぜひ実際に聞きに行ってみてください。\n話者：\n @_yasaichi さん @t_wada さん  以降、勉強になった点を抜き出していきます。\nなお、\u0026lt;\u0026gt;内に記載している時間は、記述内容が実際に話されている時間を示しています。\nDDDが解決したかった問題 \u0026lt;6分30秒ぐらいから\u0026gt;\nエリック・エヴァンスがDDDで解決しようとしていた問題は以下の2点\n 分析モデルとコード間の乖離：詳細は後述 ビジネス側と開発側の乖離：ビジネス側の言葉と開発側の言葉が異なることによる開発の複雑化  分析モデルとコード間の乖離ってなに？ \u0026lt;9分45秒ぐらいから\u0026gt;\n2000年代前半はフェーズで区切ったソフトウェア開発が主流だった。\nそして、その区切られたフェーズのひとつである「モデリングフェーズ」では、\n分析や設計を通してモデルを作り上げていくのであるが、\n開発の対象領域をきちんと写し取った抽象的なモデル（分析モデル）を作ることが最大の目的であった。\nしかし、開発フェーズに入った時、分析モデルでは不完全なことが多かった。\nよって、開発で使えるように修正が加えられ、最終的には分析モデルとは全く異なるモデルができあがる。\nコードを書かないと分からないこと、実際にシステムが使われ始めないと分からないことがたくさんあるので、当然の結果である。\n解決策：改善のループを回そう \u0026lt;17分20秒ぐらいから\u0026gt;\n分析モデルとコード間の乖離を解決するために、\n分析モデル→開発時のモデルの一方通行ではなく、\n開発時のモデル↔分析モデルのように両方向にフィードバックする。\nそして、フィードバックをもとに改善のループを回していくことが重要。\n（＝アジャイルソフトウェア開発時代の改善ループの回し方）\n今はあまり分析モデルとコード間の乖離が問題にならない \u0026lt;25分00秒ぐらいから\u0026gt;\n現在ではあまり分析モデルとコード間の乖離が問題にならない。\n理由としては、分析モデルの作成フェーズ（モデリングフェーズ）と開発フェーズを担当する人が同じになってきたから。\n昨今の開発ではこうした開発体制が普通になっているので、\nそもそも今いる大半のエンジニアにはイメージがつきにくい事象である。\nしたがって、現在は、DDDと言われるとビジネス側と開発側の乖離に注目が行きがち。\nエヴァンス本から学ぶべき大事なこと \u0026lt;21分40秒ぐらいから\u0026gt;\nコードとドメイン知識間の乖離を無くし、\n一致させ続ける反復的作業こそが大事であると訴えたことがとても良かった。\nつまり、先述したとおり、\nフィードバックが 分析モデル→開発時のモデルの一方通行 だったものを 開発時のモデル↔分析モデルのような両方向 にしようと提唱したことこそが最重要。\nここを意識して学ぼう！\n\u0026lt;33分00秒ぐらいから\u0026gt;\nデザインパターンの部分（2部、3部あたり）はもちろん大事であるが、\nエヴァンス本の本質的な部分ではない。\n","ref":"/tech-blog/blog/podcast-matome-texta-200827/"},{"title":"Goの参照渡しについて調べてみた","date":"","description":"Goでは全てが値渡し","body":"Goにおける参照渡し＝ポインタの値渡し Goでは関数にパラメータを渡すとき、全て値渡しで実現されています。\n（C派生の言語はすべてそうらしいです）\nじゃあ、参照渡しって何？ってなりますよね。\n参照渡し＝ポインタの値渡しです。\nつまり、ポインタそのものを渡しているわけではなく、ポインタのコピーを渡しています。\n値渡しと参照渡しの差は、内部の値をコピーするかどうかです。\nこちらについては後ほど例を交えて説明します。\n今回の内容はGo公式ドキュメントの『Pointers and Allocation』 の章に 詳細な記載があります。\n本記事では、『Pointers and Allocation』 から要点を抜粋して紹介します。\n値渡しと参照渡しの違いは内部値のコピー有無 まずは、先述した\n 値渡しと参照渡しの差は、内部の値をコピーするかどうかです。\n について詳しく見ていきます。\n公式ドキュメント『When are function parameters passed by value?』 の節に以下の記述があります。\n For instance, passing an int value to a function makes a copy of the int, and passing a pointer value makes a copy of the pointer, but not the data it points to.\nたとえば、int値を関数に渡すとintのコピーが作成され、ポインター値を渡すとポインターのコピーが作成されますが、ポインターが指すデータは作成されません。\n つまり、\n 値渡し：値のコピーが作成される 参照渡し：ポインタのコピーは作成されるが、ポインタが指すデータ（値）のコピーは作成しない  といった差があります。\n図にすると以下のとおりです。\n同じ色の箱はアドレスが同じだと考えてください。\n（図が下手なところはほっといてあげてください🙇‍♂️）\n大きな差がありますね。\nこの差により、例えば、多くのフィールドを持つ構造体を関数の引数やレシーバとして渡す場合、\n値渡しでは全フィールドのコピーが行われてしまうため パフォーマンス的に良くないといった違いが生まれてきます。\n無駄なコピーを行わないために全て参照渡しにしとけばいいか、\nというとそれはまた別で考慮すべき点が出てきます。\n「値渡し または 参照渡しのどちらを使用するか」については多くの議論がなされています。\n Go公式ドキュメント『Should I define methods on values or pointers?』  Yury Pitsishin『Pass by pointer vs pass by value in Go』  pospomeのプログラミング日記『golang の 引数、戻り値、レシーバをポインタにすべきか、値にすべきかの判断基準について迷っている』  THE Finatext Tech Blog『Go言語（golang）における値渡しとポインタ渡しのパフォーマンス影響について』   コードで確認 では、最後にここまでの内容をコードで確認して終わります。\nplayground 上記のplaygroundを実行すると、以下のように出力されました。\n（アドレス部分は実行ごとに異なります）\nmain()における構造体のアドレス： 0xc00010a040 main()におけるnameのアドレス： 0xc00010a040 PassByReference()における構造体のアドレス： 0xc000102020 PassByReference()におけるnameのアドレス： 0xc00010a040 PassByValue()における構造体のアドレス： 0xc00010a050 PassByValue()におけるnameのアドレス： 0xc00010a050  PassByReference()がレシーバを参照渡しで受け取る関数で PassByValue()がレシーバを値渡しで受け取る関数です。\nmain()とPassByReference()を比較すると、両者の構造体のアドレスが異なっています。\nHuman構造体がもつnameフィールドについては同じアドレスを指しています。\nつまり、レシーバのポインタはコピーしたものを参照していますが、\nフィールドの値はコピーではなく、main()で定義したものが使用されています。\n先述の内容と一致しますね。\n一方で、main()とPassByValue()を比較すると、\n両者の構造体のアドレスおよびフィールドのアドレスがすべて異なります。\nすなわち、レシーバのポインタおよびフィールドのすべての値に関して、コピーしたものを参照しています。\nこちらも先述の内容と一致します。\n納得！\nちなみに、なぜすべて値渡しで実現しているかについては、\n先程紹介した下記の記事で触れられています。\nYury Pitsishin『Pass by pointer vs pass by value in Go』 →「Passing by value often is cheaper」の章\n","ref":"/tech-blog/blog/go-always-passing-by-value/"},{"title":"【Go+DDD】エンティティと値オブジェクトの実装方法（自己流）","date":"","description":"こんな感じでやってます","body":"GoでDDD 今担当しているプロジェクトでは、GoでAPIを作っています。\nこのプロジェクトでは、DDDの考え方や設計パターンも取り入れています。\n今回はDDDの設計パターンの中でもEntityとValue Object（VO）について、\n僕がGoでどうやって実装しているのか紹介していきます。\n実装例 兎にも角にも、まずはコードを示します。\n// animal/dog/dog.go package dog type Dog struct { name Name } func New(name string) (*Dog, error) { n, err := newName(name) if err != nil { return nil, err } return \u0026amp;Dog{ name: *n, }, nil }  // animal/dog/name.go package dog import ( \u0026quot;errors\u0026quot; \u0026quot;unicode/utf8\u0026quot; ) type Name string func newName(v string) (*Name, error) { // 名前は3文字以上というビジネスロジック if utf8.RuneCountInString(v) \u0026lt; 3 { return nil, errors.New(\u0026quot;名前は3文字以上！\u0026quot;) } n := Name(v) return \u0026amp;n, nil }  // main.go package main import ( \u0026quot;fmt\u0026quot; \u0026quot;playground/animal/dog\u0026quot; ) func main() { // d := dog.Dog{name: \u0026quot;犬太郎\u0026quot;} できない d, _ := dog.New(\u0026quot;犬太郎\u0026quot;) // できる fmt.Printf(\u0026quot;%+v\\n\u0026quot;, d) d, err := dog.New(\u0026quot;犬\u0026quot;) if err != nil { fmt.Println(err) // 犬の名前が「犬」は可愛そうだからできない() } }  playground 今回の例では、DogというstructがEntityで、NameがVOです。\nDogのnameは必ず3文字以上にするというビジネスロジックがあります。\nポイント1 EntityとVOでファイルを分けています。\nまた、両者は同じディレクトリ内に置いています。\nどれがEntityでどれがVOか分かりづらいと思われる方もおられるかもしれませんが、\n個人的には言うほど分かりづらくありません。\nなぜかと言うと、EntityとVOが入っているディレクトリ（パッケージ）名と、\nEntityのファイル名が一致するからです。\n今回の例で言えば、\nDog Entityは/animal/dogディレクトリ配下のdog.goの中にあります。\nディレクトリ名とEntityのファイル名が一致しています。\nこのルールが分かっていれば、特に問題はありません。\n加えて、EntityとVOは同一のパッケージ内にあるべきだと考えています。\nポイント2 Dog Entityのnameフィールドを小文字にすることで、\nNew()（コンストラクタ的なの）を使用しないと、\nnameの値をセットできないようにしています。\n（dog.Dog{name: \u0026quot;hoge\u0026quot;} はできない）\nまた、New()を経由することで、必ずnewName()が使われる ため、\nDogのnameは 3文字以上にするというビジネスロジックを確実に守ることができます。\n社内の方に「dog.Dog{} はできちゃうね」とコメントをいただきました。\nこの件については、（願望的なところも入ってきてしまうのですが）\n不用意なsetterを用意していなければ、\n「あれ？フィールドに値セットできない！」ってなるはずなので、\nそこで気づいてもらえると思っています。。。\n（さすがに初期化しただけの構造体を保存するようなことはないと信じてます）\nポイント3 VO自体はexportします。\nVO（型）を引数として指定することもあるのでこうしています。\nexportしちゃうと、dog.Name(\u0026quot;ねこ太郎\u0026quot;)とすることで、\n不正なnameを作れるのでは？と考える方もおられると思います。\nたしかに作れます。\nしかしながら、保存はEntity単位で行うため、\n不正なnameがEntityにセットできないようになっていれば無問題であると考えています。\nポイント4 VO→基本型への変換が必要になることは、往々にしてあると思います。\nこのとき必要になる、基本型への変換処理はVO自身に持たせています。\n（ここは特に議論の余地があると思っています）\n以下のサンプルをご覧ください。\n// animal/dog/dog.go package dog type Dog struct { name Name } func New(name string) (*Dog, error) { n, err := newName(name) if err != nil { return nil, err } return \u0026amp;Dog{ name: *n, }, nil } func (d Dog) Name() *Name { return \u0026amp;d.name }  // animal/dog/name.go package dog import ( \u0026quot;errors\u0026quot; \u0026quot;unicode/utf8\u0026quot; ) type Name string func newName(v string) (*Name, error) { // 名前は3文字以上というビジネスロジック if utf8.RuneCountInString(v) \u0026lt; 3 { return nil, errors.New(\u0026quot;名前は3文字以上！\u0026quot;) } n := Name(v) return \u0026amp;n, nil } func (n Name) String() string { return string(n) }  // main.go package main import ( \u0026quot;fmt\u0026quot; \u0026quot;playground/animal/dog\u0026quot; ) func main() { d, _ := dog.New(\u0026quot;犬太郎\u0026quot;) fmt.Println(d.Name().String()) }  playground まず、Dog Entityに（不本意ながら）nameのgetter（Name()）を追加しました。\n次に、Name VOにString()メソッドをもたせました。\nそして、呼び出し元では d.Name().String() とすることで、\n基本型（string）としてのnameを取得できます。\nDog Entityにnameのgetterを用意したことについて、\nDTOへの変換やレイヤ間で値を受け渡すときなどに、\n構造体の詰め替えが発生すると思います。\nこのときに、Goの場合どっちみちgetterが必要になることでしょう。\nよって、どうせ必要になることが分かっているので用意した形になります。\nただし、このgetterは、\n値の詰め替えや基本型取得といった、複雑なロジックを持たない処理にのみ使用し、\n不用意な使い方はしないことを 運用（PRレビュー）で100%カバーすること前提で許可しています。\n・・・\n確実にできないようにした方がいいんでしょうね。。。\n賛否両論ありますよね、、、わかります\n他の方法として、Dog EntityのName()を以下のようにもできます。\nfunc (d Dog) Name() string { return string(d.name) }  ただし、ある関数の引数として、NameというVO（型）のまま渡したい場合、\nこの方法では対応できません。\n引数で渡す用の値（VOのまま）を取得する処理と 基本型としての値を取得する処理を別関数として用意するのが一番いいのかなと思っています。\n…が、今のところ、VOにString()メソッドを持たせる方式で特に困ったことがないため、\nこのまま進めています。\nおわりに ざっとポイントを洗い出してみましたが、\n実装方法を考えていた時期とブログを書いている時期がずれているため、\n書き忘れているポイントがあるかもしれません。\nなにか思い出したタイミングで追記していきます。\n最後にお願いです！\nGo+DDDの事例は他の言語に比べるとまだまだ少ないと思います。\nよって、僕も日々、試行錯誤し、より良い実装方法を探しています。\n今回紹介した実装方法には、まだまだ抜けもあれば、より良い実装方法もあると考えています。\nなので、みなさん、ぜひコメントください！\n→ Twitter よろしくお願いします〜\n","ref":"/tech-blog/blog/go-ddd-entity-vo/"},{"title":"【Golang】go test におけるキャッシュの消し方","date":"","description":"知っておくと便利","body":"go test のキャッシュを消すのは簡単 $ go clean -testcache\n以上です！\n$ go test ./... ok github.com/oxequa/realize\t(cached) ok github.com/oxequa/realize/realize\t(cached)  このように (cached) となっていたものが、、、\n$ go clean -testcache $ go test ./... ok github.com/oxequa/realize\t0.086s ok github.com/oxequa/realize/realize\t0.389s  このように、実行時間が表示されており、キャッシュが消えていることが分かりますね。\nちなみに、キャッシュを無視する方法はもうひとつあり、\n以下のように -count=1 をつけてやればOKです。\n$ go test ./... -count=1 ok github.com/oxequa/realize\t0.076s ok github.com/oxequa/realize/realize\t0.384s  ここからは上記コマンドが一体なにをしてくれたのか、\nもう少し詳細に話していきます。\ngo clean とは こちら にドキュメントがあります。\n Clean removes object files from package source directories.\n go clean は上記のとおりファイルを消してくれるわけですね。\n-testcache オプションをつけると、\nテストに関するキャッシュファイルのみを消してくれます。\nでは、次にキャッシュファイルがどこにあるのか見ていきます。\nキャッシュはどこに保存されている？ 環境変数 GOCACHE で指定されている場所に保存されます。\n参考：公式ドキュメント count オプションについて 最後に$ go test ./... -count=1 によって、\nキャッシュを無効化できた理由についてです。\nこの話は公式ドキュメント にて、\n「本来意図した使い方ではないが、そういう使い方もできる」\nぐらいのニュアンスで紹介されています（以下参照）\n The idiomatic way to disable test caching explicitly is to use -count=1.\n そもそも、countオプションはその名前のとおり、 キャッシュ無効化のためのものではないです。\ncountオプションはテストを指定回数実行し、\nそのベンチマークを取るためのオプションです（以下参照）\n -count n\n Run each test and benchmark n times (default 1). If -cpu is set, run n times for each GOMAXPROCS value. Examples are always run once.   ベンチマークを取るのにあたってキャッシュは不要であるため、\ncountオプションがつくとキャッシュが無効化されます。\nこのルールを応用して、-count=1とすることで、\nテスト自体は1回しか実行されず、かつ、キャッシュも無効化して、\nテストを走らせることができるわけです。\nなるほど\n","ref":"/tech-blog/blog/go-test-cache-clear/"},{"title":"【Golang】jsonパッケージの知っておくと便利な機能","date":"","description":"","body":"jsonパッケージ Goを触ってる人ならだれもが一度はお世話になるであろう パッケージ「json 」\n今回はそんな json パッケージについて、\n知っておくと便利な機能を2つ紹介します。\n（比較的有名なものしかないですが🙏）\n1. 独自の変換ロジックを実装できる 例えば、下記のコードのように、\nある構造体（Human）のフィールドを外部公開したくない場合、\njsonパッケージの Unmarshal()，Marshal() が使えません。\n（上記関数は外部公開されたフィールドのみ変換できる）\ntype Human struct { // フィールドを外部公開したくない name string age int } func main() { h := Human{ name: \u0026quot;Taro\u0026quot;, age: 21, } // 構造体 → JSON j, _ := json.Marshal(h) fmt.Println(string(j)) // {} // JSON → 構造体 var uh Human _ = json.Unmarshal(j, \u0026amp;uh) fmt.Printf(\u0026quot;%+v\\n\u0026quot;, uh) // {name: age:0} }  playgroud 実際に実行してみると、うまく変換できていないことが分かると思います。\nさて、このときどうすれば正しく変換できるかというと、\n変換対象の構造体に以下のメソッドを生やしてやればOKです。\n MarshalJSON() ([]byte, error) UnmarshalJSON(data []byte) error  type Human struct { // フィールドを外部公開したくない name string age int } func (h Human) MarshalJSON() ([]byte, error) { type tmp struct { Name string `json:\u0026quot;name\u0026quot;` Age int `json:\u0026quot;age\u0026quot;` } t := tmp{ Name: h.name, Age: h.age, } return json.Marshal(t) } func (h *Human) UnmarshalJSON(data []byte) error { type tmp struct { Name string `json:\u0026quot;name\u0026quot;` Age int `json:\u0026quot;age\u0026quot;` } var t tmp _ = json.Unmarshal(data, \u0026amp;t) h.name = t.Name h.age = t.Age return nil } func main() { h := Human{ name: \u0026quot;Taro\u0026quot;, age: 21, } // 構造体 → JSON j, _ := json.Marshal(h) fmt.Println(string(j)) // {\u0026quot;name\u0026quot;:\u0026quot;Taro\u0026quot;,\u0026quot;age\u0026quot;:21} // JSON → 構造体 var uh Human _ = json.Unmarshal(j, \u0026amp;uh) fmt.Printf(\u0026quot;%+v\\n\u0026quot;, uh) // {name:Taro age:21} }  playgroud うまく変換できましたね👍\nこのように、Marshal() と Unmarhsal() は 対象の構造体に生えている MarshalJSON() と UnmarhsalJSON() を見に行ってくれるわけです。\nGoの内部実装を追いかけたければ…  対象の構造体に生えている MarshalJSON() と UnmarhsalJSON() を見に行ってくれるわけです。\n 先述した↑この部分がどういう仕組みになっているのかは、\njson/encode.go を見ればわかります。\n→ 494行目らへんとかとか 使いみちいろいろ 今回紹介した例以外にも、\n下記記事のように時間形式を変更するために使用する例もあります。\n 時間形式の変更   2. 構造体なしでも変換できる 実はJSONの変換処理は、構造体をきっちり定義してやる必要はありません。\n以下に示すとおり、\ninterface{} を使うと、map[string]interface{} に変換してくれます。\nfunc main() { // どんな内容か分からないJSON mysteriousJSON := \u0026quot;{\\\u0026quot;name\\\u0026quot;: \\\u0026quot;Taro\\\u0026quot;, \\\u0026quot;age\\\u0026quot;: 21}\u0026quot; var i interface{} _ = json.Unmarshal([]byte(mysteriousJSON), \u0026amp;i) for k, v := range i.(map[string]interface{}) { fmt.Printf(\u0026quot;%s: %v\\n\u0026quot;, k, v) // キー・バリューのセットを取得できる } }  playground 後は、mapに対してよしなに処理してやればOKです。\nやはり、ちゃんと構造体を作って、\nフィールドで型を指定してやるのが理想だと思います。\nしかし、正常時と異常時でレスポンス構造が大きく変わる場合などは、\n一旦、map型に変換して、正常時用か異常時用かを判断するのもありかなと思います。\n正常時と異常時の両方に対応できるでっかい構造体を作ってもいいですが、\n無駄が多くなりがちですしね。\nその状況に合わせて、使い分けれると良さそうですね👍\nみなさんどうしているのか聞いてみたいですね〜\nまとめ 知っていればどうってことない機能ですが、\n知らなければハマりどころになるところですよね。\nGo初学者の方の参考になれば幸いです。\n","ref":"/tech-blog/blog/go-json-tips/"},{"title":"【Golang】errorの同値性と表示について調べた","date":"","description":"errorに関するちょっとしたメモ","body":"errorについて疑問があった Goのコードを書いてて、ふと気になったことがあったので調べてみました。\nerrorの同値性 1つ目の疑問は、下記コードで e1 と e2 がイコールではないことです。 （同値性なんて仰々しく言ってすみません。たったこれだけの疑問です😇🙇‍♂️）\nfunc main() { e1 := errors.New(\u0026quot;error1\u0026quot;) e2 := errors.New(\u0026quot;error1\u0026quot;) e3 := e1 fmt.Println(e1 == e2) // false fmt.Println(e1 == e3) // true }  Playground 結論（errorの同値性） errors.New() が返しているのがポインタでした。\nつまり、さきほどのコードの6行目はポインタの値を比較しているので、そりゃfalseになりますね。\nerrorの表示 2つ目の疑問は、下記コードで e1 を表示すると、\nerrors.New()の戻り値である構造体の値ではなく、エラー文言が表示されることです。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;errors\u0026quot; ) func main() { e1 := errors.New(\u0026quot;error1\u0026quot;) fmt.Println(e1) // error1 }  Playground errors.New()が返しているのは構造体なので、\n下記コードのように構造体の内容が表示されないのはなんでだ？ってなったわけです。\npackage main import \u0026quot;fmt\u0026quot; func Hoge() interface{} { type hoge struct { s string } return \u0026amp;hoge{s: \u0026quot;hoge\u0026quot;} } func main() { h := Hoge() fmt.Println(h) // \u0026amp;{hoge} }  Playground まぁ、だいたい予想はついています。\nerrorってGoの中に組み込まれているやつなので、特別な処理が入っているんでしょう（参考 ）\n問題はその処理がどこにあるのかってことですね。\nってことで、該当箇所を探します。\n・\n・\n・\nありました。\nここ ですね。\np.fmtString(v.Error(), verb)  Error() で取り出した値を表示しているようですね。\nということは、、、\npackage main import ( \u0026quot;fmt\u0026quot; ) type CustomError struct { s string } func (e CustomError) Error() string { return e.s + \u0026quot; この文章が表示されるはず\u0026quot; } func NewCustomError(s string) error { return \u0026amp;CustomError{s: s} } func main() { ce1 := NewCustomError(\u0026quot;custom error 1\u0026quot;) fmt.Println(ce1) // custom error 1 この文章が表示されるはず }  Playground たしかに、Error() 関数に変更を入れると、表示される内容も変わりましたね。\n結論（errorの表示） errorに関しては、特別な処理が入っていて、Error()で取得した文字列を表示している。\n","ref":"/tech-blog/blog/error_questions/"},{"title":"【Golang】errorsパッケージの中身覗いてみた","date":"","description":"今回は Unwrap()，Is()，As() についてお届け","body":"errorsパッケージに興味持った v1.13からerrorsパッケージに Unwrap() Is() As() といった関数が追加されました。\n（もう1.14もリリースされているのに今さらですね😇）\n今回はこれら3つの関数について、内部実装を追いかけていきます。\nと、その前に、errorsパッケージの概要と関連パッケージについて軽く説明しておきます。\nerrorsパッケージと関連パッケージ errorsパッケージ 名前の通り、エラー関連の処理がまとまっているパッケージですね。\nGoの標準パッケージです。\n→ GoDoc v1.13にて、先述の Unwrap() Is() As() という関数たちが追加されました。\nerrorを扱うパッケージとして、もうひとつ有名なパッケージがあります。\nxerrorsパッケージです。\nxerrorsパッケージ xerrors とは、 Goのサブリポジトリ で開発が進められているパッケージです。\n（準標準パッケージといった感じでしょうか）\nxerrorsのGoDoc に下記の記述がある通り、\n These functions were incorporated into the standard library\u0026rsquo;s errors package in Go 1.13: - Is - As - Unwrap\n もともとは本パッケージに Unwrap() Is() As() が実装されていましたが、\nv1.13にて標準パッケージに取り込まれました。\nさて、軽くerror関連のパッケージについて触れたところで、\n早速、Unwrap() Is() As() の内部実装を見ていきたいと思います。\nなお、Goのコードはv1.14.0を参照しています。\nUnwrap()  ラップされたエラーから中身のエラーを取り出す関数です。\n処理としては下記のようになっています。\nfunc Unwrap(err error) error { u, ok := err.(interface { Unwrap() error }) if !ok { return nil } return u.Unwrap() }  https://golang.org/src/errors/wrap.go?s=372:400#L14\nぱっと見だと、ん？っとなってしまうかもしれませんが、\n下記のように処理を分解してやると、特別難しいことは何もしていないことがわかります。\nfunc Unwrap(err error) error { // ラップされたエラーのインターフェース type wrapErrInterface interface { Unwrap() error } // 型アサーションにより、ラップされたエラーのインターフェースを満たしているかチェック u, ok := err.(wrapErrInterface) if !ok { return nil } return u.Unwrap() }  やっていることとしては、7行目で 型アサーションを用いてラップされたエラーのインターフェースを満たしているかチェックし、\n満たしていなければ（ok == false）、nilを返す。\n満たしていれば（ok == true）、実装されている Unwrap() を処理するわけです。\nここで注意ですが、\n12行目の Unwrap() は今まで話に出てきていた errors.Unwrap() とは全く別物です。\nでは、12行目の Unwrap() はどこにあるのか。 答えはerrorをラップする処理のところにあります。\nerrorをラップする関数 errorをラップする関数である fmt.Errorf() の中身を見てみましょう。\nfunc Errorf(format string, a ...interface{}) error { p := newPrinter() p.wrapErrs = true p.doPrintf(format, a) s := string(p.buf) var err error if p.wrappedErr == nil { err = errors.New(s) } else { err = \u0026amp;wrapError{s, p.wrappedErr} } p.free() return err }  https://golang.org/src/fmt/errors.go?s=624:674#L17\n10行目で、wrapError なる構造体を返していますね。 宣言箇所に飛んでみましょう。\ntype wrapError struct { msg string err error } func (e *wrapError) Error() string { return e.msg } func (e *wrapError) Unwrap() error { return e.err }  https://golang.org/src/fmt/errors.go#L32\nUnwrap() がありましたね。\nwrapError構造体は内部フィールドに err を持っており、\nここにラップしたエラーを入れるわけです。\n実際、さきほどの Errorf() の10行目でセットしてますよね。\nerrors.Unwrap() はこうして実装されていたわけですね〜\nどんどん行きましょう。\nIs()  次は Is() を見ていきます。\n本関数は2つのエラーが同じエラーかどうかを判定します。\nまた、比較元（第一引数）のエラーがラップしたエラーだったとしても、\n最後までUnwrapして比較してくれます。\n処理はこんな感じです。\nfunc Is(err, target error) bool { if target == nil { return err == target } isComparable := reflectlite.TypeOf(target).Comparable() for { if isComparable \u0026amp;\u0026amp; err == target { return true } if x, ok := err.(interface{ Is(error) bool }); ok \u0026amp;\u0026amp; x.Is(target) { return true } if err = Unwrap(err); err == nil { return false } } }  要となる処理は7〜20行明のfor文内の処理です。\nまずは、8,9行目にて単純にエラー同士の比較をしています。\nここで一致すれば return true ですね。\n次に11行目でerrが Is(error) bool という関数を持っているかどうか、\n型アサーションによって確認しています。\n本処理がなにをしているかというと、\n独自の同値判定処理がないか確認し、ある場合はその同値判定処理を使用して判定を行う\nということをしてくれています。\nIs(error) bool の実装例が公式のドキュメント にあります。\n↓↓↓\nfunc (m MyError) Is(target error) bool { return target == os.ErrExist }  独自のエラー型を定義するときに役立ちそうですね。\nでは、最後に15行目からの処理です。\nここはerrをUnwrapする処理ですね。\n（このUnwrap()は前章で説明した関数です）\nつまり、\nisComparable \u0026amp;\u0026amp; err == target\nおよび\nx, ok := err.(interface{ Is(error) bool }); ok \u0026amp;\u0026amp; x.Is(target)\nの両条件に該当しなかった場合は、errの中にあるエラーを抜き取り、\nそのエラーに対して、forループの最初から処理していくということになります。\nこの最後のUnwrap()により、\n本章冒頭に述べた\n また、比較元（第一引数）のエラーがラップしたエラーだったとしても、\n最後までUnwrapして比較してくれます。\n というのを実現しているわけですね。\nAs()  最後に As() です。\n本関数はラップされたエラーから指定のエラーを抽出します。\n抽出できるエラーがない場合は戻り値としてfalseが返されます。\nそれでは内部実装を見ていきます。\nfunc As(err error, target interface{}) bool { if target == nil { panic(\u0026quot;errors: target cannot be nil\u0026quot;) } val := reflectlite.ValueOf(target) typ := val.Type() if typ.Kind() != reflectlite.Ptr || val.IsNil() { panic(\u0026quot;errors: target must be a non-nil pointer\u0026quot;) } if e := typ.Elem(); e.Kind() != reflectlite.Interface \u0026amp;\u0026amp; !e.Implements(errorType) { panic(\u0026quot;errors: *target must be interface or implement error\u0026quot;) } targetType := typ.Elem() for err != nil { if reflectlite.TypeOf(err).AssignableTo(targetType) { val.Elem().Set(reflectlite.ValueOf(err)) return true } if x, ok := err.(interface{ As(interface{}) bool }); ok \u0026amp;\u0026amp; x.As(target) { return true } err = Unwrap(err) } return false } var errorType = reflectlite.TypeOf((*error)(nil)).Elem()  for文と errors.Unwrap() を使って ラップされたエラーの中身を取り出していくあたりは Is() と同じですね。\nまた、19行目で独自定義の As() を使用できるところも Is() と同じです。\n特徴的なのは、5〜18行目の部分になります。\nまず、5，6行目でreflectliteを使って第2引数のエラー（target）の構造を読み取っています。\n reflectliteはreflectパッケージの軽量版で、\nruntimeおよびunsafe以外での使用は基本的に禁止されています。 \u0026raquo; 参考  そして、targetがポインタである、かつ、nilでないことを確認します。\n抽出したエラーはtargetに格納するので、targetはポインタである必要があります。\nよって、ポインタかどうか確認しているのだと考えています。\n加えて、10行目で、interfaceである、かつ、errorType（＝error）を実装できているかをチェックします。\n以上で、targetがerrorを格納できる箱であるかどうかを判定しています。\n続きの13行目以降で、\nerrがtargetに格納できる値かどうかを判定し、できるならば格納しています。（15，16行目）\n格納できない場合は、独自実装の As() 探して、実行していますね。\nerr が target に格納できず、独自実装の As() もない場合は、\nerr を Unwrap() して再度同じ処理を行います。\nそして、格納できるエラーがなかった場合は false を返すわけですね。\nまとめ errorsパッケージの実装を覗いてみましたが、いかがだったでしょうか？\n普段使ってる標準パッケージの内部実装を追いかけるのは楽しいですね〜\n今回はerrorsパッケージの中身を見ましたが、reflectliteパッケージが結構使われていましたね。\nreflectliteの動きが分からない部分もあったので、\n次はreflectliteの中身も見たいなという気持ちになっています。\n（reflectliteを少し覗いたのですが、Goの型のデータ構造？的な話が入ってきており、ビビってます😇）\nreflectliteを一緒に読みたいって方おられたらTwitterでDM ください！\nぜひオンラインでコードリーディング会しましょう\n参考文献  errorsパッケージの公式ドキュメント  Go 1.13 のエラー・ハンドリング  Golang: How to handle Errors in v1.13  reflectliteパッケージの公式ドキュメント   ","ref":"/tech-blog/blog/errors_package/"},{"title":"Goのバージョン管理について","date":"","description":"地味にいろいろとあってややこしい","body":"Goのバージョン管理 注意1：本記事はGo自体のバージョン管理についてです。Go Modulesなどは対象外です。 注意2：基本的にMacユーザを対象にしています。（WindowsとLinuxももちろん好きです）\n開発において言語のバージョン管理はつきものだと思います。\nそのニーズは高く、rbenv や nodenv といったバージョン管理ツールが普及しています。\nただし、Goの場合は少し話が変わってきます。\nもちろんGoでも goenv が用意されていますが、\n（今のところ）Goは後方互換性が担保されているので、基本的に最新バージョンに上げ続ければOKです。\n…と言いつつも、GAEを使用するといった場合に、どうしてもバージョン管理したくなることがあると思います。\nそこで今回はまずGoのバージョン管理ツールの紹介をした後で、\n最新バージョンをインストールする方法を紹介していきたいと思います。\nGoのバージョン管理ツール ▼ goenv  ◯◯env系は有名ですよね。\n言語のバージョン管理といえばこれです。\n導入手順は公式の手順 通りなので省略します。\n1点はまりどころがあります。\n$GOPATHが変わらなくなってしまうという問題です。\n本件に関しては以前、僕のブログで対処法を書いているので、\nこちら を参考にしてみてください。\n▼ go get（公式サイトに記載のある方法） （バージョン管理\u0026quot;ツール\u0026quot;とは言えませんが…）\n本方法は公式サイト に 記載されている方法です。\n$ go get golang.org/dl/goX.Y.Z $ goX.Y.Z download $ goX.Y.Z version go version goX.Y.Z linux/amd64  コマンド打つたびに、バージョンまで打つのがめんどくさいという方は、\nbash や zsh の設定でエイリアスでも貼ってやればOKですね。\n最新バージョンのインストール方法 冒頭で「基本的に最新バージョンに上げ続ければOK」と述べていたので、\n最新バージョンのインストール方法についても言及しておきます。\n特に新しいことはなくいろんなサイトで紹介されているのでさらっと流していきます。\n▼ Homebrew $ brew install go  以上です。\n標準出力にて「必要ならパスの設定してね」と言われます。\n言われたとおりにやればOKです。\n▼ ソースからのインストール こちらの方法はHomebrewでのインストールと比べると、少しややこしくなります。\nざっくり手順を説明します。（公式の説明ページ ）\n  Go1.4をインストール\nhttps://golang.org/doc/install/source#go14\nなぜ、いきなりv1.4をインストールするかというと、\nv1.5以降は全てGoで書かれているため、Go自身でコンパイルできます。\nよって、v1.5以降のGoをインストールするために GoをビルドするためのGoが必要になる というわけです。\n（ややこしいですが、セルフホスティング ってやつですね）\n  Gitから最新版のソースをもってくる\nhttps://golang.org/doc/install/source#fetch\n  最新版をインストール\nhttps://golang.org/doc/install/source#install\n  動作確認\nhttps://golang.org/doc/install/source#testing\n  （ただのリンク集になっていますが）以上です。\n▼ 公式サイトからのインストール この方法の方がソースからインストールするより簡単かなと思います。\nこちらの方法も公式サイト に詳しい説明があるのでざっくりの説明だけ載せておきます。\n（公式サイト には LinuxおよびWindowsについてもちゃんと説明があります）\n  Go本体をダウンロード\nhttps://golang.org/doc/install#download\n次節の『Go install.』 で 指定したOS用のGoがダウンロードされるので、Macを選択した上でダウンロードを開始します。\n  インストール\nhttps://golang.org/doc/install#install\nダウンロードした.pkgファイルを開くとインストールが勝手に始まります。\n  PATH設定\nhttps://golang.org/doc/install#install\nインストールして得たバイナリに対してPATHを通します。\n  以上です。\nまとめ バージョン管理ツールおよびインストール方法はいくつか存在します。\n使いやすい方法でどうぞ！\n","ref":"/tech-blog/blog/go-versions/"},{"title":"【DDD】集約とトランザクション境界について調べたことメモ","date":"","description":"「データの一貫性の境界」を見極めよう！","body":"簡単まとめシリーズ 今回は 集約とトランザクション境界 について、\n自分のわからないところを調べたので、メモとして残しておきます。\n集約 集約の説明を『ドメイン駆動設計入門 ボトムアップでわかる! ドメイン駆動設計の基本』 から拝借すると、\n「データを変更するための単位として扱われるオブジェクトの集まりを集約といいます」とのこと。\n↓ もうすこし具体的に言うと\nDDDではエンティティと値オブジェクトというものがありますが、\n値オブジェクトを直接触らず、 エンティティ経由でしか変更しないようにするというものですね。\nこのような制限をかけることで、\nひとまとまりにされたオブジェクト間で維持されるべき不変条件を守ることができます。\nトランザクション境界 基本的な考えとしては、集約ごとにトランザクションを貼ります。\n↑この基本を守るためにも、理想としては正しいモデリングにより、\n正しいトランザクション境界を見つけることが大事です。\n正しいトランザクション境界を見つけることは、不用意に大きなDBロックの発生を防止します。\nしかしながら、集約をまたいでトランザクション制御したくなるときもあります。\n→ 参考例 こういうときにどうするか、上記リンクでもいくつかの方法が挙げられています。\n他のサイトも調べてみましたが、だいたい同じような方法が出てきました。\n 結果整合性   主流っぽい  いろいろなサイト、書籍の中で紹介されていました   整合性を担保するための仕組みづくりが必要  整合性をチェックするためのバッチ など     集約をまたいでトランザクションを貼る   下記理由のためにあまり推奨されない  ロック範囲が大きくなってしまう 守るべき「データの一貫性の境界」をコード上で表現できなくなる  参考サイト        複数の集約をさらにまとめた集約をつくる   ロック範囲が大きくなってしまうため、あまり推奨されない  結果整合性 結果整合性については、\n『ドメイン駆動設計入門 ボトムアップでわかる! ドメイン駆動設計の基本』 の 12章3説「集約の大きさと操作の単位」で言及されているので、もう少しだけ詳しく調べました。\n結果整合性とは、最終的に整合性の取れていればOKという考え方。\nしたがって、整合性が取れていない状況が起こり得るが、それは許容する。\n「最終的に整合性を取る」ってどうやるの？\n→ こちら が参考になる。\nまとめ 設計周りの話は、唯一無二の答えがあるわけではありません。\nよって、今回の話においても「データの一貫性の境界」を意識し、\nちゃんとメリットとデメリットを理解した上で最善の解を選択する必要がありますね。\n参考資料  ドメイン駆動設計入門 ボトムアップでわかる! ドメイン駆動設計の基本  DDDにおいて、なぜ複数の集約にまたがってトランザクションをかけてはいけないのか（multiple aggregates in one transaction）  集約とトランザクション境界に関するメモ  集約の境界と整合性の維持の仕方に悩んで2ヶ月ぐらい結論を出せていない話  集約の境界と整合性問題に関する感想   ","ref":"/tech-blog/blog/ddd-aggregates-transaction/"},{"title":"【簡単まとめシリーズ】Go1.12からの変更点","date":"","description":"Go1.14が楽しみ","body":"簡単まとめシリーズ 『簡単まとめ』では、僕が記事や書籍で学んだ内容をメモ程度に簡単にまとめていきます📝\n今回は Go1.12からの変更点 についてです。\nThe State of Go 2020 Twitterで『The State of Go 2020 』というタイトルのスライドを見つけました。\nGo1.12から変わったところに焦点を当て、\nGo1.13でどのような機能が追加されているのか、 Go1.14でどのような機能が追加される予定なのかまとめてあります。\n今回は、完全主観で自分が興味のある内容をハイライトします〜😇\n完全主観ハイライト ▼ 数値まわりの表現方法が増える https://speakerdeck.com/campoy/the-state-of-go-2020?slide=7\n▼ interfaceにおける関数の重複が許可される（例外あり） https://speakerdeck.com/campoy/the-state-of-go-2020?slide=17\n▼ エラーハンドリングが変わる https://speakerdeck.com/campoy/the-state-of-go-2020?slide=26\n▼ testingパッケージに CleanUp() が追加 https://speakerdeck.com/campoy/the-state-of-go-2020?slide=39\n▼ go modules https://speakerdeck.com/campoy/the-state-of-go-2020?slide=43\n▼ 配列・スライスにおける範囲外指定時のエラーが親切になった https://speakerdeck.com/campoy/the-state-of-go-2020?slide=50\n▼ deferが速くなる https://speakerdeck.com/campoy/the-state-of-go-2020?slide=51\n▼ json関連の処理が速くなる https://speakerdeck.com/campoy/the-state-of-go-2020?slide=52\n▼ 他にもいろいろ速くなる https://speakerdeck.com/campoy/the-state-of-go-2020?slide=53\n▼ GopherConの参加者が増えていく様子がえもい https://speakerdeck.com/campoy/the-state-of-go-2020?slide=64\n","ref":"/tech-blog/blog/changes-since-go-1-12/"},{"title":"【merpay Tech Talk】マイクロサービスの冪等性に関する勉強会","date":"","description":"冪等性 is 大事","body":"Tech Talk vol.2 Backend Engineer 〜マイクロサービスの冪等性〜  connpass  ハッシュタグ：#merpay_techtalk  質問板   merpay社で開催された勉強会です。\n参加者のツイートも含めてメモを残しておきます。\nかなり雑なのでコンテキストが読み取れないところもあると思いますが、\nなにかの参考になれば幸いです。\n（@sonatard さんの実況にとても助けられました。 ありがとうございました！）\n1. 500万ユーザーを支える残高の冪等性 登壇者：（@knsh14）\nスライド\n参考スライド （ベースとなる話は↑これ）\n残高管理サービス（Balance Service） 使ってるDBはCloud Spanner\n外部サービスや他のマイクロサービスには依存してない\nDeleteなしでCRUのみ\nかなりシンプルで冪等性を担保しやすい\n冪等性があるAPI 最初に成功した一度だけ処理される\n同じリクエストを何回繰り返しても内部的には処理されない\n何度リクエストしても同じ結果が返ってくる 何度でもリトライできる\n取引IDが保存されていれば既に行われた取引である\n冪等性の担保  冪等性キーが同じ 外部から指定される取引IDのこと 残高の種類が同じ ポイント/メイルペイ残高 など 操作する金額が同じ  冪等なレスポンス  レスポンスはDBから引ける情報で組み立てる 取引IDから引ける情報  取引後残高は返さない    Twitterメモ 冪等なAPIでのエラー  リトライしても良いエラー：ex. タイムアウト リトライだめなエラー：ex. 残高不足  誰がどう使うのか？  リクエストを投げる側の使い方1つで簡単に冪等性が壊れる → ex. 取引IDを毎回変えるとか  2. コード決済における冪等性と整合性 登壇者：（@susho0220）\nスライド モノリスであれば、リクエスト、レスポンス内のトランザクションで整合性を保てる。\nマイクロサービスでは、トランザクションが分かれるため、\n決済の進捗状態を保持するDBを用意し、状態を管理 → Pending、Authorized、Captured\nメルペイのコード決済では、\nCloud Pub/Subを使ってAuthorizedまでを同期処理、Captureは非同期処理で行っている。\n同期処理の責務を最小限に抑えて、処理自体もシンプルにするのが狙い。\n→ リトライによる不整合の解消が重要な処理は、自動的にリトライをしてくれるPubSubで非同期にすることで、実装がシンプルになる\n3. バッチ処理と冪等性 登壇者：（@kaznishi1246）\nスライド バッチ処理 回復可能かどうかはとても大事\n冪等性があれば回復後のリトライも安心して行える\n何回実行されても大丈夫（冪等）なバッチ処理を作る バッチのリトライ戦略には大別して下記2パターンがある。\n（メルペイではどちらもある。）\n 処理済みも含めてやり直す  全ての処理が冪等であることが求められる。\n難しいことをあまり考えなくて良い。（if文減る）\nただし、時間・リソースをくう\n個々のステップが冪等である前提が必要。\n他のマイクロサービス連携してる場合は、リクエスト先の冪等性も必要\n 一度処理したものはスキップする  実装が複雑になる。（ステータスなどで条件分岐）\nただし、未処理のみ対応するので所要時間が短く、軽い\n「どこまで処理したか」をどこかに保持する必要がある\n外部サービスを使用する場合はどうする？ 外部サービスが冪等ならば何度リトライしても大丈夫だから無問題\nただし、外部サービスによっては、ロールバックされるものもあるので、そういう場合は検討が必要\nバッチを回す前の確認 バッチ処理が処理する材料データは揃っているか確認する （前段のバッチが終わっているか確認）\n→各バッチの終了状態をDBで管理している\n4. パネルディスカッション 登壇者：@kazegusuri, @knsh14, @susho0220, @kaznishi1246\n質問板 会場からの質問が多く、Q\u0026amp;Aだけで終了しました。\nとても興味深い話ばかりでした。\n冪等性キーの発行や管理はどうしてるんだろう？ Balance Service の前段にある Payment Service にて発行 → UUID v4 で発行（基本的に被ることはないはず）\nマイクロサービス間のデータ不整合を修正するバッチはどれくらいの時間間隔で実行しているのでしょうか？ 30分に1回\n15分とか短くしたいが、実行中の可能性も出てくるので、難しい\n10, 15分あける必要があるが、コンサバで30分\n冪等性がないことにより発生した問題や障害などは過去にありましたでしょうか？（言える範囲で結構です）   最初から意識されていたので特になかった\n  正しくリトライされ無かった経験はある\n  リクエストを受けたら、別マイクロサービスの情報を使用して処理を行っていた。\nしかし、その別マイクロサービスからもらうデータが変わったことでエラーとなった。\n→解決策として、Bodyデータ（別マイクロサービスの？）もDBに保存して使いまわした\nTwitterメモ トランザクションを使う以外にべき等性を担保する方法って例えばどんなのがありますか ユニーク制約を保証できるものならOK\nex. ユニーク成約に引っかかるようになったらロールバックとか\nカオスエンジニアリング的なことってやってたりするんですか Istioでfalte injection機能で取り組もうとしているが、想定した機能ではなかったのでまだ実施していない\nCloud Spannerの部分をMockにしてランダムでエラーを返すなどのテストを実行している\nTwitterメモ 売掛決済やクレカ決済のようにauthorized-\u0026gt;capturedに数日かかる場合はありますか？その場合にauthorizedを解放することはありますか？ statusをどうやって管理しているのか知りたい updateしているのか、eventソーシング的に組み立てているのか update でやってる。\nイベントソーシングに挑戦するほどの余裕がなかった。\nただ、updateだといつアクションが起こったのか分からなくなるから、ログを残す必要がある。\nマイクロサービス化するとチームごとに指針が違ったりすると思いますが、冪等性等外せないところを担保するためにどのような組織的工夫をしていますか。 最初はkazegusuriさんが口酸っぱく言っていたが、今はみんなが意識できている。\nTwitterメモ デザインドックを書いてレビューしてから取り組む\n冪等性の理解の普及をしてきた\nそのうえでチームに任せている\n取引IDが重複する可能性を考慮してるの、そもそもなんで重複する可能性があるんだろ。重複はしないけど、マイクロサービスの１サービスの中では重複するかしないかは知らないから一応考慮しておくという感じなのかな IDが絶対に被らない生成方法がある？\n冪等性キーだけで冪等性を保証しようとすると、\nリトライ時のパラメータが変わった時に問題が起きる可能性があるので、\nリクエストのボディーなども見るようにしたかった\n(が、今は冪等性キーだけしか見ていない？\nTwitterメモ 残高の整合性をどう担保しているのか聞いてみたい Balance Service では増えた減ったのアクションだけ記録、\n別で会計サービス?とかが残高を持っていたりして、そこと照らし合わせたりはする\nauthorizedになった時点でcapturedには100%遷移できるという前提でしょうか？ yes\nなぜBalance Serviceでサービスで残高などをレスポンスとして返してはいけないのかがわからなかったです 「結果いくらになった」というのは変わるからだめ\nこの話の中で、バッチの実行履歴テーブルを作ってる・場合によってはワークフロー化とかもある、という話があったと思うんですが、ワークフロー化せず履歴テーブルを作る選択をしたのはどうしてでしょうか？バッチの中での各トランザクションごとに再開ポイント・スキップできるできない、みたいな話もあったと思うんですけど、各トランザクションごとに個別バッチ化してワークフロー組んだら便利だったのかなーって思うのですがどうでしょうか？  各トランザクションごとに個別バッチ化しワークフローを組む\n という部分について、処理が複雑なところがあるので、できるか分からない。\n取引IDだけじゃなくてコンテンツの中身までチェックする理由は？ 取引IDが同じで処理内容が異なるリクエストの場合に、\n処理済みOKと誤って返さないようにという配慮の観点もあるとのこと。\n勉強になりました、良き\nTwitterメモ 取引IDを一意にするのは難しい？ そんなことはない\n「冪等性」の重要性は十分に理解しているのですが、そもそもどういう問題を解決するためでしょうか？ 不整合を修復すること。\n冪等性キーとレスポンスは永遠に保持し続けるのか、定期的に削除したほうがいいのか気になりました 今のところ消す予定はない\n一般的には消す方が多い。 →2時間とかで消すパターンが多い\nメルペイは消すのがめんどくさかったから、残せばいいんじゃない？で残ってたはず\nバッチの実行間隔短くすると周回遅れが起きたり、処理中掴むのは確かにありそう。だけど、決済で、数十分の処理中はあるんだろうか？ まぁ、ないです。ｗ\n5分くらいにはできるかなとは思っている。\nバッチにより不整合を解消することが起きるのか GCPのネットワークの問題で不整合が起きていることはある\nuuid v4だとしても衝突する場合があるのですが、ユニーク性はどう担保してますか? DBに保存しており、ユニーク制約があるので大丈夫\n不整合を修正するバッチがこけ続けたことはないですか？ あります。\n人力になるところもあるので、気付ける仕組みづくりをしている\nここだけの話 メルペイはかなりオープンに話しているから、特に無いｗ\nバッチ処理が増えてくると、何がどのタイミングでデータにアクセスしているか管理しきれなくなる場合があると思いますが、そのあたりの課題感はありますか？システム全体の処理を把握されている方が担保しているのでしょうか？ そこまで複雑にはなっていない。\nある程度マイクロサービス内で閉じた状態になっている。\nだから、今のところ特になにもしてないけど大丈夫\n全体を把握している人はいない。\nなんとなく分かっている人がいる？ので、なにかあったらその人中心に動くかなぁ。\nマイクロサービス意識しすぎて、コードペイメントとインナーペイメント別けるとかやりすぎじゃない？ QRとかNFCとか決済プロバイダ側で担保すること、\nその裏側でのお金の動きを別けるために必要だと感じている。\nインナーペイメント：クレカでいくら、残高からいくらって言えば、処理して、その結果を返すやつ\n（↑まとめきれませんでした。ですが↓のツイートが参考になります）\nTwitterメモ Code PaymentとInternal Paymentは分けすぎなのではないか？\n外部へのオーソリを投げるのはやり過ぎではないか？もっと簡易的にするべきではないか\nInternal Paymentは決済プロバイダのような立場\nCode Paymentは、決済プロバイダを使うFintech企業のサービスのような立場\n最後に 「自分のマイクロサービスだけでは冪等性を守れないので、そのマイクロサービスを使う他のマイクロサービスのチームとコミュニケーション大事」\nTwitterメモ ","ref":"/tech-blog/blog/mercari-tech-talk-idempotency/"},{"title":"GolangCI-Lintの設定ファイルを理解する","date":"","description":"DMM Advent Calendar 2019 9日目","body":"DMM Advent Calendar 2019 本記事は DMM Advent Calendar 2019 の 9日目 の記事です。\n私は現在、DMM.com の CDS というチームに所属し、\n主にユーザレビュー基盤 のバックエンドを開発しています。\n今回は、Golang 用 Linter である GolangCI-Lint を軽く紹介した後に、\nGolangCI-Lint のハマリポイントとその解決策である設定周りの話をします。\nLinter 導入していますか？ 突然ですが、みなさんの開発環境には Linter が導入されているでしょうか？\n私の所属するチームでは、\nコーディング規約違反 および コンパイラでは見つけられないエラー を検知するために、\nローカルと CI において Linter を回すようにしています。\nGolang における Linter Golang の場合、Linter がデフォルトで用意されているうえに、\nライブラリとして公開されているものも多く存在します。\nなかでも有名なものに以下のようなものがあります。\n govet：Golang デフォルトの Linter errcheck：ちゃんとエラーハンドリングしているかチェックしてくれる unused：未使用の定義をチェックしてくれる goimports：未使用のimportを消してくれたり、フォーマット修正してくれる gosimple：コードをシンプルにしてくれる  しかしながら、多すぎるがゆえに どれを選択すればいいのか分からなくなりがちです。\n加えて、導入する Linter が増えれば、その分だけ 導入・管理コストが増加 します。\nこの問題を解決してくれるツールが GolangCI-Lint です。\nGolangCI-Lint 勉強会でもよく耳にするようになってきている＋多くの紹介記事があるので、\nここで詳しく説明する必要もないかもしれませんが、いちおう少しだけ触れておきます。\nGolangCI-Lint とは、 Golang の Linter を一元管理するためのツールです。\n開発者は GolangCI-Lint を導入するだけで様々な Linter を実行することができます。\nしたがって、Linter の導入・管理コストが一気に下がりますし、\n運用していく過程で不要だと感じた Linter は、簡単に無効化することもできるので、\n気軽に Linter を試用することができます。\n対応 Linter はこちら に一覧が載っています。\n似たようなツールに gometalinter というのがあったのですが、\nこちらの議論 の結果、なくなることが決定しました。\n今後の主流は GolangCI-Lint です。\n（…ロゴいいですよね👍）\n使ってみる 導入 こちら に導入方法が書いてあります。\nBinary のインストール方法を紹介しておくと、下記のようになります。\n# $(go env GOPATH)/bin ディレクトリ配下にインストールする方法 curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin v1.21.0 # ./bin ディレクトリ配下にインストールする方法 curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s v1.21.0 # alpine linux 用のインストール方法 wget -O- -nv https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s v1.21.0  もちろん go get でもインストールできますし、\n他にも brew や Docker イメージとしても提供されています。\nIDEやエディタ上で実行する方法も紹介 されており、サポートが手厚いです。\n弊チームでは、ローカル用コンテナイメージのビルド時に go get してインストールしています。\n実行 $ golangci-lint run コマンドで実行できます。\nテストファイルにも Lint をかけたい場合は、--tests オプションを付与します。\n何も設定しない状態では、こちら に記載のある Linter が実行されます。\nでは、実際に動かしてみます。\n$ docker-compose exec -T app golangci-lint run --tests ./... handler/rest/blog.go:82:27: Error return value of `(*encoding/json.Encoder).Encode` is not checked (errcheck) json.NewEncoder(w).Encode(res) ^ domain/model/task/task.go:9:2: structtag: struct field tag `json:\u0026quot;title\u0026quot;,\u0026quot;hoge\u0026quot;` not compatible with reflect.StructTag.Get: key:\u0026quot;value\u0026quot; pairs not separated by spaces (govet) Title string `json:\u0026quot;title\u0026quot;,\u0026quot;hoge\u0026quot;` ^  エラーが出ました。\n2行目と5行目の最後に括弧書きでエラーを発見した Linter の名前が書いてあります。\n（厳密には Lint で出力された内容はエラーではありませんが、CIがこけるという意味で「エラー」と呼ぶことにします）\n今回の場合だと、errcheck と govet がエラーを発見したようですね。\nGolangCI-Lint には検知できないエラーがある…？🧐 では、ここから本記事の主題に入っていきたいと思います。\n実際に GolangCI-Lint を導入しようとしてハマったポイントです。\nといっても、GolangCI-Lint の README はとても詳細に書かれているので、\nなにかあっても README を見ればすぐ解決できます👍\n・\n・\n・\nそんなこんなでいきなりですが、同じソースコードに対して、\nGolangCI-Lint を使わずに golint を単体で走らせてみます。\n$ golint ./... domain/model/task/task.go:7:1: comment on exported type Task should be of the form \u0026quot;Task ...\u0026quot; (with optional leading article)  ！？\nさきほどの GolangCI-Lint にはなかったエラーが出力されました。\nなんとなく分かってきた方もおられると思いますが、\nGolangCI-Lint はデフォルト設定だと、いくつかのエラーを無視するようになっています。\n例えば、今回の例だと、コメントの記述形式についてのエラーですが、\nそこまで厳密に守らなくてもいい内容ですね。（僕は守りたい派ですが。。。）\nしたがって、GolangCI-Lint が気を利かせて無視するようにしてくれています。\nデフォルトで無視されるルール デフォルト設定だと無視されるルールは こちら の--exclude-use-defaultオプションの説明のところに記載があります。\n抜粋してくると以下のとおりです。\n    Linter名 無視されるエラー（Linterが出力する内容）     1 errcheck Error return value of .((os\\.)?std(out\\|err)\\..*\\|.*Close\\|.*Flush\\|os\\.Remove(All)?\\|.*printf?\\|os\\.(Un)?Setenv). is not checked   2 golint (comment on exported (method\\|function\\|type\\|const)\\|should have( a package)? comment\\|comment should be of the form)   3 golint test系パッケージにおける func name will be used as test\\.Test.* by other packages, and that stutters; consider calling this   4 govet (possible misuse of unsafe.Pointer\\|should have signature)   5 staticcheck ineffective break statement. Did you mean to break out of the outer loop   6 gosec Use of unsafe calls should be audited   7 gosec Subprocess launch(ed with variable\\|ing should be audited)   8 gosec errcheckと重複するエラーチェック G104   9 gosec (Expect directory permissions to be 0750 or less\\|Expect file permissions to be 0600 or less)   10 gosec Potential file inclusion via variable    さきほど例に挙げていた、golint のコメント記述形式に関するエラーは、表中2番のエラーです。\nだから、GolangCI-Lint では検知されなかったんですね。\nこのルール、人によっては「これ無視しちゃだめだろ」と思われるものもあると思いますが、\n投稿日時点ではこのようなルールがデフォルトで無視されるようになっています。\n設定ファイル .golangci.yml 気を利かせてくれているのは分かりますが、無視しないで欲しいときもありますよね。\n逆にこのエラーは無視してほしいっていうニーズもあると思います。\nそこで登場するのが .golangci.yml です。\n.golangci.yml により、GolangCI-Lint の細かな設定が可能になります。\nCLIのオプションでも指定できますが、チームで共有するなら設定ファイルの方がいいでしょう。\nまた、後述しますが、CLIのオプションでは指定できない設定もあるので注意が必要です。\n設定方法  設定ファイルとして .golangci.yml を紹介しましたが、他にも下記の拡張子が使用できます。\n .golangci.toml .golangci.json  今回は.golangci.ymlを使用します。\n設定ファイルのサンプルがGitHub上に公開 されています。\n使えるオプションはCLIと同じです。\nただし、CLI では、Linter ごとの設定（linters-settings）ができないため、\nLinter ごとに細かく設定をしたい場合は設定ファイルを書く必要があります。\n設置場所 次に、.golangci.ymlをどこに置くのかという話ですが、\nPC のルートディレクトリからプロジェクトのルートディレクトリ内のどこか であればOKです。\n例えば、$GOPATH が /go で、プロジェクトルートが /go/src/github.com/yyh-gl/hoge-project だった場合、\n以下のディレクトリ内を見に行ってくれます。\n ./ /go/src/github.com/yyh-gl/hoge-project /go/src/github.com/yyh-gl /go/src/github.com /go/src /go /  上にいくほど優先順位が高いです。（PCのルートディレクトリが一番低い）\n基本的には各プロジェクトのルートに置いておけばいいでしょう。\n実際に読み込まれている設定ファイルは-vオプションで確認可能です。\n$ golangci-lint run --tests -v ./... level=info msg=\u0026quot;[config_reader] Config search paths: [./ /go/src/github.com/yyh-gl/hoge-project /go/src/github.com/yyh-gl /go/src/github.com /go/src /go /]\u0026quot; level=info msg=\u0026quot;[config_reader] Used config file .golangci.yml\u0026quot; ← ここ \u0026lt;省略\u0026gt;  では、実際に設定ファイルを変更し、\nさきほどの golint が検知していたコメント記述形式に関するエラーを、\nGolangCI-Lint でも検知できるようにしてみます。\n\u0026ldquo;デフォルトで無視されるルール\u0026quot;を無視する golint が検知していたコメント記述形式に関するエラーを検知するには、\n\u0026ldquo;デフォルトで無視されるルール\u0026quot;を無視する必要があります。\n設定自体はすごく簡単です。\n# .golangci.yml issues: exclude-use-default: false  以上です。\nテストしてみましょう。\n$ docker-compose exec -T app golangci-lint run --tests ./... handler/rest/blog.go:82:27: Error return value of `(*encoding/json.Encoder).Encode` is not checked (errcheck) json.NewEncoder(w).Encode(res) ^ domain/model/task/task.go:7:1: comment on exported type Task should be of the form \u0026quot;Task ...\u0026quot; (with optional leading article) (golint) // Taskhoge : タスクを表現するドメインモデル ^ domain/model/task/task.go:9:2: structtag: struct field tag `json:\u0026quot;title\u0026quot;,\u0026quot;hoge\u0026quot;` not compatible with reflect.StructTag.Get: key:\u0026quot;value\u0026quot; pairs not separated by spaces (govet) Title string `json:\u0026quot;title\u0026quot;,\u0026quot;hoge\u0026quot;` ^  golint のエラーが増えましたね👍\nこのように簡単に GolangCI-Lint の設定を変更することができます。\n細かな設定も可能 さきほど少し触れましたが、各 Linter ごとの細かな設定も可能です。\nlinters-settings 各 Linter ごとの設定は linters-settings によって定義できます。\n# .golangci.yml linters-settings: errcheck: check-type-assertions: false check-blank: false ignore: fmt:.*,io/ioutil:^Read.* exclude: /path/to/file.txt govet: check-shadowing: true settings: printf: funcs: - (github.com/golangci/golangci-lint/pkg/logutils.Log).Infof - (github.com/golangci/golangci-lint/pkg/logutils.Log).Warnf - (github.com/golangci/golangci-lint/pkg/logutils.Log).Errorf - (github.com/golangci/golangci-lint/pkg/logutils.Log).Fatalf enable: - atomicalign enable-all: false disable: - shadow disable-all: false golint: min-confidence: 0.8  例えば、golint の min-confidence は Lint の厳しさを設定するもので、\n数値が低いほど厳しいルールが適用されます。\n（ちなみに、デフォルトは 0.8で、1.1 にすると何も検知しなくなります😇）\n他の設定たち GolangCI-Lint で使用できる設定を探したい場合は、\n設定ファイルのサンプルを参考にすればOKです。\nこのファイルの中に利用可能な全ての設定とデフォルト値が記載されています👍 最高ですね\n 設定ファイルのサンプル   まとめ GolangCI-Lint により、様々な Linter が一元管理でき、\nLinter の導入・管理コストがとても低くなったと感じています。\nまた、いろいろな Linter を気軽に試せるようになりました。\nちょっとしたコーディング規約違反を毎回人力で指摘している方や\nコンパイラでは発見できないエラーを潰すのに疲弊している方などは、\nぜひ、GolangCI-Lint の導入を検討しみてはいかかでしょうか？\n最高の DX です🎁\nDMM Advent Calendar 2019、明日は mimickn さんです！\n","ref":"/tech-blog/blog/golangci-lint-custom-settings/"},{"title":"【Golang+VCR】外部APIとの通信を保存してテストに使用する話","date":"","description":"Go3 Advent Calendar 2019 8日目","body":"Go3 Advent Calendar 2019 本記事は Go3 Advent Calendar 2019 の 8日目 の記事です。\nではでは、早速本題に入っていきます。\nモック使ってますか？ みなさんモックコードは書いていますか？\nテストコードを書いているなら、ほぼ必ず登場するあのモックです。\nDB処理や関数のモックなどいろいろありますよね。\nそんなモックコードですが、作ったり管理するのめんどくさいなぁとか思ってないですか？\nモックだからといって雑なコードになっていませんか？\n今回は、外部API通信のモック化にフォーカスし、\nモックコードの作成・管理コストを軽減する VCR ライブラリ を紹介します。\nVCR ライブラリ とは？ VCR（Video Cassette Recorder）とは、通信を保存し、再生するライブラリです。\nつまり、APIリクエストの初回通信の内容を保存し、\n次回以降その保存内容（レスポンス）を使いまわしてくれるというものです。\n言い換えれば、外部APIのモックを自動生成してくれるということですね！\nVCR ライブラリ in Golang World Golang 用の VCR ライブラリはいろいろあります 。\nスター数が多いのは以下のものです。\n go-vcr  vcr-go  govcr  rpcreplay   go-vcr および vcr-go，govcr の開発は盛んではないようです。\nrpcreplay は google-cloud-go に包含されるパッケージであり、安心して使えそうです。\nただし、gRPC 用なので、その点は注意が必要です。\nGoDocはこちら です。\n今回は REST API を使って説明していくので、go-vcr を使用します。\ngo-vcr は、vcr-go と govcr よりスター数が多いです。\nRuby 製の vcr というライブラリがもとになっているようです。\nサンプルを見ていく では、コードを交えて紹介していきたいと思います。\n今回は下記のような簡単なサンプルを用意しました。\n（最終的なサンプルコードはこちら にあります。）\nQiitaのユーザ情報取得APIを呼び出し、\nレスポンス内容（ID と Location のみ）を表示するだけの簡単なプログラムです。\n// /main.go package main import ( \u0026quot;fmt\u0026quot; \u0026quot;github.com/yyh-gl/go-vcr-sample/qiita\u0026quot; ) func main() { user := qiita.FetchUser(\u0026quot;yyh-gl\u0026quot;) fmt.Println(\u0026quot;============ RESULT ============\u0026quot;) fmt.Printf(\u0026quot;%+v\\n\u0026quot;, user) fmt.Println(\u0026quot;============ RESULT ============\u0026quot;) }  // /qiita/qiita.go package qiita import ( \u0026quot;encoding/json\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;net/http\u0026quot; ) type User struct { ID string Location string } func FetchUser(id string) (user *User) { req, _ := http.NewRequest(\u0026quot;GET\u0026quot;, \u0026quot;https://qiita.com/api/v2/users/\u0026quot;+id, nil) client := new(http.Client) resp, _ := client.Do(req) defer resp.Body.Close() body, _ := ioutil.ReadAll(resp.Body) _ = json.Unmarshal(body, \u0026amp;user) return user }  実行してみると、、、\n$ go run main.go ============ RESULT ============ \u0026amp;{ID:yyh-gl Location:Tokyo, Japan} ============ RESULT ============  ちゃんと ID と Location が表示できていますね。\nテストしたい 今回のサンプルは簡単なコードですがテストを書くことにします。\n・\n・\n・\n// /qiita/qiita_test.go package qiita_test import ( \u0026quot;testing\u0026quot; \u0026quot;github.com/stretchr/testify/assert\u0026quot; \u0026quot;github.com/yyh-gl/go-vcr-sample/qiita\u0026quot; ) func Test_FetchUser(t *testing.T) { tests := []struct { testCase string id string wantLocation string }{ { testCase: \u0026quot;Qiitaからyyh-glのユーザ情報を取得できていること\u0026quot;, id: \u0026quot;yyh-gl\u0026quot;, wantLocation: \u0026quot;Tokyo, Japan\u0026quot;, }, } for _, tt := range tests { t.Run(tt.testCase, func(t *testing.T) { user := qiita.FetchUser(tt.id) assert.Equal(t, tt.wantLocation, user.Location) }) } }  書きました。\n$ go test ./... ? github.com/yyh-gl/go-vcr-sample\t[no test files] ok github.com/yyh-gl/go-vcr-sample/qiita\t0.313s  ちゃんとテストが通りますね。\nしかし、このままではテストのたびに Qiita API にリクエストが飛んでしまうので良くないですね。\nここで、本日の主役 go-vcr を導入していきましょう。\ngo-vcr のセットアップ VCR ライブラリは通信内容を保存します。\nつまり、通信を傍受する必要があります。\ngo-vcr では、http.Client の Transport を go-vcr で用意されたものに差し替えることで、\n通信の傍受を可能にします。\nしたがって、まずは独自の http.Client を差し込めるように、\nサンプルのコードを修正していきます。\nQiita API 用の HTTP クライアントを作る まず、qiita.go に HTTP クライアント生成関数を作ります。\n// /qiita/qiita.go package qiita import ( \u0026quot;encoding/json\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;net/http\u0026quot; ) // ここ type Client struct { *http.Client } // ここ func NewClient(c *http.Client) Client { return Client{c} } type User struct { ID string Location string } // ここ func (c Client) FetchUser(id string) (user *User) { req, _ := http.NewRequest(\u0026quot;GET\u0026quot;, \u0026quot;https://qiita.com/api/v2/users/\u0026quot;+id, nil) resp, _ := c.Do(req) // ここ defer resp.Body.Close() body, _ := ioutil.ReadAll(resp.Body) _ = json.Unmarshal(body, \u0026amp;user) return user }  main.go と qiita_test.go も直します。\n// /main.go package main import ( \u0026quot;fmt\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;github.com/yyh-gl/go-vcr-sample/qiita\u0026quot; ) func main() { // ここ qiitaClient := qiita.NewClient(http.DefaultClient) user := qiitaClient.FetchUser(\u0026quot;yyh-gl\u0026quot;) fmt.Println(\u0026quot;============ RESULT ============\u0026quot;) fmt.Printf(\u0026quot;%+v\\n\u0026quot;, user) fmt.Println(\u0026quot;============ RESULT ============\u0026quot;) }  // /qiita/qiita_test.go package qiita_test import ( \u0026quot;net/http\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;github.com/stretchr/testify/assert\u0026quot; \u0026quot;github.com/yyh-gl/go-vcr-sample/qiita\u0026quot; ) func Test_FetchUser(t *testing.T) { tests := []struct { testCase string id string wantLocation string }{ { testCase: \u0026quot;Qiitaからyyh-glのユーザ情報を取得できていること\u0026quot;, id: \u0026quot;yyh-gl\u0026quot;, wantLocation: \u0026quot;Tokyo, Japan\u0026quot;, }, } // ここ qiitaClient := qiita.NewClient(http.DefaultClient) for _, tt := range tests { t.Run(tt.testCase, func(t *testing.T) { user := qiitaClient.FetchUser(tt.id) assert.Equal(t, tt.wantLocation, user.Location) }) } }  この状態でテストを実行すると、、、\n$ go test ./... ? github.com/yyh-gl/go-vcr-sample\t[no test files] ok github.com/yyh-gl/go-vcr-sample/qiita\t0.293s  ちゃんと通りますね。\nさて、これで NewClient() に渡す引数（http.Client）しだいで、\n使用する HTTP クライアント変更できるようになりました。\ngo-vcr 導入 ここから go-vcr を導入して、外部APIとの通信を保存・再生していくのですが、\nめちゃくちゃ簡単です。\n今回はテストにおいて、外部APIとの通信部分をモック化したいので、\nqiita_test.go を直していきます。\n// /qiita_test.go package qiita_test import ( \u0026quot;net/http\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;github.com/dnaeon/go-vcr/recorder\u0026quot; \u0026quot;github.com/stretchr/testify/assert\u0026quot; \u0026quot;github.com/yyh-gl/go-vcr-sample/qiita\u0026quot; ) func Test_FetchUser(t *testing.T) { tests := []struct { testCase string id string wantLocation string }{ { testCase: \u0026quot;Qiitaからyyh-glのユーザ情報を取得できていること\u0026quot;, id: \u0026quot;yyh-gl\u0026quot;, wantLocation: \u0026quot;Tokyo, Japan\u0026quot;, }, } // ここ // go-vcr のレコーダを生成 // 通信内容は ../fixtures/qiita に保存される r, _ := recorder.New(\u0026quot;../fixtures/qiita\u0026quot;) defer r.Stop() customHTTPClient := \u0026amp;http.Client{ Transport: r, // ここ 重要！ } qiitaClient := qiita.NewClient(customHTTPClient) for _, tt := range tests { t.Run(tt.testCase, func(t *testing.T) { user := qiitaClient.FetchUser(tt.id) assert.Equal(t, tt.wantLocation, user.Location) }) } }  以上で終了です。\nこの状態で $ go test ./... してみると、\n$ go test ./... ? github.com/yyh-gl/go-vcr-sample\t[no test files] ok github.com/yyh-gl/go-vcr-sample/qiita\t0.472s  普通にテストが通りますね。\nでは、この状態で、ネットワーク（WiFi）を切って、再度テストしてみます。\n$ go test ./... ? github.com/yyh-gl/go-vcr-sample\t[no test files] ok github.com/yyh-gl/go-vcr-sample/qiita\t0.014s  成功しました。\n\u0026ldquo;保存された通信内容\u0026quot;を見ているので、ネットワークに繋がっていなくても、テストが通ります。\n（\u0026ldquo;保存された通信内容\u0026quot;がどこにあるかは後で説明します）\nつまり、モック化できてしまっているのです！\nしかも、実行時間が短くなっていますね！これはでかい。\nでは、\u0026ldquo;保存された通信内容\u0026quot;を消して、再度テストしてみましょう。\n$ go test ./... ? github.com/yyh-gl/go-vcr-sample\t[no test files] panic: runtime error: invalid memory address or nil pointer dereference [recovered] panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x40 pc=0x12aef8d] goroutine 21 [running]: testing.tRunner.func1(0xc0000fe200) /Users/yyh-gl/.anyenv/envs/goenv/versions/1.13.4/src/testing/testing.go:874 +0x3a3 panic(0x1343900, 0x1642f80) /Users/yyh-gl/.anyenv/envs/goenv/versions/1.13.4/src/runtime/panic.go:679 +0x1b2 github.com/yyh-gl/go-vcr-sample/qiita.Client.FetchUser(0xc00008b2c0, 0x13a96ac, 0x6, 0x104fe28) /Users/yyh-gl/workspaces/Go/src/github.com/yyh-gl/go-vcr-sample/qiita/qiita.go:26 +0x10d github.com/yyh-gl/go-vcr-sample/qiita_test.Test_FetchUser.func1(0xc0000fe200) /Users/yyh-gl/workspaces/Go/src/github.com/yyh-gl/go-vcr-sample/qiita/qiita_test.go:37 +0x49 testing.tRunner(0xc0000fe200, 0xc0000a0540) /Users/yyh-gl/.anyenv/envs/goenv/versions/1.13.4/src/testing/testing.go:909 +0xc9 created by testing.(*T).Run /Users/yyh-gl/.anyenv/envs/goenv/versions/1.13.4/src/testing/testing.go:960 +0x350 FAIL\tgithub.com/yyh-gl/go-vcr-sample/qiita\t0.020s FAIL  エラーになりましたね。\nちゃんとエラーハンドリングしていないので、nil参照のエラーになっていますが、\nこれはネットワークに繋がっていない（＋\u0026quot;保存された通信内容\u0026quot;がない）ために、\n外部APIへのリクエストが失敗し、発生したエラーです。\n\u0026ldquo;保存された通信内容\u0026rdquo; では、さきほど go test を初めて実行したときに何が起こっていたのかを説明します。\nプロジェクト内を見てみると、\n$ tree go-vcr-sample go-vcr-sample ├── fixtures │ └── qiita.yaml ├── go.mod ├── go.sum ├── main.go └── qiita ├── qiita.go └── qiita_test.go  fixtures ディレクトリができています。\n中身を見てみると、\n$ ls fixtures qiita.yaml  qiita.yaml ができています。\n# /fixtures/qiita.yaml --- version: 1 interactions: - request: body: \u0026quot;\u0026quot; form: {} headers: {} url: https://qiita.com/api/v2/users/yyh-gl method: GET response: body: \u0026quot;{\\\u0026quot;description\\\u0026quot;:\\\u0026quot;東京でエンジニアしてます／CLI名刺 $ npx yyh-gl／メインは個人ブログです\\U0001F4DD\\\u0026quot;,\\\u0026quot;facebook_id\\\u0026quot;:\\\u0026quot;\\\u0026quot;,\\\u0026quot;followees_count\\\u0026quot;:19,\\\u0026quot;followers_count\\\u0026quot;:18,\\\u0026quot;github_login_name\\\u0026quot;:\\\u0026quot;yyh-gl\\\u0026quot;,\\\u0026quot;id\\\u0026quot;:\\\u0026quot;yyh-gl\\\u0026quot;,\\\u0026quot;items_count\\\u0026quot;:11,\\\u0026quot;linkedin_id\\\u0026quot;:\\\u0026quot;\\\u0026quot;,\\\u0026quot;location\\\u0026quot;:\\\u0026quot;Tokyo, Japan\\\u0026quot;,\\\u0026quot;name\\\u0026quot;:\\\u0026quot;\\\u0026quot;,\\\u0026quot;organization\\\u0026quot;:\\\u0026quot;\\\u0026quot;,\\\u0026quot;permanent_id\\\u0026quot;:119088,\\\u0026quot;profile_image_url\\\u0026quot;:\\\u0026quot;https://qiita-image-store.s3.amazonaws.com/0/119088/profile-images/1535528464\\\u0026quot;,\\\u0026quot;team_only\\\u0026quot;:false,\\\u0026quot;twitter_screen_name\\\u0026quot;:null,\\\u0026quot;website_url\\\u0026quot;:\\\u0026quot;https://yyh-gl.github.io/tech-blog/\\\u0026quot;}\u0026quot; headers: Cache-Control: - max-age=0, private, must-revalidate Content-Type: - application/json; charset=utf-8 Date: - Sat, 07 Dec 2019 07:27:05 GMT Etag: - W/\u0026quot;a6adaa36bf27d2045a25659539dcdae5\u0026quot; Rate-Limit: - \u0026quot;60\u0026quot; Rate-Remaining: - \u0026quot;56\u0026quot; Rate-Reset: - \u0026quot;1575706459\u0026quot; Referrer-Policy: - strict-origin-when-cross-origin Server: - nginx Strict-Transport-Security: - max-age=2592000 Vary: - Origin X-Content-Type-Options: - nosniff X-Download-Options: - noopen X-Frame-Options: - SAMEORIGIN X-Permitted-Cross-Domain-Policies: - none X-Request-Id: - f0ca74f0-4aae-4d0f-b6f9-ec08b0407b56 X-Runtime: - \u0026quot;0.082646\u0026quot; X-Xss-Protection: - 1; mode=block status: 200 OK code: 200 duration: \u0026quot;\u0026quot;  リクエストおよびレスポンスの内容が全て保存されています。\nこのように、go-vcr では、通信内容を傍受して、yaml 形式で保存します。\n（内容自体も、Web エンジニアならよく見かける単語ばかりなので読みやすいですね）\nそして、この yaml ファイルがあるときは、外部APIに対してリクエストを飛ばさずに、\nyaml ファイルの内容からレスポンスを返します。\nリクエスト済みかどうかの判断方法 ここで、go-vcr がどのようにして、\nリクエストを送ったことがあるかどうかを判定しているのか説明していきます。\n答えはこちら のコードにあります。\n// DefaultMatcher is used when a custom matcher is not defined // and compares only the method and URL. func DefaultMatcher(r *http.Request, i Request) bool { return r.Method == i.Method \u0026amp;\u0026amp; r.URL.String() == i.URL }   compares only the method and URL.\n デフォルトだと、HTTP メソッドとリクエストURL しか見てないんですね。\nしかし、この判定処理において、\nHTTP メソッドとリクエストURL以外も見るようにしたかったり、\n逆にこのURLへのリクエストだけは保存したくないといったニーズもあると思います。\nそこで 登場するのが Custom Request Matching です。\nCustom Request Matching README.md にもあるとおり、\nMatcher を作ってあげるだけで、簡単にオリジナルの判定処理を実装可能です。\nさきほどの README.md にあるサンプルを拝借して、\n僕のコード書き換えてみると以下のとおりになります。\n// /qiita/qiita_test.go package qiita_test import ( \u0026quot;bytes\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;github.com/dnaeon/go-vcr/cassette\u0026quot; \u0026quot;github.com/dnaeon/go-vcr/recorder\u0026quot; \u0026quot;github.com/stretchr/testify/assert\u0026quot; \u0026quot;github.com/yyh-gl/go-vcr-sample/qiita\u0026quot; ) func Test_FetchUser(t *testing.T) { tests := []struct { testCase string id string wantLocation string }{ { testCase: \u0026quot;Qiitaからyyh-glのユーザ情報を取得できていること\u0026quot;, id: \u0026quot;yyh-gl\u0026quot;, wantLocation: \u0026quot;Tokyo, Japan\u0026quot;, }, } // go-vcr のレコーダを生成 // 通信内容は ../fixtures/qiita に保存される r, _ := recorder.New(\u0026quot;../fixtures/qiita\u0026quot;) defer r.Stop() // ここ r.SetMatcher(func(r *http.Request, i cassette.Request) bool { if r.Body == nil { return cassette.DefaultMatcher(r, i) } var b bytes.Buffer if _, err := b.ReadFrom(r.Body); err != nil { return false } r.Body = ioutil.NopCloser(\u0026amp;b) return cassette.DefaultMatcher(r, i) \u0026amp;\u0026amp; (b.String() == \u0026quot;\u0026quot; || b.String() == i.Body) }) customHTTPClient := \u0026amp;http.Client{ Transport: r, } qiitaClient := qiita.NewClient(customHTTPClient) for _, tt := range tests { t.Run(tt.testCase, func(t *testing.T) { user := qiitaClient.FetchUser(tt.id) assert.Equal(t, tt.wantLocation, user.Location) }) } }  SetMatcher() 内の処理によって、判定ロジックを変更します。\nこの例だと、HTTP メソッドとリクエストURL に加えて、リクエストBody の内容も見るようになっています。\nこのように、SetMatcher() を定義してやるだけです。\n後はいつもどおり、http.Client の Transport に渡してやるだけなので簡単ですね👍\n保存内容を修正する必要が出たときはどうする？ yaml ファイルを消すだけです。\n例えば、外部APIの仕様が変わり、モックを更新する必要が出てきた場合は、\nyaml ファイルを消してやるだけで、次のAPIリクエストの内容を保存 =\u0026gt; つまり、モックを更新できます。\nもちろん yaml ファイルを直接変更することもできます。\nモックの管理が楽になりますね👍\nまとめ go-vcr を利用することで、外部API通信のモック化および管理が簡単にできるようになりました。\nしかも、モックの内容は、実際にリクエストして得た内容なので、\n仕様が漏れることもないでしょう。\nまた、今回は説明しませんでしたが、\ngo-vcr には Protecting Sensitive Data という機能もあり、\n指定したデータを保存しないようにするといったこともできます。\nカスタマイズ性が高く、とてもおすすめのライブラリです。\nもしモックの作成・管理で悩んでいる方がおられたら、\nぜひ一度検討してみてください！\nGo3 Advent Calendar 2019、明日は EbiEbiEvidence さんです🛫\n","ref":"/tech-blog/blog/golang-vcr/"},{"title":"【React+TypeScript】TypeScript入門","date":"","description":"TypeScript Advent Calendar 2019 2日目","body":"TypeScript Advent Calendar 2019 本記事は TypeScript Advent Calendar 2019 の 2 日目の記事です。\n内容としては、TypeScript 初級者のための TypeScript 入門です。\n基礎的な内容から入り、\n最終的には、企業や個人の技術ブログを参考に、\nReact の実プロジェクトにおいて、\nどのように TypeScript が使われているのか紹介できればと思います。\n（APIリクエスト周りのTypeScript活用事例を紹介）\n今日の記事を読んで TypeScript に入門し、\n今後の TypeScript Advent Calendar をお楽しみいただけると幸いです！\n基礎編 TypeScript とは TypeScript は Microsoft 社によって開発され、 現在は OSS として開発が進められています。\n「TypeScript とは何か」を簡単に説明すると、\nJavaScript に対して、省略も可能な静的型付けとクラスベースオブジェクト指向を加えたスーパーセット です。\n公式サイト はこちらで、\n2019年12月2日現在、最新版は 3.7.2 となっています。\nでは、実際にコードを交えながら基礎的な部分を説明していきます。\nただし、実践編で使用する内容に絞って説明していきますので、\nその点はご了承ください🙇‍\n（足りない情報は公式ドキュメント を参考にしてください）\n型 では、早速、TypeScript の型に触れていきましょう。\nTypeScript で使用できる基本的な型として以下のものがあります。\n Boolean Number String Array Tuple Enum Any Void Null and Undefined Never Object  だいたいの型は他言語でも用意されているので、\n説明がなくても理解できると思います。\nTuple や Never といった、他言語では見慣れない型もあると思いますが、\n他サイトでたくさん説明されているので割愛します。\n【参考サイト】\n 公式サイト  Qiita記事   型の宣言方法は以下のとおりです。\nfunction greeter(person: string) { return \u0026quot;Hello, \u0026quot; + person; } const user: string = \u0026quot;Jane User\u0026quot;; document.body.textContent = greeter(user);  1行目にて、greeter() に person という string 型の引数を渡すことが明示されています。\nまた、変数 user は string 型であることが明記されています。\n仮に greeter() に string 型以外の値を渡すと、\nコンパイル時 or IDE 上にエラーが吐かれるので、ミスに気づくことが可能です。\nインターフェース 次にインターフェースについて見ていきます。\nインターフェースは本来、JavaScript に無い機能ですが、\nTypeScript によってその機能が追加されています。\nインターフェースは、クラスやオブジェクトの規格を定義するのに使用します。\nクラスだけでなく、オブジェクトの規格を定義できるため、\nAPI のレスポンスとして返ってくるデータ（＝オブジェクト）の規格を定義することが可能です。\n有用性の高い機能のひとつではないでしょうか。\n定義方法は以下のとおりです。\ninterface LabeledValue { label: string; } function printLabel(labeledObj: LabeledValue) { console.log(labeledObj.label); } let myObj = {size: 10, label: \u0026quot;Size 10 Object\u0026quot;}; printLabel(myObj);  上記コードは、LabeledValue というインターフェースと、\nそのインターフェースを満たす myObj というオブジェクトを定義しています。\n加えて、printLabel() という LabeledValue インターフェースを受け取る関数が用意されています。\nmyObj は label を持っているので、LabeledValue インターフェースを満たしており、\nprintLabel() に引数として渡すことが可能です。\nクラスの規格定義としてのインターフェースは以下のとおりです。\nこちらは他言語でよく見る形なので詳細な説明は省略します。\ninterface ClockInterface { currentTime: Date; setTime(d: Date): void; } class Clock implements ClockInterface { currentTime: Date = new Date(); setTime(d: Date) { this.currentTime = d; } constructor(h: number, m: number) { } }  なお、クラスという概念は JavaScript（ES6） に組み込まれているクラスの機能を\nES6 以前の JavaScript でも使えるようにしたものです。\n入門時の落とし穴 僕が TypeScript を初めて触ったときに戸惑ったのが以下のエラーでした。\nCould not find a declaration file for module 'react-router-config'. '/hoge/index.js' implicitly has an 'any' type. Try `npm install @types/react-router-config` if it exists or add a new declaration (.d.ts) file containing `declare module 'react-router-config';` TS7016 1 | import React from 'react'; \u0026gt; 2 | import { renderRoutes, RouteConfigComponentProps } from 'react-router-config'; | ^ 3 | import './App.css'; 4 | 5 | const App: React.FC\u0026lt;RouteConfigComponentProps\u0026gt; = ({ route }) =\u0026gt; {  このエラーが何を言っているかと言うと、\n「ライブラリで使用する関数や変数に関する型宣言情報がないから、どう解釈したらいいか分からん！」\nってことです。\nライブラリは TypeScript のためではなく、JavaScript のためのものなので、\nインポートしたライブラリの中には、TypeScript 対応していないものがあるのは当然ですよね。\nでは、どうするかですが、\n@types を使ってやればOKです。\n@types @types を使用することで、提供されている型定義ファイルを取得することができます。\n本サイト によると、\nJavaScriptライブラリの90%に対応しているんだとか。\nすごすぎる。。。\n例えば、さきほどのエラーに対応する場合は、\nnpm install @types/react-router-config を実行してやることで、\nreact-router-config ライブラリの型に関する定義を取得できます。\n型定義ファイル もし型定義ファイルが提供されていない場合は、 自分で型定義ファイルを作る必要があります。 作るときは本サイト が参考になると思います。\n（こんな技 もあるようですが…）\n実践編 では、（かなりざっくりと）基本的なことはお話したので、\n実践的な内容に入っていきます。\n今回は、React + TypeScript を使用します。\nソースはGitHub 上にあげています。\nReact ＋ TypeScript 環境のセットアップ React ＋ TypeScript の開発環境は下記コマンドひとつで揃います。\n$ npx create-react-app my-app --typescript\nここから、src配下のディレクトリ構成を少し変更していきます。\n今回は下記のようなディレクトリ構成を取りました。\nWebのフロントエンド開発においてよく見られる形ではないでしょうか？\n$ tree react-typescript-sample react-typescript-sample ├── package-lock.json ├── package.json ├── public ├── src │ ├── App.css │ ├── App.test.tsx │ ├── App.tsx │ ├── api │ │ ├── client.ts │ │ └── user.ts │ ├── components │ ├── index.css │ ├── index.tsx │ ├── layouts │ ├── models │ │ └── user.ts │ ├── pages │ │ └── users.tsx │ ├── react-app-env.d.ts │ ├── router │ │ └── index.tsx │ └── serviceWorker.ts ├── tsconfig.json └── yarn.lock  なお、今回は説明しやすくするために、\ncomponents および layouts は使用していません。\n本来であれば、pages は components 配下のコンポーネントを組み合わせることにより表現します。\ncomponents 配下は、Atomic Design に沿ったディレクトリ構成が取られることが多い気がします。\nまた、ページのレイアウト（ヘッダーやフッター、メインコンテンツの位置など）は、\nlayouts 配下のコンポーネントによって表現します。\nAPI リクエスト 最近のフロントエンドでは、\nフロントから API リクエストを行うシーンが多くあると思います。\nそのさいに、API のレスポンスが\nどういったフィールドを持っているのかが定義されていれば、\n以下のようなメリットがあります。\n レスポンス内容がフロントのコードから読み取れる  存在しないパラメータにアクセスしようとするといった凡ミスを無くせる   IDE による補完が効く  では、実際にどうやって API のレスポンスを定義するのか見ていきます。\n今回は、例としてユーザ情報を受け取る API を用意しました。 下記のような JSON を取得します。\nGET https://localhost:3000/api/v1/users [ { \u0026quot;id\u0026quot;: 1, \u0026quot;first_name\u0026quot;: \u0026quot;信長\u0026quot;, \u0026quot;last_name\u0026quot;: \u0026quot;織田\u0026quot; }, { \u0026quot;id\u0026quot;: 2, \u0026quot;first_name\u0026quot;: \u0026quot;秀吉\u0026quot;, \u0026quot;last_name\u0026quot;: \u0026quot;豊臣\u0026quot; }, { \u0026quot;id\u0026quot;: 3, \u0026quot;first_name\u0026quot;: \u0026quot;光秀\u0026quot;, \u0026quot;last_name\u0026quot;: \u0026quot;明智\u0026quot; } ]  1. interface を定義 まずは、ユーザ情報がどういった形式で送られてくるのか、\ninterfaceを使って表現します。\n// /src/models/user.ts export interface User { id: number; firstName: string; lastName: string; }  2. API クライアントを実装 次は API リクエストを送る Axios クライアントを作っていきます。\n// /src/api/client.js import axios, { AxiosInstance, AxiosResponse } from 'axios'; import camelCaseKeys from 'camelcase-keys'; let client: AxiosInstance; export default client = axios.create({ baseURL: `http://localhost:3000/api/v1`, headers: { 'Content-Type': 'application/json', } }); client.interceptors.response.use( (response: AxiosResponse): AxiosResponse =\u0026gt; { const data = camelCaseKeys(response.data); return { ...response.data, data }; } );  ここで注目すべき点が2つあります。\n1つ目は、Axios をインポートするさいに型情報も合わせて取得している点です。\n3行目にて、axios 以外に AxiosInstance と AxiosResponse を取得しています。\nこの AxiosInstance と AxiosResponse こそが Axios ライブラリで使用する型情報です。\nそれぞれ 6行目 と 16行目 で使用しています。\n2つ目は、camelcase-keys というライブラリを使用している点です。\nJavaScript のコーディング規約では、変数名にキャメルケースを使用します。\nしかしながら、 JSON のキー名は多くの場合でスネークケースです。\nつまり、普通に JSON を受け取ると、\nresposen.first_name のようにしてデータを取り出します。\nしかし、これでは JavaScript の命名規則的に気持ち悪いですね。\n加えて、User モデル（interface）は firstName として定義しているため、\nfirst_name として受け取るのはよろしくありません。\nここで camelcase-keys ライブラリの登場です。\nスネークケースのキー名をキャメルケースに変換するためのもので、\n本ライブラリを用いて、受け取った JSON データのキー名を全てをキャメルケースに変換しています。\nTypeScript の話から少し脱線しましたが、\nこれで User インターフェースどおりのオブジェクトを受け取ることが可能になりました。\n3. ユーザ一覧取得 API リクエストを実装 では、さきほど実装した Axios クライアントを使って、\nAPI サーバにユーザ情報をもらうリクエストをします。\n// /src/api/user.ts import { AxiosPromise } from 'axios'; import client from './client'; import { User } from '../models/user'; export const fetchUsers = (): AxiosPromise\u0026lt;User[]\u0026gt; =\u0026gt; client.get(`/users`);  8行目にて、User[] を受け取ることを明示しています。\n4. ユーザ一覧を取得＆表示 では、受け取ったユーザ情報を表示してみます。\nなお、冒頭で説明したとおり、\n簡略化のために、表示に関する全実装を pages コンポーネント内で行います。\n// /src/pages/users.tsx import React, { useEffect, useState } from 'react'; import { fetchUsers } from '../api/user'; import { User } from '../models/user'; const Users: React.FC = () =\u0026gt; { const [userList, setUserList] = useState\u0026lt;User[] | undefined\u0026gt;(undefined); const fetchUsersReq = async () =\u0026gt; { try { const { data } = await fetchUsers(); return data; } catch (e) { console.log(e); } }; useEffect(() =\u0026gt; { const data = fetchUsersReq(); data.then(users =\u0026gt; { setUserList(users); }); }, []); return ( \u0026lt;\u0026gt; \u0026lt;h1\u0026gt;User List\u0026lt;/h1\u0026gt; { userList \u0026amp;\u0026amp; userList.map((user) =\u0026gt; { return ( \u0026lt;p key={user.id}\u0026gt;{`${user.lastName} ${user.firstName}`}\u0026lt;/p\u0026gt; \u0026lt;!-- ポイント3 --\u0026gt; ); }) } \u0026lt;/\u0026gt; ); }; export default Users;  まず初めに登場する型は、React.FC（8行目）です。\nこの型は React Functional Component を意味します。\n次に登場するのは、9行目の useState\u0026lt;User[] | undefined\u0026gt; ですね。\nこの定義は、userList の型が User[] または undefined であることを示します。\nあとは、useEffect() でさきほど実装した API リクエストを行い、\n取得したユーザ情報を userList にセットしています。\nこのとき、33行目のユーザ情報表示処理では、\nUser インターフェースを定義しているため、\nIDE において、どういったキーが存在するかが補完候補として出てきます！ ↓\n型がちゃんと定義されているので、\n取得したデータに対して、どういった処理ができる（どのメソッドを適用できる）かが明確になり、\n凡ミスを減らすことができますし、コードの可読性向上にも繋がります。\nいいですね！\n実践編は以上です。\nAPI リクエスト部分だけかよというツッコミはどうかご勘弁を😇\n最後に TypeScript を使う上での注意点と最新版で追加された機能を少し紹介して終わりにしたいと思います。\nTypeScriptを使う上での注意点 TypeScript の型情報はなくなる TypeScript で型を定義していたとしても、最終的にそのコードは JavaScript に変換されます。\nご存知のとおり、JavaScript には型などありません。\nしたがって、実際に動くコードには型情報はついていません。\nあくまで開発段階で型の整合性チェックや補完などができるだけであること、\nちゃんと理解しておくことが、とても重要だと思います。\ncreate-react-app では使えない機能がある create-react-app の最新版 3.2.0 では、\nTypeScript 3.7 から使用できる一部機能にまだ対応していません。\n本内容については、次章にて詳細に話します。\n最新安定版 3.7 で追加された機能 2019年11月7日にメジャーアップデートが行われ、バージョン 3.7 がリリースされました。\n今回は以下の新機能をついて紹介します。\nOptional Chaining  Kotlin を書いたことがある人は、見覚えのある文法ではないでしょうか？\nlet x = foo?.bar.baz();  このように書けば、foo が null または undefined じゃない場合にのみ foo.bar.baz() を実行します。\n下記のコードと同義です。\nlet x = (foo === null || foo === undefined) ? undefined : foo.bar.baz();  ここで、さきほど、最新版の create-react-app では 最新版 TypeScript の一部機能が使えないと言いましたが、\nその機能がこの Optional Chaining です。\n本機能を使用しようとすると、\n./src/pages/users.tsx SyntaxError: /Users/yyh-gl/workspaces/React/react-typescript-sample/src/pages/users.tsx: Support for the experimental syntax 'optionalChaining' isn't currently enabled (29:25): 27 | \u0026lt;h1\u0026gt;User List\u0026lt;/h1\u0026gt; 28 | { \u0026gt; 29 | userList?.map((user) =\u0026gt; { | ^ 30 | return ( 31 | \u0026lt;p\u0026gt;{user.firstName}\u0026lt;/p\u0026gt; 32 | ); Add @babel/plugin-proposal-optional-chaining (https://git.io/vb4Sk) to the 'plugins' section of your Babel config to enable transformation.  このようにエラーが出て、\nBabel（TypeScript を JavaScript に変換するやつ）の設定ファイルに @babel/plugin-proposal-optional-chaining  を追加しろと言われます。\nしかしながら、現在、Babel の設定ファイルである .babelrc や babel.config.js に create-react-app（厳密には react-scripts）が対応しておらず、読み込むことができません。\n本件については、すでに Issue が出されて、PRもマージ済みということなので、\n今後のリリースに期待ですね。。。\n参考サイト なお、Optional Chaining は本家 JavaScript にも組み込まれる予定です！\nTypeScript は、JavaScript の Class のように、\nJavaScriptのバージョンを上げないと使えない機能を\nライブラリレベルで使えるようにしてくれるのでいいですね👍\nNullish Coalescing  Nullish Coalescing をコードで表すと下記のようになります。\nlet x = foo ?? bar();  foo が null または undefined でなければ、 foo が代入されます。\nnull または undefined であれば、bar() が実行されます。\n下記のコードと同義です。\nlet x = (foo !== null \u0026amp;\u0026amp; foo !== undefined) ? foo : bar();  コードの記述量が減っていいですね👍\nまとめ TypeScript 入門 いかがでしたでしょうか？\n詳細な説明を飛ばしたところもありましたが、\nTypeScript がどんな感じなのか、少しでも感じてもらえたならば幸いです。\nTypeScript は型に注目がいきがちですが、\n他にも様々な便利機能があるので、どんどん使い倒していきたいですね！\n明日からのアドベントカレンダー記事も楽しみです😃\nTypeScript Advent Calendar 2019、\n明日は kimromi さんの『FlowからTypeScriptに段階的に移行する 』です🛫\n","ref":"/tech-blog/blog/react_typescript_sample/"},{"title":"【DeNA.go #3】Go活用事例やパフォーマンスチューニングの話聞いてきた","date":"","description":"DeNAさん主催のGolang勉強会","body":"DeNA.go #3  connpass  ハッシュタグ：#DeNAgo   初参加です！\nビールとお弁当もらいました。\nそしてなんとなんと k8sの技術書をいただいちゃいました！！！\nもちろんステッカーもありましたよ👍\n1. [Go活用事例]安全運転支援サービスを支える運用サイト 登壇者：@suhirotaka さん オートモーティブ事業本部スマートドライビング部システム開発グループ\nスライド 主題 管理画面を Golang で作成\nRailsで作ってるものをGolangで作る理由  実証実験時はスピード重視でRails 本サービスはパフォーマンス重視でGolang  順次Golangに書き換えていく\nGolangのフレームワーク GolangのWAF（Web Application Framework）には\n フルスタック・MVC ミニマル・高速  の2種類がある\nこの辺の話は、僕の旧ブログ にもいろいろ書いているのでどうぞー\nDeNAではフルスタック・MVCを選択\nGolangにおけるフルスタックなWAF  Beego：採用！ Revel：開発が止まってきている Iris：プロジェクトの運用がうまくいっていないようだった  Beego  フルスタックのMVCフレームワーク ORMまでついてる セッション管理、ロガー、キャッシュなどのライブラリがいろいろついてるけど、全てモジュール化されていて、部分的に他のライブラリを使うことができる Railsライクなフレームワーク  Railsのbefore/after_actionに相当するものもある（Prepare(), Finish()）    ライブラリ 使用ライブラリはこちら こういうの教えてくれるのめっちゃ嬉しい\n ORM：GORM ロガー：logrus PDF生成：gopdf → 日本語もきれいにでるので最高にクール 画像生成：gg バーコード生成：Barcode  2. WebシステムのパフォーマンスとGo （写真撮り忘れた…）\n登壇者：（@karupanerura） ゲーム・エンターテインメント事業本部ゲーム事業部Publish統括部共通基盤部アライアンスシステムグループ\nスライド Webシステムにおけるパフォーマンスとは たくさんリクエスト処理できる かつ リソース消費が少ないのが システム全体で見たときの理想的なパフォーマンス\nパフォーマンスチューニングのいろいろ 詳しいチューニング方法はこちら この中で初めて知ったものをピックアップ↓\n◎ Server Sent Events  HTTPコネクションを持続させる WebSocketより扱いが簡単らしい  バファリングの諸注意 結局リソースを消費していることに違わないので、メモリ管理はちゃんとしないといけない\nQ\u0026amp;A Q. sync.Pool でメモリ効率は良いがメモリは消費していくとは？（該当スライドページ ）\nA. Poolが居続けるからメモリ消費するよって話\nQ. SetMaxOpenConnsの数ってどうやって決めるのがいい？\nA. DBへのコネクションがどれくらいかとかを可視化して、そのデータに基づいて大きすぎず、小さすぎずの数を探していく（最終的には手探り）\nQ. バッファリングの使い所\nA. バッファリングよりシャーディングで対応できることが多い シャーディングで対応した場合、アプリケーション（実装）がシンプルになる\n","ref":"/tech-blog/blog/denago_3/"},{"title":"【GitHub Actions】プライベートアクションを使ってみた","date":"","description":"HCLではなくてyml版です","body":"プライベートアクションとは GitHub Actions では、開発者がアクション（Lint やテストといったジョブなど）を作って、公開することができます。 この公開されたアクションは、世界中の人が使えるため、もちろん自分のプロジェクトに持ってきて使用できます。 この公開されたアクションのことを パブリックアクション といいます。\nパブリックアクションが溢れた世界を想像するだけでワクワクしますね👍 （野良 Docker イメージと同様に、ほいそれとは使えないでしょうが…）\n今回、とりあげるのはパブリックアクションの正反対にあるものです。 つまり、公開しない（できない）アクション ＝ プライベートアクション です。 プライベートアクションを使うための準備 ディレクトリ構成は以下のとおりです。\n.github ├── actions │ └── golang-test │ ├── Dockerfile │ ├── action.yml │ └── entrypoint.sh └── workflows └── golang.yml  /actions ディレクトリ配下に golang-test という、Lint とテストを実行するアクションを作ってみます。\n/workflow ディレクトリ配下には、golang 用のワークフロー定義ファイルを置いています。\nでは、次から各ファイルの定義を見ていきます。\nプライベートアクションの定義 # /actions/golang-test/action.yml name: 'Golang Lint and Test Action' description: 'Lint and Test for Golang' author: 'yyh-gl' runs: # Docker を使って実行することを宣言 using: 'docker' # 使用する Docker イメージを指定 image: 'Dockerfile'  アクションの定義は上記のとおりです。 公式ドキュメント を参考にしました。\naction.yml 内で使用している Dockerfile は以下のとおりです。\n# /actions/golang-test/Dockerfile FROM golang:1.12.5 LABEL \u0026quot;name\u0026quot;=\u0026quot;Golang workflow\u0026quot; \\ \u0026quot;maintainer\u0026quot;=\u0026quot;yyh-gl \u0026lt;yhonda.95.gl@gmail.com\u0026gt;\u0026quot; \\ \u0026quot;com.github.actions.icon\u0026quot;=\u0026quot;code\u0026quot; \\ \u0026quot;com.github.actions.color\u0026quot;=\u0026quot;green-dark\u0026quot; \\ \u0026quot;com.github.actions.name\u0026quot;=\u0026quot;golang　workflow\u0026quot; \\ \u0026quot;com.github.actions.description\u0026quot;=\u0026quot;This is an Action to run go and golangci-lint commands.\u0026quot; ENV LINT_VERSION=\u0026quot;v1.18.0\u0026quot; COPY entrypoint.sh /entrypoint.sh RUN curl -sfL https://install.goreleaser.com/github.com/golangci/golangci-lint.sh | sh -s -- -b $(go env GOPATH)/bin ${LINT_VERSION} \\ \u0026amp;\u0026amp; chmod +x /entrypoint.sh ENTRYPOINT [\u0026quot;/entrypoint.sh\u0026quot;]  Dockerfile 内で使用している entorypoint.sh は以下のとおりです。\n# /actions/golang-test/entrypoint.sh #!/bin/bash APP_DIR=\u0026quot;/go/src/github.com/${GITHUB_REPOSITORY}/\u0026quot; mkdir -p \u0026quot;${APP_DIR}\u0026quot; \u0026amp;\u0026amp; cp -r ./ \u0026quot;${APP_DIR}\u0026quot; \u0026amp;\u0026amp; cd \u0026quot;${APP_DIR}\u0026quot; export GO111MODULE=on go mod tidy go mod verify if [[ \u0026quot;$1\u0026quot; == \u0026quot;lint\u0026quot; ]]; then echo \u0026quot;############################\u0026quot; echo \u0026quot;# Running GolangCI-Lint... #\u0026quot; echo \u0026quot;############################\u0026quot; golangci-lint --version echo golangci-lint run --tests --disable-all --enable=goimports --enable=golint --enable=govet --enable=errcheck ./... fi  Dockerfile と entrypoint.sh はこちら を参考にしました。\nワークフローの定義 # /workflow/golang.yml # ワークフローの名前 name: Workflow for Golang # push をトリガーとしてワークフローを実行 on: [push] # ジョブを定義：ジョブは並列処理される（デフォルト動作） jobs: lint: name: Lint runs-on: ubuntu-latest # job の中にさらに細かい粒度で step が存在：step は job と違い上から順に実行される steps: - name: Checkout uses: actions/checkout@v1 - name: Lint uses: ./.github/actions/golang test: name: Test runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v1 - name: Test run: go test ./...  /workflows/golang.yml の中身を上記のとおりです。 今回は Lint と go test を並列で実行しています。\n重要ポイント：プライベートアクションとパブリックアクションでの設定差異 プライベートアクションを使用するときは チェックアウト が必須です！\n公式ドキュメントのサンプル を下記に示します。\nname: Greet Everyone # This workflow is triggered on pushes to the repository. on: [push] jobs: build: # Job name is Greeting name: Greeting # This job runs on Linux runs-on: ubuntu-latest steps: # This step uses GitHub's hello-world-javascript-action: https://github.com/actions/hello-world-javascript-action - name: Hello world uses: actions/hello-world-javascript-action@v1 with: who-to-greet: 'Mona the Octocat' id: hello # This step prints an output (time) from the previous step's action. - name: Echo the greeting's time run: echo 'The time was $｛｛ steps.hello.outputs.time ｝｝.'  14行目でパブリックアクションを使用しています。 パブリックアクション使用時は、アクションの本体（コード）がどこからでも取得可能な場所にあるのでチェックアウトが必要ありません。\nしかし、プライベートアクションは自分のプロジェクト内にアクションの本体があります。 したがって、チェックアウトして、プロジェクトのコードをアクション実行環境に持ってくる必要があります。\n重要ポイント：チェックアウト ここで、GitHub Actions ではどのようにしてチェックアウトするのか。ですが、 答えは パブリックアクションを使用する です。\nGitHub が公開している公式アクションの中に、actions/checkout があります。 これを使用します。\n僕のコードでいうと、 /workflow/golang.yml 内の 16 行目で使用しています。\n 「チェックアウト って何？」という方は、 actions/checkout の README の説明がとても分かりやすいと思います。\n This action checks out your repository to $GITHUB_WORKSPACE, so that your workflow can access the contents of your repository.\n（あなたのリポジトリ（コード）を $GITHUB_WORKSPACE に持ってきて、ワークフローがそのコードにアクセスできるようにする）\n ↑ これを実現するためのものです。\nプライベートアクションはネット上に公開されていないから、 手元にあるアクション本体（コード）を GtHub Actions の実行環境に持っていった というだけですね。\n ・\n・\n・\nワークフローを実行 後は push するだけです。\n実際、push してみると、 下記のとおり、ワークフローが実行されました🎉\nログを見ると、Dockerfile からアクションが組み立てられていることが、なんとなく読み取れると思います。\nまとめ パブリックアクションが実現する CI/CD まわりのエコシステムは、とてもワクワクしますね。 でも、やっぱり公開できないアクションもあると思います。\nそういったときにはプライベートアクションを活用していきましょう。\n【余談】 ワークフローについてもっと知りたい方は、 ぜひ公式ドキュメント を読んでみてください。\n日本語対応しています👍\n参考記事  Docker コンテナのアクションを作成する｜Docker公式ドキュメント  ワークフローを設定する｜Docker公式ドキュメント  GitHub Actionsのワークフロー構文｜Docker公式ドキュメント   ","ref":"/tech-blog/blog/github-actions-private-action/"},{"title":"【mercari.go #11】エラーハンドリング ＋ singleflight ＋ ISUCON ベンチマーカー【Golang】","date":"","description":"めちゃくちゃためになった","body":"mercari.go #11  connpass： リンク  ハッシュタグ： \u0026lt;code\u0026gt;#mercarigo\u0026lt;/code\u0026gt;   今回もお弁当とドリンクがありました！ありがたや\n[追記：2019年10月12日]\n[Mercari Engineering Blog](https://tech.mercari.com/entry/2019/10/11/160000) にて、本イベントの記事が公開されました。\n発表資料が載せてあります。ありがたや🙏 1. About error handling in Go 登壇者：jd さん（@JehandadKamal）\n資料 （正式に共有されたものでないので、発表の内容が少し異なります）\nErrors are values ”Errors are values ” という考え方。\nGolangでよくあるエラー処理パターン  エラーをラップしてより詳細な情報を付与する 専用構造体を作る スタックトレースを構成する  ”Error is your domain” Domain Error Struct を作成する。\ntype Error struct { Op Op Kind Kind Serverity zapcore.ErrorLevel Err error }   Op：Operation → 関数名とか Kind：エラー種別 → NotAvailable, NotFound といったもの Serverity：エラーレベル Err：エラー内容  上記のような構造体を作る理由 error を比較するときは、基本的に文字列の比較になるため取り回しが悪い → ”NotFound” という文字列を比較するとかとか\nDomain Error Struct を作れば Kind での比較などが可能になる。\n加えて、操作内容やエラー種別とか情報を付与できる。\nこれ大事！ Remember ”Error is your domain”\nエラーの分割方法 Twitterメモ 2. singleflight 登壇者：@nsega さん\nスライド singleflight   同じ処理が複数回実行される場合に、一回だけ実行して、その結果を使い回すというもの。 → キャッシュに似ていますが、違いは後述します。\n  BFF レイヤーで活躍 → マイクロサービスにおいて、複数のAPIにリクエストを投げて、レスポンスを集約するようなときに有効。\n  ここ にある3つの関数さえ押さえればOK。\n  singleflight のユースケース 初見だと、キャッシュとなにが違うのか分かりづらいと思います。 ここらへんを見ると singleflight のユースケースがわかってくると思います。\n singleflight で解決できること1  singleflight で解決できること2   Q\u0026amp;A Q. goroutine で使うのはどうでしょう？\nA.\nsingleflight は扱いが難しいので、呼び出し元がわからなくなると、デバッグが余計難しくなる。 よって、goroutine ではあまり使わない方が良さそう。 → 呼び出し元は明確な方が追跡しやすくていいと思う。\n3. ISUCON9予選のベンチマーカーについて（TBD） 登壇者：カタツイさん（@catatsuy）\n資料 上記資料が全てです！\nISUCON の裏側、つまりベンチマーカーを作った話です。\nこんなことを考えて作られているんだと知ることができ、 めちゃくちゃおもしろかったし、勉強になりました！\nぜひ、上記資料読んでみてください！\n","ref":"/tech-blog/blog/mercarigo_11/"},{"title":"React.memo について調べたのでメモを残しておく","date":"","description":"React Hooks 楽しい","body":"React.memo とは 公式ドキュメント を見ると、\n これは React.PureComponent に似ていますが、クラスではなく関数コンポーネント用です。\n とあります。\nつまり、 React.PureComponent を関数コンポーネントで実現するための手段らしいです。\nReact.PureComponent とは 公式ドキュメント を見ると、\n React.PureComponent は React.Component と似ています。 両者の違いは React.Component が shouldComponentUpdate() を実装していないことに対し、 React.PureComponent は props と state を浅く (shallow) 比較することでそれを実装していることです。\n とあります。\nshouldComponentUpdate() によって、どういった変更があれば再描画するかを定義するようです。\n追加でこの参考記事 を読んでみると、\n PureComonentはprops及びstateの変更を検出した場合のみレンダリングを行います。 Messageコンポーネントではmessage propsの変更を察知し、必要分の更新を行うようになります。\n とあります。\n自分で再描画条件を定義できるので、無駄な再描画を省くことができ、パフォーマンス向上を期待できるんですね。\n→ React.PureComponent を用いることでパフォーマンスを向上させることができるようです。\n（参考記事内にもあるとおり銀の弾丸ではないようですが…）\n浅い比較 とは  shouldComponentUpdate() は浅い比較によって変更検知を行う。\n とありましたが、浅い比較とはなんでしょうか。\n（shouldComponentUpdate() のデフォルトが浅い比較というだけで、オリジナルの比較方法を実装可能なようです）\nさきほどの参考記事 にて説明されていました。\n 浅い比較というのは、簡潔に述べるとオブジェクトの参照先が同じであれば等しいと見なすことです。\n 参照先しか見ていないので、中身は見ていないということですね。\n（このような実装なのは、React の思想として、props や state といったデータは immutable であるべきだとしているからだと思います）\nちなみに ミューテート（変更）せずに新しいオブジェクトを作るには下記のようにして、新しいオブジェクトを作って返してやればいいようです。（参考 ）\nObject.assign({}, prevState, {color: 'blue'});  React.memo 実践（していく予定） React.memo の使い方は\n 公式ドキュメント  他の方のブログ記事   上記を見ればだいたいわかりそうです。\n会社のプロジェクトに導入できそうなところあったら使ってみたいと思います💪\n","ref":"/tech-blog/blog/react_memo/"},{"title":"【Backend Engineer’s meetup】メルカリ社主催 バックエンダーのための Meetup イベント行ってきた","date":"","description":"実は2日連続でメルカリ行ってた","body":"Backend Engineer’s meetup ~マイクロサービスにおける認証認可基盤~  connpass  ハッシュタグ：#merpay_meetup   メルカリさん恒例のオリジナルドリンクもらいました\n1. マイクロサービスの内部通信における認証について 登壇者：@pospome さん\nスライド （日本語が消えてしまっていますが、ダウンロードしたら見れました）\n上記スライドの簡易メモ   アカウント管理とログイン処理はそれぞれのチームに任せている\n SubjectID という 全サービス共通のID に変換して扱う    メルカリでは、OIDCベースの認可の仕組みを採用\n RFCに書いてあるものと大差ないので、今回は マイクロサービスの内部通信における認証 について話す    全サービスは Gatwway を経由\n Gateway から Authority Service にくる    Authority Service を認証基盤チームが管理\n 外部からのリクエスト検証と内部通信用のトークンを生成している    内部トークンは毎リクエストごとに生成\n マイクロサービス間で使用されるトークンはリクエスト単位で同一    内部トークン用のSDKを提供\n Golangのみ対応 SDKを使うといろいろとよしなにしてくれる  クレームをいい感じに取得 SubjectID のパースとかをいい感じにしてくれる      マイクロサービスはバッチのためのエンドポイントをもつことがあるので、Gatewayによってユーザが直接叩くことがきない環境を作れるのはメリットとなる\n  2. パネルディスカッション 登壇者：\n Keigo Watanabe さん @kazegusuri @nerocrux @pospome  パネルディスカッションのはずがほとんど質疑で終わりましたｗ\n質疑は さきほどの 発表 に対するものが主でした。\nしたがって、以下、上記発表に関する質問と回答になります。\nQ. 第三パーティーにスコープを指定させるのではなく、外部スコープと内部スコープのマッピングを行ったのはなぜか A.\nユースケースベースでスコープを提供した方が第三パーティーの開発者がわかりやすい。\nリソースベースだとどれが必要なスコープなのかが分かりづらい。\n（yyh-gl 感想） AWSのポリシーがリソースベースだと思うんだけど、どのポリシーが必要か分かりづらいもんねー\nQ. JWT（内部トークン）の保持期間（消すタイミング、有効期限） A. 保存していない\nQ. Authority Serviceの可用性 A.\n処理自体は複雑ではないし、特に何か特別なことをやっているわけではない。\nマイクロサービスに対するリクエストのリトライ、タイムアウトとかはやっている。\nQ. サービス間のアクセス制御はどのようにやってるか？各サービスが送信元をチェックするのか？どのサービスが度のサービスにアクセスするかの制御はどうしてるのか？ A.\nどちらかというと認可の話だと思っている。まだやっていない。\nOriginを見て、どこまでの処理をマイクロサービスがやっていいかは決めている。\nQ. 不正監視はしている？ A. 内部トークンの有効期限が短いので、現状やっていない。\nQ. 外部スコープと内部スコープの管理が大変そう。マイクロサービスを分割したときとか。このテーブルの管理は（誰が）どうやっている？ A.\nまだ一部でしか使っていないので、管理が難しいフェーズではない。ただし、今後その必要性は感じているので、対策を考える必要あり。\nQ. 公開鍵の失効タイミングはどのようにしているか？スロット的な仕組みは入れているのか？ A.\n公開鍵と秘密鍵はN世代で管理している。\nメルペイでは Design Doc を作ってしっかりと議論してから開発を進めていくと決めている。\nQ. JWTトークンにクレーム含ませると長くなってくると思うけど、パフォーマンスとか大丈夫？ A.\n長くなることは懸念している。\nCWT(https://tools.ietf.org/html/rfc8392)(CBOR) とかで、バイナリ化したいと勝手に思っている。\nQ. ユーザーのアカウント認証は Authority Service でやっているか？ A. ログイン部分は特にやってない\nQ. 可用性について、性能面で意識したこと A.\nまず、前提としてメルカリはレイテンシについてはあんまり考えない方針。レイテンシはモノリシックにしたら早くなるに決まっているから。\nただ、共通基盤は全サービスが利用するから早くする必要がある。だからmemcachedとかでローカルで完結するようにしたりはしてる。\nQ. SDKの更新はどうやっている A. @here ですｗ 配布先に展開が必要… まさに今問題になっていますｗ\nQ. SDKの更新は サイドカー とか Istio でやらない？ A. 今後やっていきたいです\nQ. トークンの有効期限 A.\nものすごく短い。リフレッシュもできない。\n1リクエストが10分かかるわけもないという判断軸で期限を決めている。\nQ. 外部と内部のマッピングなどの手作業が必要になるところはどこがある A.\nSubjectID はアカウントの種類が増えると増やさないといけないが、アカウントの種類はそんなに増えないと思っているので、その都度増やす対応を取る。\n他にマスターデータも手作業が必要である。今はは手作業でやっていてしんどいので自動化していきたい。\nQ. あるサービスから他のサービスにバッチ処理することはあるか A.\nあります。バッチ処理のときも内部トークンを使う。\n内部トークンは Authority Service から生成する仕組みがある。\n（各サービスが秘密鍵をもっていて、それを使うと生成できる。その秘密鍵にスコープは現在ない。今後つけたい）\nQ. 外部スコープと内部スコープのマッピングにクライアント情報を足せば、各マイクロサービス間で認証する必要がなさそう。（＝Authority Serviceだけで認証が完結できそう） A.\n反対です。それは各マイクロサービスが絶対に安全であるという前提でやっているから。\n各Serviceが自分が受けていいものかを判断する。どんなリクエストが来るかはわからない。\nQ. 一番厳しいユースケースは？（今後認証基盤の大変そうなところ） A.\n内部トークンの寿命が短いので、pub/subといった非同期通信に対応できない。解決策はまだない。\nバッチ処理は各サービスが Authority Service にトークンを作りに行くようにしている。（それでしのいでいる）\n ここでようやくパネルディスカッションです。\n話題はひとつだけですがｗ\nQ. 苦労話 A.\n  @pospome さん\n内部通信における問題を考えるということがしんどい。\nPO的なこともやっているので、いろいろやらないといけなくてさらにしんどい。\n  @kazegusuri さん\nAuthority Service の複雑な考え方が社内に受け入れられるか不安だった。\nしかし、ちゃんと受け入れてもらえてよかったー。\n@pospome さんと @nerocrux さんがよくやってくれたおかげ。\n  @nerocrux さん\nフルタイムで手を動かせるエンジニアが4人だけでつらい。\n認可サーバのユースケースはよく変わるからつらい。\n  ","ref":"/tech-blog/blog/mercari_meetup_for_backend_engineers_1/"},{"title":"【Go同miniConf】Golangの勉強会に参加してきた話","date":"","description":"CyberAgent ＆ merpay 主催の Golang 勉強会","body":"概要 CyberAgent ＆ merpay が共催した Golang のイベント\n Connpass情報  ハッシュタグ：#godo_miniconf  （写真撮るの忘れた…）\n以下、発表まとめ\n1. マイクロサービスとMonoRepo  登壇者：江頭 宏亮さん（@_hiro511） 発表スライド   リポジトリ管理について WinTicket というサービス開発・運用中\n36個のマイクロサービスで動いている\n マルチリポジトリ：マイクロサービスごとにリポジトリが別れている モノリポジトリ：ひとつのリポジトリ。WinTicket ではこっち  モノリポジトリ  Google, FB, Tiwtter, Uberが採用 メリット  依存管理をシンプルにできる  マルチリポジトリの場合、複数のリポジトリに変更を加える必要があるし、変更を取り込むのが面倒 モノレポだとすべてのコードが一箇所にあるので変更が楽   一貫性のある変更  複数のサービスにまたがる変更においても、アトミックなコミットが可能   コードの共有と再利用が用意  common ディレクトリがあればできる   大きなリファクタリングが容易    ビルドとテストを効率良くしたいという モノリポジトリだと、ビルドとテストに時間がかかる ので、効率よくビルドとテストしたい\n Bazel（ベイゼル）：ビルド・テストツール  Go, Andoroid, iOSなど様々な言語に対応 Googleが使っている（Googleの自社ツールがOSS化） 必要箇所だけビルド・テストする  速い   スケーラブル 拡張可能  StarDarkという独自言語で設定定義   WinTicketではDockerビルドもこれ    Golang with Bazel  Bazel のインストール by brew WORKSPACEファイルの作成  外部の依存関係を記述   BUILDファイルを作成  ビルド方法を示したもの Gazzelを利用して自動生成可能    ディレクトリ構成例\n. ├BUILD.bazel ├WORKSPACE └cmd └main.go  Gazzelは Go Modules と dep に対応 go.mod, Gopkg.lockファイルから依存パッケージを取りこみWORKSPACEファイルに書き込んでくれる\nProtocol Buffer を Golang コンパイル可能 golang/protocolbufとgogoprotoに対応している\nビルドアウトプットをリモートにキャッシュできる  開発者やCIなどでビルドアウトプットを共有できる  全員が高速なビルド体験を得られる   キャッシュバックエンド  nginx google cloud storage などなど    Go Modules and Proxy Walkthrough  登壇者：キタローさん（@ktr_0731） 発表スライド   Go modules の特徴  リポジトリのモジュール化 セマンティックバージョニング go.modによる依存管理 go.sumによるチェックサムの管理  正しい（安全な）モジュールか確認できる    ★ Go 1.13 でもautoがデフォルトのまま\nただし、src内でもgo.modがあればonになるようになる\nGo Modules 有効時の go get の挙動  $GOPATH/src 配下にモジュールが配置されなくなる go.modとgo.sumが書き換わる go get -u=patch とするとパッチを当てられる  Go Modules 周辺ツール 追加資料  Module Index  パブリックに利用可能なモジュールをクエリ検索できる   Module Authentication  GOPATHに取得する go get は取得したモジュールを検証するすべがなかった go modules で検証が可能になった   Go checksum database（sumdb）  あらゆるモジュールのチェックサムを集約 モジュールの初回インストール時はチェックサムできないのを解決   Module Mirrors  モジュールのコードやチェックサムのキャッシュを行う 特定のサーバの可用性やレイテンシに影響されるのを防ぐ 一度キャッシュされたものは基本的に削除されないので注意  突然のリポジトリ削除に対処するため（ex. go-bindata）     Module Proxy  Go 1.13 から go modules はproxyからモジュールを取得しにいくようになる $GOPROCXY と $GOSUMDB で設定変更可能    Private Modules  github のプライベートリポジトリに proxy.golang.org はアクセスできない  セキュリティ的な問題からモジュール取得に失敗するとエラーとなる   $GONNOPROXY を使えば解決可能  Go 1.13 からは、デフォルトで (link: http://proxy.golang.org) proxy.golang.org 経由で依存を解決しにいく  プライベートリポジトリへのアクセスに失敗する 環境変数に GONOPROXY を設定して回避したらOK      パネルディスカッション 登壇者：\n  とのもりさん（@osamingo）メルカリ\n  江頭さん（@_hiro511）サイバー\n  たかなみさん（@storz）メルペイ\n  プロダクト関連の話 テスト  WinTicket  クリーンアーキテクチャなので全部tesableな（interface）作りを意識 gomockというライブラリを使っている codecov というカバレッジを可視化している  現在91%くらい   testifyのassertを使っている  アサーション使わない問題は認識した上で選択   どこが違うか知りたいときはgocmp を使っている   メルペイ  gomockを使ってモッキング codecov というカバレッジを可視化している assertを使わず、gocmpという構造体の比較を行っている  testifyコントリビュータに聞くと madrier\u0026hellip;? というライブラリをおすすめされた      ロギング  WinTicket  zapを使っている ログ収集はCloudLoggingを使っている  GCPのk8sを使っているから   アクセスログはビッグクエリに流している   メルペイ  zapを使っている datadogに全て流している  お金かかるのでログを残すものの取捨選択をし始めている   templateリポジトリがあってログとかの基盤系処理が容易されている アクセスログはビッグクエリに流している    repository/package戦略  WinTicket  kubernetesのリポジトリ構成を参考にしている  /pkg 配下にマイクロサービスごとにディレクトリが切られている  各マイクロサービスはクリーンアーキテクチャ 一般的なクリーンアーキテクチャ   /cmd 配下にマイクロサービスごとにmain.go と bin が入ってる     メルペイ  マイクロサービスごとにリポジトリを分けている ディレクトリ構成はマイクロサービス（チーム）ごとに別れている  主流はクリーンアーキテクチャ フラットにパッケージを切るのも主流  ドメインごとに切っている 人によってパッケージの切り方が異なってくるので、統一するために、最近はクリーンアーキテクチャを採用することが増えている        エディタ   WinTicket\n IntelliJ    メルペイ\n GoLand Vim Emacs    acme（russが使ってるやつ）はいないｗ\ngo modules は使っているか   WinTicket\n dep使用    メルペイ\n 昔ながらのやつはdep 最近のはmodules    エンジニアの育成について 育成どうしてます？   WinTicket\n ディベロッパーガイドラインを作っており、クリーンアーキテクチャとかについてかっちりとルールを決めている  プロジェクトにおける、クリーンアーキテクチャの各層ごとの役割が明文化されている   モノレポなので結構人によってズレがでないようなパッケージ構成になっている 指摘とかはみんながちゃんと言えるような環境づくりをしている（心理的安全性が高い環境）    メルペイ\n tentenさんのGopher道場で実力をつけていってる 明文化されているガイドラインはない  各マイクロサービスのリポジトリを見て盗むのが主流   アーキテクトチームがあり、マイクロサービスの基本的な考え方を指導している Design Doc を導入しており、他のチームからレビューしてもらえる環境を作っている    Webエンジニアの採用  メルペイ  技術試験のコードを自動採点する仕組みがある    新卒教育   サイバー\n 現場に入って学ぶ（OJT）    メルカリ\n tentenさんのGopher道場  （いいなぁ）      ","ref":"/tech-blog/blog/godo_miniconf/"},{"title":"【OAuth 2.0 / OIDC】アクセストークンとIDトークンの違い ＋ OIDC誕生の歴史","date":"","description":"","body":"はじめに Web API のセキュリティ周りについて調べていると、\n「OAuth 2.0」や「OpenID Connect」という単語をよく見かけると思います。\nさらに調べると、「アクセストークン」と「IDトークン」という単語に出会いました。\nしかし、この2つのトークンの違いについて、\nいまいち理解ができていなかったので、今回は両者の違いを調べてみました。\n加えて、トークンについて調べる中で、\nOpenID Connectが生まれた経緯も知ることができたのでメモしておきます。\n2つのトークンの違い アクセストークン と IDトークン、両者は役割が大きく異なります。\n アクセストークン：認可（リソースへのアクセスコントロール＝あるリソースへの権限（readやwriteなど）を持っているかどうか確認すること） IDトークン：認証（その人が誰かを確認すること）  名前のままでした。\n認可に使うためのいろいろな情報が詰まっているのがアクセストークンで、 認証に使うためのいろいろな情報が詰まっているのがIDトークンです。\nOpenID Connectが生まれた経緯 OAuth 2.0およびOpenID Connectについて調べていると、\n「OpenID Connect は OAuth 2.0 を拡張した仕様」であるという記述を見かけました。\nどうしてOpenID Connectが必要になったのか、\nこの辺の経緯について述べていきます。\nOAuth 2.0 は 認可 の仕組み まずは、OAuth 2.0について見ていきます。\nOAuth 2.0 は 認可 の仕組みであり、 認証 の仕組みではない\nのですが、実際にはOAuth 2.0を認証用途で使っているシステムは多く存在します。\nOAuth 2.0 で認証を行うことの問題点については、\nこちら の記事に詳しく書いてあります。\n上記記事より、OAuth 2.0 による認証の問題点は、\nクライアント（アプリケーション）側でトークンの正当性を確かめる術がない ことであるとわかります。\nなお、ここでいう「正当性」に関して補足しておくと、\n「正当なトークン」とは、クライントが受け取ったトークンがそのクライアントのために用意されたものであることを意味します。\nつまり、クライアント側でトークンの正当性を確かめる術がない＝クライアントが自身のためのトークンであることを検証する術がないという意味です。\n（トークンの改ざん検知うんぬんの話ではありませんのでご注意ください）\n 「OAuth 2.0 による認証の問題点」という言葉を使っていますが、先述のとおりOAuth 2.0は認可のための仕組みなので、厳密には「認証の問題」なんて存在しません。 説明しやすくするためにこういった言葉を使っています。\n クライアント側でトークンの正当性を確かめたい OAuth 2.0 による認証の問題は OpenID Connect に則ることで解決できます。\nでは、どうして OpenID Connect を使うと安全に認証できるようになるのでしょうか。\nキーとなるのは IDトークン に含まれる audクレーム です。\naudクレーム audクレーム は IDトークン に含まれるデータのひとつです。\n（「クレーム」はJSONにおける「キー」とほぼ同義だと思ってください）\nでは、この audクレーム がどういった情報を持っているかと言うと、\nそのトークンがどのクライアントのために発行されたものか という情報です。\nしたがって、audクレームを使用することで、\nクライアントは自身のためのトークンかどうか調べることが可能です。\nこの「クライアント側で audクレーム のチェックを行う」ことは仕様として決められています。（参考 ）\nこのような仕組み（ルール）があるから、\nOpenID ConnectでOAuth 2.0 による認証の問題を解決できるわけですね。なるほど\nまとめ  アクセストークンは認可、IDトークンは認証に使うもの 認証がしたいなら OpenID Connect を使いましょう  今回の内容は、自分が調べたことをだいぶざっくりメモした程度のものです。\n下記に参考記事を載せておくので、詳細はそちらを御覧ください。\n参考  OAuth 2.0 仕様  OpenID Connect 仕様  OAuth 2.0 \u0026#43; OpenID Connect のフルスクラッチ実装者が知見を語る（@TakahikoKawasaki さん）  IDトークンが分かれば OpenID Connect が分かる（@TakahikoKawasaki さん）  OAuth 2.0/OpenID Connectの2つのトークンの使いみち（@wadahiro さん）  単なる OAuth 2.0 を認証に使うと、車が通れるほどのどでかいセキュリティー・ホールができる（Nat Sakimura さん）   ","ref":"/tech-blog/blog/id_token_and_access_token/"},{"title":"【徒然なるままに】サービス発案における主観と客観のバランスについて","date":"","description":"サービス発案って難しい…","body":"研修での サービス発案 をやった 新卒研修で サービス発案 について学び、実際に\n 問題提議 ソリューション検討 サービスに落とし込む  など、チームで作業しました。\n（今回考えたサービスを、今後チームで開発していきます）\nそして、一日考えたサービスをターゲット層となる人たちに 「こんなサービスどうですか？あったら欲しいですか？」といったアンケートを行いました。 返ってきた答えは「欲しくない」 が過半数でした。\nそのとき僕たちは 正直、意気消沈しました。\nただ、こういう結果になった原因は明白でした。\nなぜかというと、この時、チーム内から多く出た声が\n「必死に考えたサービスだったのに」\n「絶対欲しいでしょこれ」\n「俺は欲しい」\nといった内容だったからです。\nハッカソンでもあるあるですよね。\n自分たちが考えたサービスに愛着が出てきて、客観性がなくなっている状態。\nそうです。僕たちは客観的になれていなかったんです。\nそれでもめげずに僕たちは動いた めそめそしていても仕方ないので、僕たちはアンケートを答えてくれた人に 話を聞きに行ってみることにしました。\nこの行動が大正解でした。\nチーム外の人の話を聞くと、どういったところがだめだったのかが見えてきました。\n加えて、 自分たちもサービスを客観視することができるようになり、\n他にもだめなところが見えてきました。\n\n後、意外だったのですが、自分たちが特にどこに力を入れていて、\nどういった解決方法を取ろうとしているのか、熱量を持って伝えると、\n相手方が理解して、共感・納得してくれることがありました。\nつまり… サービスを提案する上で、第一に大事なのは 客観性 だと感じました。\n自分たちがどれだけいいものだと思っても、\n他の人々がいらないと言ったら、そのサービスは世の中には受け入れられません。\nつまり、客観的に見る ＝ 世の人々がなにに課題を感じているのか調査し、\nソリューションを提供していくことが大事です。\nしかしながら、さきほど言ったとおり、\n 熱量を持って伝えると、相手方が理解して、共感・納得してくれることもありました。\n こういうケースもあります。\nこれは、多少主観的でも論理的に正しいことを熱量持って伝えることで、\n世の人々がまだ気づいていない課題に気づき、提案サービスの必要性を感じてもらえた瞬間だと思います。\nただ、相手にサービスの良さを気づいてもらうには、\nサービスに対する絶対的自信（主観）がないと難しいですよね。\nすなわち、主観 も大事ってことですね。\n主観と客観のバランスが難しい ここまでの内容をまとめると 僕は「サービス発案において、主観 と 客観 どちらも大事」という結論に落ちつきました。\nでも、主観と客観のバランスってめちゃくちゃ難しくないですか？\n主観的意見もある程度は受け入れてもらえるんです。\nそして、そこがそのサービスのユニークな機能になると思います。\nしかし、主観的意見が多くなりすぎると、誰にも求められないサービスができあがってしまう。\nいかに、この 主観 と 客観 を両立するのか。\nまだまだ サービス発案 について学ぶことは多いと感じました。\n徒然なるまま …すぎた 研修で感じたことを書きなぐっただけなので、\n論理的に破綻していることろ、一般論的に間違っているところ、多々あると思います。\nでも、今はとにかく思ったことを間違っていてもいいからアウトプットしておき、\n数年後見たときにどう感じるのか知りたいと思いました。だから、書きました。\n// TODO: 数年後の自分よ、続編記事をちゃんと書くように\n","ref":"/tech-blog/blog/my_thinking_about_planning/"},{"title":"【OGP】リンク先のサムネイル画像を表示できるようにした話","date":"","description":"OGP大事","body":"Twitter のリンクにサムネイル画像が表示されない このように Twitter でブログのリンクを載せても、サムネイルが表示されない。\nはてなブログをやっていたときは、何もしなくてもサムネイルが表示されていました。\nトップ画像をよしなにサムネイルにしてくれるのかなぁっと思っていましたが違ったんですね…。\nどうやったらサムネイル画像が表示されるか Twitter や Facebook などの SNS でタイトルやサムネイルといったWebページの情報を表示するには、\nOpen Graph Protocol（OGP） というものを設定する必要があります。\nOGP を設定するだけで、Twitter や Facebook でサムネイル付きのリンクを表示することができます。\nこちらのサイト で詳細が説明されています。\nOGP の設定 OGP の設定項目には以下のものがあります。\n og:title og:type og:url og:description og:image  これらを HTML に meta タグで埋め込めば OK です。\n\u0026lt;meta property=\u0026quot;og:title\u0026quot; content=\u0026quot;【Golang + レイヤアーキテクチャ】DDD を意識して Web API を実装してみる\u0026quot;\u0026gt; \u0026lt;meta property=\u0026quot;og:type\u0026quot; content=\u0026quot;article\u0026quot;\u0026gt; \u0026lt;meta property=\u0026quot;og:url\u0026quot; content=\u0026quot;https://yyh-gl.github.io/tech-blog/blog/go_web_api/\u0026quot;\u0026gt; \u0026lt;meta property=\u0026quot;og:description\u0026quot; content=\u0026quot;hoge\u0026quot;\u0026gt; \u0026lt;meta property=\u0026quot;og:image\u0026quot; content=\u0026quot;https://yyh-gl.github.io/tech-blog/img/tech-blog/2019/06/go_web_api/featured.png\u0026quot;\u0026gt;  こんな感じですね。\nこれを head タグ内に埋め込みます。\nただし、僕の場合、Hugo のテーマの方で、 og:image 以外は設定してくれていました。\nしたがって、今回は og:image を追加で設定しました。\nog:image の設定 下記のような og:image の設定を /themes/\u0026lt;your-theme-name\u0026gt;/layouts/partials/meta.html に追加しました。\n\u0026lt;meta property=\u0026quot;og:image\u0026quot; content=\u0026quot;｛｛ .Site.BaseURL ｝｝｛｛ if .Params.featured ｝｝img｛｛ .Page.Date.Format \u0026quot;2006/01\u0026quot; | relURL ｝｝/｛｛ .Params.featured ｝｝｛｛ else ｝｝｛｛ .Site.Params.intro.ogp.src ｝｝｛｛ end ｝｝\u0026quot; /\u0026gt;  なにやら長たらしく定義していますが、やっていることをまとめると、\n featured画像（各記事ごとのサムネイル画像）が設定されていれば それを使用 featured画像が設定されていなければ、デフォルトの OGP 用画像を使用  以上のことをしています。\n【おまけ】toml による定数定義 og:image を定義するさいに .Site.Params.intro.ogp.src こんなのを使っています。\nこれは展開されると OGP 用画像のパスになるわけですが、そのパスをどうやって定義しているかというと…\n/\u0026lt;your-blog-root\u0026gt;/confi.toml に以下のように設定を記述すれば使えるようになります。\n[params.intro] header = \u0026quot;yyh-gl's Tech Blog\u0026quot; paragraph = \u0026quot;技術系ネタ中心のブログです。サーバサイドをメインとしたフルスタックエンジニアを目指しています。\u0026quot; rssIntro = true socialIntro = true \u0026lt; 一部省略 \u0026gt; [params.intro.ogp] src = \u0026quot;img/main/ogp_image.png\u0026quot; alt = \u0026quot;yyh-gl's image for OGP\u0026quot;  9 〜 11 行目が OGP 用のデフォルト画像を設定しているところです。\n結果 OGP が正しく設定できているかは 以下のサイトを使って確かめることが可能です。\n Card validator（Twitter）  シェアデバッガー（Facebook）   僕は Twitter にしか共有する気がなかったので、 Card validator を使用してデバッグしました。\nこんな感じで確かめることができます。\n最後に、Twitter 上でどのように表示されているか確認します。\n少しサイズがずれちゃっていますが、ちゃんと表示できていますね👍\n感想 はてなブログを見に行ってみたら、 OGP 用の設定がされていました。\n裏で設定してくれていたんですね。\nOGP という仕組みを知れてよかったです。\nリンクのサムネイル出るようになったで🤡https://t.co/OGXRRGonKc\n\u0026mdash; ｴﾝｼﾞﾆｱのﾎｹﾞさん 🌕 (@yyh_gl) 2019年6月16日  ","ref":"/tech-blog/blog/ogp/"},{"title":"【HTML + CSS + Prism.js】ブログの見た目を整えた話","date":"","description":"","body":"シンタックスハイライト導入 このブログ、ちょっと前までコードのシンタックスハイライトが効いていませんでした。\n正確には対応していない言語が（めちゃくちゃ）ありました。\nこのとおり、 Golang にも対応していませんでした…。\nもともと、このブログのテーマは Hugo Themes （Hugo 公式 テーマショップ的なの）に あったものを使わせてもらっているのですが、さすがに対応していない言語が多すぎたので、\nシンタックスハイライト部分だけ個別に導入することにしました。\nPrism.js さっそく、「HTML シンタックスハイライト」で調べてみました。\nそしたら、だいたい以下の3つが出てきました。\n Prism.js  highlight.js  Google code-prettify   どれにしようか迷ったのですが、見た目が一番好みだった Prism.js を使うことにしました。\n導入 導入方法については記事がたくさんあるので、そちらをご覧ください。\n 公式ダウンロードページ  導入 参考記事  導入 参考記事  導入 参考記事   導入後 きれいですねー\n今回導入した Prism.js のプラグインは、\n Line Highlight：行指定した箇所をハイライトする機能（上記画像内では使用していません） Line Numbers：行番号を表示する機能 Show Language：右上に 言語名 を表示している機能  の3つです。\n困ったこと 行番号が表示されない 行番号を表示するには、\n\u0026lt;pre class=\u0026quot;line-numbers\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;language-c\u0026quot;\u0026gt; コード \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;  上記コードのように、表示するコードスニペットに対して、\nline-numbers というクラスを付与してあげるだけでOKです。\n…が、なぜか行番号が他の要素の下にいってしまい、見えなくなっていました。\nしたがって、prism.css を修正して行番号が他の要素の上に来るようにしました。\nリスト表示の行間が異様に広い Prism.js 導入後…\nこのようになぜか リスト表示（箇条書き）の行間が異様に広くなり、文字が折り返されずはみ出ています。\nまさかと思い、prism.css を無効にすると…\n直った！\nということで、なにかしらのスタイルが悪さをしている模様。\nしかし、これは僕が手抜きで、\n\u0026lt;pre class=\u0026quot;line-numbers\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;language-c\u0026quot;\u0026gt; コード \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;  のコードを、コードスニペット部分だけじゃなく、記事全体に対して適用していたため発生していました。\n（手抜いて本当にごめんなさい。悪気はなかったんです。）\nしかしながら、記事のコンテンツに関する HTML は Hugo が自動生成してくれるため、\n中身をさわることができない模様…。\nどうしようと困っているときに、こちら の記事を発見。\nこれで生成された HTML 内の要素を置換できます。\n最終的には、 content-single.html を以下のとおり修正しました。\n\u0026lt;article class=\u0026quot;post\u0026quot;\u0026gt; ｛｛ .Render \u0026quot;header\u0026quot; ｝｝ \u0026lt;section id=\u0026quot;social-share\u0026quot;\u0026gt; ｛｛ partial \u0026quot;share-buttons\u0026quot; . ｝｝ \u0026lt;/section\u0026gt; ｛｛ .Render \u0026quot;featured\u0026quot; ｝｝ \u0026lt;div class=\u0026quot;content\u0026quot;\u0026gt; ｛｛ .Content | replaceRE \u0026quot;\u0026lt;pre\u0026gt;\u0026quot; \u0026quot;\u0026lt;pre class=\\\u0026quot;line-numbers\\\u0026quot;\u0026gt;\u0026quot; | safeHTML ｝｝ \u0026lt;/div\u0026gt; \u0026lt;footer\u0026gt; ｛｛ .Render \u0026quot;stats\u0026quot; ｝｝ \u0026lt;/footer\u0026gt; \u0026lt;/article\u0026gt;  修正したのは 8行目部分です。\n｛｛ .Content ｝｝  だけだった部分を\n｛｛ .Content | replaceRE \u0026quot;\u0026lt;pre\u0026gt;\u0026quot; \u0026quot;\u0026lt;pre class=\\\u0026quot;line-numbers\\\u0026quot;\u0026gt;\u0026quot; | safeHTML ｝｝  こうすることで、 コードスニペット部分だけに line-numbers を適用することができました。\n行間もシンタックスハイライト\u0026amp;行番号 もいい具合に表示できています。\nまとめ Prism.js いいですね！\nフロントに疎い僕でも簡単にシンタックスハイライト対応ができました。\nフロントの勉強もどんどんやっていきます。\n","ref":"/tech-blog/blog/blog_style_fix/"},{"title":"【mercari.go #8】メルカリの Golang に関する勉強会メモ","date":"","description":"","body":"mercari.go #8  connpass： リンク  ハッシュタグ： \u0026lt;code\u0026gt;#mercarigo\u0026lt;/code\u0026gt;  独自ルール： 懇親会のGルール 懇親会のときに登壇者を囲んでもいいけど、自分たち以外にもう一人入ってこれるスペースを常に開けておこうねっていうルール。とてもよい！ 雰囲気  ビール以外にもおいしそうなご飯もありましたが、写真を撮るの忘れ…\n以降、自分用のメモを書き連ねます。\n詳細はスライドの方をご覧ください。\n1. Goで学ぶKnative 登壇者： @toshi0607 さん\nスライドリンク Knative   Knative ＝ 最新のサーバーレス ワークロードをビルド、デプロイ、管理できる Kubernetes ベースのプラットフォーム  AWS の Lmabda に近いことを k8s 上でできると解釈   登壇者含め、会場内で Knative を本番に導入している人はなし。\nまだ時期尚早っぽい k8s のリソースを抽象化し、独自のPaaS/FaaSを構築するためのパーツを提供 k8s 上にのっかる。 Knative の構成  Serving  Build  Eventing    現状、一部、Istio に依存してしまっているので、Istioの導入が必要不可欠 登壇者は 機能実装に一層集中するための基盤 として注目している yml ファイルで定義した内容に基づいて コード生成  感想 終盤、 Knative の内部処理を コードリーディング していたのですが、\n見入ってしまいメモを忘れていました。。。\nKnative 初めて聞いたのですが、おもしろそうだなという感想。\nk8s の勉強しないとな。\n2. Gotham GoとGopherCon EUに参加してきました 登壇者： @tenntenn\nスライドリンク  技術をアウトプットするところに人は集まる メルペイ エキスパートチーム では 50%以上の時間 をコミュニティへの貢献に充てている 海外カンファレンスに参加する理由  最新の技術を知る 世界各地のエンジニアとの交流    Gotham Go  ニューヨークで毎年開かれている Go カンファレンス 1トラック 200名くらいが参加する（そんなに大規模ではない） ハンズオンがあった  パックマン（ゲーム）作った（github ） 絵文字で動くらしい step by step で初心者におすすめ   自作楽器 を Go から操作する スライスをプール（再利用）する方法  leachsync を使う方法が良さそうという結論   セッションのレベルは 日本の Go Conference と同等  ただし、 現地に Goチーム がいるので登壇者が豪華   突然ビンゴ大会が始まったりする  GopherCon EU  ヨーロッパで毎年開催されている  ヨーロッパ中から Gopher が集まる   参加者は200名くらい 2トラックで大きめ ダイバーシティスカラーシップがあり、費用の補助が出る（一部） リーダビリティに関するセッション  width が大きいスパゲッティコード と dipth が大きい行き過ぎた抽象化 どちらもそれぞれいやなことがある。この間ぐらいがいいよねーって話。   GoTrace： Go Routine を可視化するライブラリ → 参考記事リンク  IDE でコードを読むなんて、 洞窟でたいまつをもって壁画に書かれた文字を読むようなもの。 可視化しましょう！   現在使用では、 map に range を使うとキーがランダムに並ぶ ので、それを使ってLT大会の発表順を決めた  感想  メルペイ エキスパートチーム では 50%以上の時間 をコミュニティへの貢献に充てている  これすごくないですか？\n多くのつよつよエンジニアが集まるのも納得です。\n海外のカンファレンスのノリがおもしろそうでした。\n発表にかける気合がすごい笑\nぜひ、一度行ってみたいです。\n3. Go + WebAssemblyを活用する 登壇者： @__syumai\n メルペイのバックエンドエンジニア Go Playground にタブを追加する chrome拡張を作った人  スライドリンク Go WebAssembly（wasm ワズム）  experimental の機能 1.11 以上で使用可能 GOOS=js GOARCH=wasm でビルドすると .wasm ファイルが生成され、JavaScript から使用できる ≒ JavaScript から Golang を使用できるようになる クリックの動作を Golang で実装したりした select{} 使わないと main 関数が終了して JavaScriptから呼べなくなる（参考 ） つらみ  GOOS=js GOARCH=wasm でしかビルドできないので、テストができない  （解決策）テストしたい部分は別パッケージにエクスポートする。Goで実装するやつは main.go だけに依存するようにしたらいい。   DOM操作をGoでやった（JavaScript ならしゅっと書けるのに…）  （解決策）ビジネスロジック部分だけを Golang で実装するようにしないとつらい DOM操作は素直に JavaScript にお任せした方がいい      感想 JavaScript から Golang で実装した機能を使えるのはいろいろと便利そう。\n4. E2E Testing with \u0026lsquo;main\u0026rsquo; function 登壇者： @yuki.ito\n サンプルリポジトリ： https://github.com/110y/go-e2e-example 普通にテストしようとすると main 関数 がカバレッジに含まれないから、含まれるように努力する話  e2e で TestMain を起動し、go test . でトップレベルのコードをgoroutineで起動 Mainで起動されたサーバに対して TestMainから接続してリクエストを投げる TestMainで生成したクライアントから個々のテストを実行する。 mainのカバレッジも取れる。    感想 こういう工夫して問題解決する話大好きです。\nその手があったか。とただただ説明を聞き入ってました。\n全体まとめ メルカリ社の技術力の高さがとても分かる勉強会でした。\n中の人たちが積極的に外に出てキャッチアップをしている姿見習っていきたいと思います。\nまた参加したいなー\n","ref":"/tech-blog/blog/mercari_go/"},{"title":"【Golang + レイヤードアーキテクチャー】DDD を意識して Web API を実装してみる","date":"","description":"2019/10/30 に内容を一部更新しました","body":"更新（2019年10月30日） 初回投稿から3ヶ月経ちました。\nこの3ヶ月で新しく得た知見を基に、内容を一部アップデートしました。\n今回やること Golang のディレクトリ構成についていろいろと調べる中で、\nこちらの資料 がとても分かりやすかったので、\n今回はこちらを参考に Golang で Web API を作っていきたいと思います。\n加えて、本プロジェクトでは、DDD と レイヤードアーキテクチャー を取り入れます。\n（内容はほぼレイヤードアーキテクチャになってしまいましたが…）\nDDD については、「DDD を Golang とレイヤードアーキテクチャでやるなら、こんな感じかな？」という個人の見解レベルです。\nパッケージ構成の参考になれば幸いです。\n（ですので、ドメインモデルは重度のドメイン貧血症に陥っていますｗ）\n釣りタイトルみたいになっちゃっててすみません🧝‍♀️\n環境  MacOS Mojave 10.14.6 Golang 1.12.5  なお、今回は、Gin や Mux などといったフレームワークは使わず、\nhttprouter のみで薄く作っていこうと思います。\nMux を使った実装は 僕の前のブログで紹介している のでよければどうぞ。\n・ ・\n・\nでは、早速本題に入っていきましょう。\n採用アーキテクチャ：レイヤードアーキテクチャ 参考記事内 で紹介されているのは レイヤードアーキテクチャ をベースに いろいろカスタマイズされたものらしいです。\nクリーンアーキテクチャに似たアーキテクチャだとか。\n ユースケース層という呼び方はクリーンアーキテクチャ由来ですね。\nDDD の文脈だと アプリケーション層 と呼ばれますが、\nアプリケーションって意味が広くて分かりづらいので、\n本プロジェクトでは ユースケース という単語を使用します。\n とりあえず、今回はスライドページ19で紹介されているディレクトリ構成に従って、 DDD を意識して Web API を実装していこうと思います。\n（意識だけして、実践できずに終わりましたが😇）\nレイヤードアーキテクチャ における各層の依存関係 について説明します。\n依存関係の図は下記のとおりです。\n矢印は依存の方向を示しています。\n例えば、上図だと Handler層 は UseCase層 の処理を利用することを意味します。\n一般的なレイヤードアーキテクチャだと、上から下に一方向に依存します。\nしかし、今回は、Infra層が Domain層に依存しています。\nこのあたりはオニオンアーキテクチャーやクリーンアーキテクチャと同じやり方ですね。\nさきほどの図を視点を変えて見てみます。（下記の図）\n今回採用したアーキテクチャは、\nオニオンアーキテクチャーやクリーンアーキテクチャのように、\n依存が中心方向に のみ 向いていることがわかります。\nすべての依存が中心に向かっているこの状態が理想です。\n（Handler層と Infra層が一緒の層みたいになっていますが、全くの別物です。うまく分離して描けず、こうなりました。ご注意を）\n 依存関係について、もう少し述べておくと、\n基本的に依存はひとつ下の層までに抑えておくべきのようです。\nただし、簡略化のために2つ下の層まで依存している例もあるので、\nそこはチームとして同意が取れていれば良いのではないでしょうか。\n ここで、ユーザから APIリクエスト があった場合を考えてみます。\nユーザからのリクエストは Handler で受け取られ、 UseCase を使って処理が行われます。\nさらに、UseCase は Domain を使って処理を行います。\nここまでは処理が中心に進んでいる、つまり依存は中心に向かって発生しています。\nしかし、たいていのサービスって DB を使用しますよね。\nつまり、ユースケースからドメインを介して、Infra を利用することになります。\nUseCase → Domain → Infra\n…依存が外側を向いてしまいました。\nこれは許されていません。ではどうするか。\n依存性逆転の法則  を使います。\n依存性逆転の法則 とは、 interfaceを利用して、依存の方向を逆にすること です。\nもう少し詳しく説明します。\nまず、 ① Domain層 において、 DB とのやりとりを interface で定義しておきます。\ninterface （後ほどコード内にて BookRepository として出てきます） 自体は実装を持たないので、\nどこにも依存していません。\n次に、 ② Infra層 から Domain層 に定義した interface （後ほどコード内にて BookPersistence として出てきます） を実装します。\n①, ② の2ステップを踏むことで、まず Domain は interface に対して 処理をお願いするだけでよくなります。 先ほども言ったとおり interface は 実装を持たないので依存関係はありません。\ninterface 自体は実装を持ちませんが、\nInfra が interface の実装を行っているので、ちゃんとDBアクセスして処理を行うことができます。\nここで、 Infra は interface を実装しているので、依存が interface 、すなわち Domain に向いています。\n依存性が逆転し、すべての依存関係が中心に向かうようになりましたね。\nここはとっつきづらいところなので、まだいまいち理解できないかもしれません。\n以降、実際のコードを紹介していくので、コードに落とし込みながら考えてみてください。\n完成物 完成物に関しては こちら に置いておきます。\nAPI 一覧 書籍管理システム の API を想定\n 書籍一覧 取得 書籍詳細 取得 書籍 追加 書籍 貸出 書籍 返却  ディレクトリ構成はこんな感じです。\napi-server-with-go-kit-and-ddd ├── cmd │ └── api │ └── main.go // サーバ起動したり、依存注入、ルーティングを行う ├── domain │ └── blog.go ├── go.mod ├── go.sum ├── handler │ └── rest // RESTful API 用のハンドラー │ └── blog.go ├── infra │ └── blog.go └── usecase └── blog.go  書籍一覧を取得するAPIを作る Domain 層 まずは、/domain/model に書籍モデルを作っていきます。\nDomain層 はシステムが扱う業務領域に関するコードを置くところです。\nよって、「書籍」 がどういうものなのかモデルという形で定義します。\n/domain/model/book.go\npackage model import \u0026quot;time\u0026quot; // Book : Book を表すドメインモデル // !! 重度のドメイン貧血症です !! type Book struct { Id int64 Title string Author string IssuedAt time.Time }  冒頭でも述べたとおり、みごとなドメイン貧血症っぷりです。\nちゃんと 値オブジェクトを使ったりして、ごりごり DDD していきたいですが、今回は…省きます🙇‍♂️\n次に、/domain/repository/book.go を作っていきます。\n今回、 リポジトリでやることを簡単に言うと、 DB や KVS などで行う CRUD処理 の定義です。\nただし、Domain層には技術的関心事を持ち込まない というルールがあるため、\nここでは interface を定義するだけです。\n実装は、後述する infra で行います。\n（Infra層 は技術的関心事を扱う層です）\nリポジトリについてちゃんと知りたい方は、\nこちら が参考になると思います。\n/domain/repository/book.go\npackage repository import ( \u0026quot;context\u0026quot; \u0026quot;github.com/yyh-gl/go-api-server-by-ddd/domain/model\u0026quot; ) // BookRepository : Book における Repository のインターフェース // -\u0026gt; 依存性逆転の法則により infra 層は domain 層（本インターフェース）に依存 type BookRepository interface { GetAll(context.Context) ([]*model.Book, error) }  今は 全ての書籍を取得する関数 GetAll() のみ定義します。\nここで、はじめに示した 依存関係の図 を思い出してください。\n今定義した Domain層 は他の層のコードを一切利用していません。\nつまり、下図の赤枠の中で依存関係が完結しています。\nInfra 層 さきほど述べたとおり、Infra層 は技術的関心事を扱う層です。\nここでさっき定義した repository の処理を実装します。\n/infra/persistence/book.go\npackage persistence // repository という名前にしたいが domain 配下の repository とパッケージ名が被ってしまうため persistence で代替 import ( \u0026quot;context\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/yyh-gl/go-api-server-by-ddd/domain/model\u0026quot; \u0026quot;github.com/yyh-gl/go-api-server-by-ddd/domain/repository\u0026quot; ) type bookPersistence struct{} // NewBookPersistence : Book データに関する Persistence を生成 func NewBookPersistence() repository.BookRepository { return \u0026amp;bookPersistence{} } // GetAll : DB から Book データを全件取得（BookRepository インターフェースの GetAll() を実装したもの） // -\u0026gt; 本来は DB からデータを取得するが、簡略化のために省略（モックデータを返却） func (bp bookPersistence) GetAll(context.Context) ([]*model.Book, error) { book1 := model.Book{} book1.Id = 1 book1.Title = \u0026quot;DDDが分かる本\u0026quot; book1.Author = \u0026quot;たろうくん\u0026quot; book1.IssuedAt = time.Now().Add(-24 * time.Hour) book2 := model.Book{} book2.Id = 2 book2.Title = \u0026quot;レイヤードアーキテクチャが分かる本\u0026quot; book2.Author = \u0026quot;はなこさん\u0026quot; book2.IssuedAt = time.Now().Add(-24 * 7 * time.Hour) return []*model.Book{\u0026amp;book1, \u0026amp;book2}, nil }  なお、 実際には DB にアクセスし、データを持ってくるようにします。\nここでは一旦モックデータを返すようにしておきます。\nまた、Persistence という単語がいきなり出てきましたが、これは Repository と同義です。\n実際に NewBookPersistence() の中身を見ると Repository のインターフェースを返していると思います。\n（NewBookPersistence()の詳細は後述）\n本当は Repositoryという名前を使いたかったのですが、\nDomain層と Infra層 でパッケージ名が被ってしまうため、やむなくこうしています。\n先ほどと同様に 依存関係 を確認します。\nInfra層 は Domain層 で作った /domain/repository/book.go のインターフェース（BookRepository）を実装しています。\nここで、Golang に慣れていない方は、どこでインターフェースと関連づけてるの？\nという疑問が生まれると思います。\n答えは、 NewBookPersistence() です。\nこの関数の戻り値は インターフェース です。\nしたがって、17行目でreturnする bookPersistence がインターフェースを満たしていないとエラーとなります。\nこのようにして インターフェースを満たしているか否かを判別します。\nNewBookPersistence() をどこで使うかは後述します。\nでは、依存関係を見ていきます。\n上述したとおり、Infra層 は Domain層 のインターフェースを満たすように作られているので、Domain層に依存しています。\nGolang には implements とかないので分かりづらいですね。\nでも、確かに依存しています。\nUseCase 層 UseCase層 では、システムのユースケースを満たす処理の流れを実装します。\n今回は単純な処理しかしないので、この層の存在価値が少し分かりづらくなってしまいます。\n複雑なビジネスロジックがあるときは、この層の存在が効いてくると思います。\nコードは以下のとおりです。\n/usecase/book.go\npackage usecase import ( \u0026quot;context\u0026quot; \u0026quot;github.com/yyh-gl/go-api-server-by-ddd/domain/model\u0026quot; \u0026quot;github.com/yyh-gl/go-api-server-by-ddd/domain/repository\u0026quot; ) // BookUseCase : Book における UseCase のインターフェース type BookUseCase interface { GetAll(context.Context) ([]*model.Book, error) } type bookUseCase struct { bookRepository repository.BookRepository } // NewBookUseCase : Book データに関する UseCase を生成 func NewBookUseCase(br repository.BookRepository) BookUseCase { return \u0026amp;bookUseCase{ bookRepository: br, } } // GetAll : Book データを全件取得するためのユースケース // -\u0026gt; 本システムではあまりユースケース層の恩恵を受けれないが、もう少し大きなシステムになってくると、 // 「ドメインモデルの調節者」としての役割が見えてくる func (bu bookUseCase) GetAll(ctx context.Context) (books []*model.Book, err error) { // Persistence（Repository）を呼出 books, err = bu.bookRepository.GetAll(ctx) if err != nil { return nil, err } return books, nil }  UseCase層 の依存関係も見てみましょう。\nUseCase層 は /domain/repository を呼び出しています。\nしたがって、 UseCase層 は Domain層 に依存しています。\n参考にしている資料 では、\nUseCase層 をさらに input と output で切っていますが、複雑になりすぎると思い、省略しました。\nHandler 層 次に Handler層 です。\n本プロジェクトにおける、Handler層 の役目は、HTTPリクエストを受け取り、UseCase を使って処理を行い、結果を返す ことです。\nただし、本来の Handler層は HTTPリクエストに限った話ではありません。\n外部にあるものがなんであれ、その差異を吸収して、ユースケースに伝えるのが役目です。\nしたがって、HTTP通信以外でも対応できるように、本プロジェクトでは /handler/rest というふうにディレクトリを切っています。\n（RESTful API であることを明確にしてみました）\nCLIを追加するなら /handler/cli というふうにディレクトリを切ればOK。\n本プロジェクトのコード的には以下のようになります。\n/handler/blog.go\npackage rest // Handler 層を変えるだけで、例えば CLI にも簡単に対応可能 import ( \u0026quot;encoding/json\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/julienschmidt/httprouter\u0026quot; \u0026quot;github.com/yyh-gl/go-api-server-by-ddd/usecase\u0026quot; ) // BookHandler : Book における Handler のインターフェース type BookHandler interface { Index(http.ResponseWriter, *http.Request, httprouter.Params) } type bookHandler struct { bookUseCase usecase.BookUseCase } // NewBookUseCase : Book データに関する Handler を生成 func NewBookHandler(bu usecase.BookUseCase) BookHandler { return \u0026amp;bookHandler{ bookUseCase: bu, } } // BookIndex : GET /books -\u0026gt; Book データ一覧を返す func (bh bookHandler) Index(w http.ResponseWriter, r *http.Request, pr httprouter.Params) { // request : 本 API のリクエストパラメータ // -\u0026gt; こんな感じでリクエストも受け取れますが、今回は使いません type request struct { Begin uint `query:\u0026quot;begin\u0026quot;` Limit uint `query:\u0026quot;limit\u0026quot;` } // bookField : response 内で使用する Book を表す構造体 // -\u0026gt; ドメインモデルの Book に HTTP の関心事である JSON タグを付与したくないために Handler 層で用意 // 簡略化のために JSON タグを付与したドメインモデルを流用するプロジェクトもしばしば見かける type bookField struct { Id int64 `json:\u0026quot;id\u0026quot;` Title string `json:\u0026quot;title\u0026quot;` Author string `json:\u0026quot;author\u0026quot;` IssuedAt time.Time `json:\u0026quot;issued_at\u0026quot;` } // response : 本 API のレスポンス type response struct { Books []bookField `json:\u0026quot;books\u0026quot;` } ctx := r.Context() // ユースケースの呼出 books, err := bh.bookUseCase.GetAll(ctx) if err != nil { // TODO: エラーハンドリングをきちんとする http.Error(w, \u0026quot;Internal Server Error\u0026quot;, 500) return } // 取得したドメインモデルを response に変換 res := new(response) for _, book := range books { var bf bookField bf = bookField(*book) res.Books = append(res.Books, bf) } // クライアントにレスポンスを返却 w.Header().Set(\u0026quot;Content-Type\u0026quot;, \u0026quot;application/json\u0026quot;) if err = json.NewEncoder(w).Encode(res); err != nil { // TODO: エラーハンドリングをきちんとする http.Error(w, \u0026quot;Internal Server Error\u0026quot;, 500) return } }  依存関係は以下のとおりです。\n57行目で UseCase を使用するので、UseCase層に依存しています。\nmain.go ここまでで、書籍に関する Handler, UseCase, Repository が用意できました。\n最後に、main.go にて、これらの依存関係を定義してやることで、利用可能な状態にします。\n（DI とかはやってません🙏）\nこのとき利用するのが、各層に用意されている NewXxx() という関数です。\nNewXxx() を使用して、Handler や UseCase, Repository を生成し、メソッドを実行できるようにします。\n/cmd/api/main.go\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;github.com/julienschmidt/httprouter\u0026quot; handler \u0026quot;github.com/yyh-gl/go-api-server-by-ddd/handler/rest\u0026quot; \u0026quot;github.com/yyh-gl/go-api-server-by-ddd/infra/persistence\u0026quot; \u0026quot;github.com/yyh-gl/go-api-server-by-ddd/usecase\u0026quot; ) func main() { // 依存関係を注入（DI まではいきませんが一応注入っぽいことをしてる） // DI ライブラリを使えば、もっとスマートになるはず bookPersistence := persistence.NewBookPersistence() bookUseCase := usecase.NewBookUseCase(bookPersistence) bookHandler := handler.NewBookHandler(bookUseCase) // ルーティングの設定 router := httprouter.New() router.GET(\u0026quot;/api/v1/books\u0026quot;, bookHandler.Index) // サーバ起動 fmt.Println(\u0026quot;========================\u0026quot;) fmt.Println(\u0026quot;Server Start \u0026gt;\u0026gt; http://localhost:3000\u0026quot;) fmt.Println(\u0026quot;========================\u0026quot;) log.Fatal(http.ListenAndServe(\u0026quot;:3000\u0026quot;, router)) }  注目していただきたのが、17行目から19行目の処理です。\nここで、各層の NewXxx() の処理を使って依存関係を定義しています。\nDI ライブラリを使うことで、よりスマートに書けると思いますが、\n愚直にやるならこんな感じです。\nテスト ここまでの実装で 書籍一覧 取得リクエスト を送れるようになりました。\n$ go run cmd/api/main.go $ curl -X GET http://localhost:3000/api/v1/books  上記コマンドを実行すると、\n2つの書籍データが返ってくるはずです。\n{ \u0026quot;books\u0026quot;: [ { \u0026quot;id\u0026quot;: 1, \u0026quot;title\u0026quot;: \u0026quot;DDDが分かる本\u0026quot;, \u0026quot;author\u0026quot;: \u0026quot;たろうくん\u0026quot;, \u0026quot;issued_at\u0026quot;: \u0026quot;2019-10-29T02:22:09.264835+09:00\u0026quot; }, { \u0026quot;id\u0026quot;: 2, \u0026quot;title\u0026quot;: \u0026quot;レイヤードアーキテクチャが分かる本\u0026quot;, \u0026quot;author\u0026quot;: \u0026quot;はなこさん\u0026quot;, \u0026quot;issued_at\u0026quot;: \u0026quot;2019-10-23T02:22:09.264841+09:00\u0026quot; } ] }  エンドポイントが一個しかなかったり、DB 接続してなかったりと、未完成なところが多いですが、\nDDD や レイヤードアーキテクチャ が絡んできて、結構重い内容になってきたので、一旦ここで切ろうと思います。\n後日、続編記事を出したいと思います。\nまとめ レイヤードアーキテクチャがメインの話になりましたが、\nアーキテクチャについて勉強中だったので、僕的にはちょうど良い勉強になりました。\n今後は、エヴァンス本で「ドメイン知識をどのようにしてドメインモデルに落とし込んでいくのか」ってところを勉強していこうと思います。\n","ref":"/tech-blog/blog/go_web_api/"},{"title":"【goenv】GOPATH が変わらないときの対処法","date":"","description":"","body":"GOPATH が変わらない… 今日こんな現象に遭遇した。\n$ export GOPATH=/Users/yyh-gl/workspaces/Go $ echo $GOPATH /Users/yyh-gl/workspaces/Go $ go env GOPATH /Users/yyh-gl/go/1.12.5  GOPATH が書き換わらない。\n解決方法 社内Slack で適当につぶやいたら、同期が助けてくれた（神）\n画像にある Qiita のリンクが こちら ちなみに僕の環境の goenv は バージョン 1.12.5 だったので、2系に上げなくても発生する模様。\n （追記：19/06/14）またまた同期が教えてくれました。\nこちらの記事 によると、 goenv による管理は バージョン 1.12 からとのこと。\n 結論：goenv が GOPATH を管理しようとしてた\ngoenv の管理から外してやるには GOENV_DISABLE_GOPATH=1 にしてやればOK。\n僕は zshrc に以下のとおり追記しました。\nexport GOENV_DISABLE_GOPATH=1\n（zshrc の読み込み直しを忘れずに）\n結果 $ go env GOPATH /Users/yyh-gl/workspaces/Go  変わった。よかった\n","ref":"/tech-blog/blog/gopath/"},{"title":"【エリック・エヴァンスのドメイン駆動設計】DDD入門 Part 1","date":"","description":"","body":"DDD の勉強始めます 新卒研修を受ける中で DDD が出てきて、勉強したくなったので、\n『エリック・エヴァンスのドメイン駆動設計』（エリック・エヴァンス著，今関 剛 監訳，和智 右桂、牧野 祐子 訳） を読んでいこうと思います。\n今回は第1部「ドメインモデルを機能させる」の 1章 と 2章 をまとめます。\n注意： 僕の理解をそのままメモとして書き連ねていきます。\nしたがって、誤った理解もあると思うので、そのときはDMとかでご指摘お願いします！\n1章 知識をかみ砕く ソフトウェアを作るときに、はじめから対象を十分に理解している開発者などいない。\n 対象 ＝ これから作るソフトウェアで実現する作業 ＝ ドメイン\n したがって、対象について詳しい人（ドメインエキスパート）と開発者で 十分に話し合って理解を深めることが重要である。\n理解したことはモデルとして書き出す。 そして、ドメインエキスパートは足りないところがあれば追加で説明する。\n開発者は分からないところがあれば質問する。\n上記工程を何度も繰り返し、その都度得た知識をモデルに落とし込んでいく。\n→ 継続的学習（継続的学習は開発が始まった後でも行う）\nはじめから対象を如実に表したモデルを作れることは滅多にない。\nドメインエキスパート と 開発者 では見ている視点が違うので少し話を聞いたぐらいで 完璧なモデルを作ることができないのは当たり前である。\nだからこそ、対話を通して、互いに疑問点や不要な点を洗い出し、洗練する必要がある。\nこれが 知識のかみ砕き である。\n1章 まとめ  ドメインエキスパートと開発者が話し合ってドメインをモデルに落とし込んでいく  用語の説明や不足点の追加など とにかく話す ドメイン：ソフトウェア化する対象（業務やサービスなど、ソフトウェア化の対象となりうる万物）   一発で完璧なモデリングはできないから、継続的に改善していく  2章 コミュニケーションと言語の使い方 ドメインエキスパートが使う専門用語を開発者は理解できないし、\n開発者が使う専門用語をドメインエキスパートは理解できない。\nドメインエキスパートと開発者の両者が同じ意味だと思って使っていたとしても たいていの場合、差異がある。\nこのような差異があると 通訳 が必要となる。\n通訳はコミュニケーションを鈍らせ、知識のかみ砕きを沈滞させる。\n共通言語としてのモデル 通訳をなくすために、 モデルを言語の骨格として使用 する。\nドメインエキスパートと開発者のコミュニケーションやコード、ドキュメント、図など 全てにおいて、その言語を使用する。\nここで、モデルはドメインエキスパートと開発者のコミュニケーションから生まれることを思い出す。\nつまり、コミュニケーションの中で認識の違いが見つかるなどして、\n言語定義に対する変更があったときにはモデルが変更になり、\nさらにはコード中のクラス名やメソッド名が変わることもありえる。\nこうすることで、\nドメインエキスパートと開発者は、ともに不正確なところや矛盾を指摘し合い、\nより確かなドメインモデルを構築することができる。\nこうして作成されたモデルをドメインエキスパートが理解できなかった場合、\nそのモデルには何か問題があることがわかる。\nつまり、実現したいソフトウェアではないということになる。\n図とドキュメントに関する注意点  ここでいうドキュメントとは開発者側でのみ使用するドキュメントだと思われる\n 設計に関する本質的な詳細は、コードにおいてとらえられる。 したがって、図でモデルを表現はしないし、ドキュメントによって全て説明しようとはしない。\n モデル ≠ 図\n 図はモデルについてのコミュニケーション、説明を助けるために使う。\nドキュメントはコードと会話の補足事項のみを記述する。\n ドキュメントは常に最新である必要があるから、\n補足事項以外も含めて全てドキュメント化するのはつらい的な意味合いに感じた。\n  なにより先述したとおり、「設計に関する本質的な詳細は、コードにおいてとらえられる」から。\nXP を代表とするいくつかの手法では、コードで全てを語る。\n 2章 まとめ   ドメインエキスパートと開発者の共通言語は、ドメインモデルを言語の骨格として使用する\n そこで理解できないことがあれば、モデルのリファクタリングが必要    図とドキュメントはあくまで補助資料。コードで語ろう。\n  ","ref":"/tech-blog/blog/evans_ddd_1/"},{"title":"【大規模サービス技術入門 5章】大規模データの処理方法についてまとめた","date":"","description":"","body":"はじめに 社内で伊藤 直也さんと田中 慎司さんが書かれた\n『Web開発者のための大規模サービス技術入門』 を輪読しました。\n今回は、僕が担当した 第5回の「大規模データ処理[実践]入門」についてまとめます。\nなお、本書は2010年に出版された本であるため、\n少なくとも第5回の内容は今では当たり前のことという印象を受けました。\nそれでも、しっかりと文章で学んでおくことは大事だと思うのでまとめます。\n★印は個人メモです。\n以下まとめ\n大量なデータを扱う場面 全文検索やデータマイニングなど RDBMSで処理できない規模のデータを\n処理したい場面は多く存在します。\nでは、RDBMSが使えない規模のデータをどう処理すればいいでしょうか。\nデータを抽出 結論から言うと、RDBMSで扱うことができないデータは、適宜RDBMSから 抽出 して利用します。\n具体的には バッチ処理でRDBMSからデータを抽出し、\n別途インデックスサーバのようなものを作って、そこに入れていきます。\n ★ ここで言っているインデックスサーバというのは、例えば全文検索用であれば\n  「検索用にチューニングした（検索しやすくした）データ構造」と考えるべきでしょう。\n  ★ 最近は、Fluentd を使用してログを外部に吐き出してから解析したりしますよね。\n  それと考え方は一緒だと思います。\n インデックスサーバにはRPC（Remote Procedure Call）を使ってアクセスします。\n（なお、RPCと言いましたが、現在では Web API でのアクセスが一般的なので、以降、 Web API を例に使用します）\nイメージとしては下図のようになります。\n用途特化型のインデクシング 上述した方法を、はてな社（著者がはてな社出身の方なのでよく出てきます）では、\n用途特化型インデクシング と呼ぶそうです。\n用途特化型インデクシングとRDBMS RDBMS はデータソートや統計処理、JOIN など、データに対して様々な処理を行うことができます。\nしかし、汎用的故に、特定の目的だけに使うときには、それ用にチューニングしたデータ構造、\nすなわち 用途特化型インデクシング を使う方が圧倒的に速くなります。\n ★ 先ほど言っていた Fluentd を用いたログ解析システム は ログ解析用にチューニングしたものと言えるでしょうか。\n 用途特化型インデクシングの使用例： 全文検索エンジン 全文検索エンジンでは、以下3点の要求をどう満たすか 考える必要があります。\n 大量のデータから検索したい 高速に検索したい 「いい感じ」の文書を上位に持ってきたい  特に難しいのが 「いい感じ」を持ってくるところ。\n ★ ここでいう「いい感じ」とは、関連度の高いキーワード とかでしょうか。\n  コンテキストによって「いい感じ」は変わってくるので皆さんが考える「いい感じ」を想像して読みすすめてください。\n RDBMS では要件を満たせない RDBMS は特定のカラムでしか並び替えることができません。\n例えば、作成日時で並べ替えるとか、名前のアルファベット順で並び替えるとかですね。\nはてな社では、「いい感じ」の文章を上位に持ってくるために\nスコアリング処理 を使用しているそうです。\nしかし、スコアリング処理には、文章が持つさまざまな情報を複合的に利用する必要があります。\nこれは特定のカラムでしか並び替えできない RDBMS が苦手する分野です。\nよって、ここで 用途特化型インデクシング が必要となります。\n ★ いろんな人が投稿した記事（文章）を単語レベルに分割して\n  保存とかしているんでしょうか？\n  とにかく、文章全文が保存されたデータソースから検索するのではなくて、\n  より検索しやすい形に整形されたデータソースに対して\n  検索をかけることが大事ということが分かってもらえれば幸いです。\n はてな社では、スコアリングしやすいデータ構造に変換してやる処理（検索インデックス）を\n自前で作成しています。（≒ 全文検索エンジンを自作）\nすなわち、用途特化型インデクシングを作成し、全文検索しているわけですね。\n理論と実践 全文検索システムは、RDBMS の JOIN を使って実現することもできるでしょう。（多分）\n一方で、「RDBMS で JOIN を使わない」というのはよく聞く話です。\n僕もコードレビューで、クエリ高速化のために JOIN を使わないように言われたことがありますし、\nその考え方は理解できます。\nしかし、それはRDS研究者からすれば「RDBMS で JOIN を使わないなんて、\nRDS を否定しながら RDS を使うようなもの」と言われてしまいます。\nここで大事なのは、\n「RDBMS で JOIN を使わない」というノウハウは 『実践』的にはすごく有益なノウハウであること。\nしかし、JOIN句を使えば、全文検索システムを作ることができるし、\n他の様々な場面においても JOIN句を使用することで解決できる問題はたくさんあります。\nこっちは 『理論』 の話。\n理論側では、JOIN句を使わないのは、バッドノウハウです。\n何が言いたいかというと、\n大規模な Webアプリケーション を運用・開発しようとすると、\n実践も理論も両方やっていかないといけない ということです。\n直面した課題に対して、ある側面ではバッドノウハウであっても、\n他の面から見たときにグッドノウハウであることがあります。\n我々エンジニアに求められるのは、実践も理論も両方をバランス良く使う力です。\n","ref":"/tech-blog/blog/bigdata_processing/"},{"title":"【Web API（Rails） + Vue.js】ブログのいいねボタン自作してみた","date":"","description":"いいね機能つけました","body":"いいねボタンがないブログ 本ブログ、いいねボタンが ありませんでした。\nだから、作っちゃいました。っていう記事です。\n構成 上図のように\n記事ページからAPIサーバにリクエストを送り、 いいねの数を取得・加算します。\n記事ページからAPIサーバへのリクエスト部分（クライアント）には Vue + axios を使用。\nAPIサーバは Rails で実装しました。\n（以前から Slackのスラッシュコマンド用に使用していたAPIサーバを流用しました）\nAPIサーバ Rails で APIサーバを建てる方法に関しては、\n以前に Qiita で 入門記事 書いたのでそちらをご覧ください。\n（少し古い記事ですが、そんなに問題はないはずです）\nDB にテーブル作成 今回、ブログ記事を管理するために、下記のテーブルを作成しました。\nmysql\u0026gt; describe blog_posts; +------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +------------+--------------+------+-----+---------+----------------+ | id | bigint(20) | NO | PRI | NULL | auto_increment | | title | varchar(255) | NO | | NULL | | | count | varchar(255) | NO | | 0 | | | created_at | datetime | NO | | NULL | | | updated_at | datetime | NO | | NULL | | +------------+--------------+------+-----+---------+----------------+ 5 rows in set (0.00 sec)  titleには、日本語のタイトル（本記事だと『【WEB API（RAILS） + VUE.JS】ブログのいいねボタン自作してみた』）ではなく、 記事ファイル（マークダウン）の名前（本記事だと『good_api』, 拡張子抜き）が入ります。\nWeb上の記事データと APIサーバのレコード をどうやって結びつけるか考えたとき、\nページが持っている記事の情報って、 URL に含まれる 記事ファイル名 しかないなぁ…と考え、\nURL から取得した 英title と テーブルの title が一致するものを探すようにしました。\nCORSの設定 今回重要なのは CORS の設定です。\nCORS を説明するとなると、 CSRF の説明やらなんやらで、とても長くなり、本題からかなり脱線するので\n今回は こちらのサイト をご紹介するだけにしておきます。\n僕的に一番分かりやすかったです。\n・\n・\n・\nでは、本題の CORS の設定についてですが、\nRails における CORS の設定はとても簡単です。\n   Gemfile に rack-cors を追加\nRails で生成した Gemfile にデフォルトで入っていますが、コメントアウトされています。\nコメントを解除してあげましょう。\n# Gemfile …省略 # Use Rack CORS for handling Cross-Origin Resource Sharing (CORS), making cross-origin AJAX possible gem 'rack-cors' …省略    cors.rb を編集\nこちらも元から存在するファイルです。\n中身に関しては、コメントを解除してあげるだけでOKです。\n# \u0026lt;Rails Root Directory\u0026gt;/config/initializers/cors.rb Rails.application.config.middleware.insert_before 0, Rack::Cors do allow do origins 'https://yyh-gl.github.io' resource '*', headers: :any, methods: [:get, :post, :options] end end  origins で指定した場所からのアクセスに関しては、同一生成元ポリシーを少し無視して\nアクセスを許可します。\nワイルドカードによる指定もできます。\n今回は、僕のブログからのアクセスのみを許可します。\nresource によってアクセスを許可するリソースを指定できます。\nresource で許可したリソースに対して、\nheaders および methods で指定したヘッダおよびメソッドのみを受け付けます。\nこちら を見ていただければ、より詳しい設定方法が分かると思います。\n今回実装するAPIは GET と POST しか使わないので\nmethods: [:get, :post, :options] となっています。\noptions は プリフライトリクエスト と言って、\n事前にサーバに対してリクエストを送信しても大丈夫か問い合わせるさいに使用します（参考 ）。\n忘れずに追加しましょう。    以上で、Rails における CORS の設定は完了です。 クライアントの実装 次は、記事ページからリクエストを送る部分です。\nまず、HTMLファイルはこんな感じです ↓\n\u0026lt;html\u0026gt; \u0026lt;div id=\u0026quot;GoodCounter\u0026quot;\u0026gt; \u0026lt;good-counter\u0026gt;\u0026lt;/good-counter\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/html\u0026gt; \u0026lt;script src=\u0026quot;/tech-blog/js/axios.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;/tech-blog/js/vue.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;/tech-blog/js/vue_app.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  中の処理を説明すると、\nIDが GoodCounter の div要素の部分に Vue コンポーネント（後述）を入れ込んでいます。\nscriptタグは、上から axios, Vue, Vue コンポーネント を読み込んでいます。\n次に Vue コンポーネントです。\n// vue_app.js Vue.component('good-counter', { template: '\u0026lt;button v-on:click=\u0026quot;addCount\u0026quot;\u0026gt;\\n' + '\u0026lt;i class=\u0026quot;far fa-thumbs-up\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; いいね　｛｛ good_count ｝｝\\n' + '\u0026lt;/button\u0026gt;', data: function () { return { good_count: \u0026quot;-\u0026quot;, } }, mounted () { // URL から記事情報を取得 let paths = location.pathname.split('/'); // URL のタイトル部分のみを抽出 // GET /posts/:title への リクエストURL を作成 let reqUrl = '\u0026lt;server url\u0026gt;' + paths[paths.length - 2]; axios .get(reqUrl) .then(response =\u0026gt; this.good_count = response.data.post.count) }, methods: { addCount: function (event) { // URL から記事情報を取得 let paths = location.pathname.split('/'); // URL のタイトル部分のみを抽出 // POST /posts/:title/good への リクエストURL を作成 let reqUrl = '\u0026lt;server url\u0026gt;' + paths[paths.length - 2] + '/good'; if(event) { axios .post(reqUrl) .then(response =\u0026gt; this.good_count = response.data.after) } } } }); // root インスタンスを作成 new Vue({ el: '#GoodCounter', });  いろいろ書いていますが、 URL から記事タイトルを取得し、\nそれを基にリクエストを送っているだけです。\nVue コンポーネントのマウント時に いいねの数を GET しています。\nそして、いいねボタンが押されるたびに addCount() が実行されて、 いいね が加算されます。\nVue の SFC を使いたかったのですが、勉強不足で実現できず、このような実装になりました。\n詳しい人ぜひ教えてください。\n完成！ できあがったものは、↓ の方にスクロールしていったら実物があるので見てみてください\nだれがいいねしてくれたかは分からないですが、 誰かがしてくれた という事実を噛み締めたいと思います。\nVue は僕の会社でも使われているので、今後も積極的にキャッチアップを続けていきたいです。\nフロントの知識もっとつけていきたいですねー👾\n（APIサーバへのアクセスを制限しないとな…）\n","ref":"/tech-blog/blog/good_api/"},{"title":"スクラムについて学んだ話","date":"","description":"","body":"スクラムとは 概要   変化に対し柔軟に開発を運用するためのアジャイルフレームワーク\n  開発に常に優先度をつける\n  仕事を進めることを主眼に考え、そのために改善を常に行う\n  ロールが3つあり、協調しあい開発する\n プロダクトオーナー スクラムチーム 開発チーム    POが満足するアウトプットがあったかのみを検証\n  5つのイベントがある（後述）\n  2つのアウトプット（成果物）がある（後述）\n  特徴   非常にシンプルなフレームワーク\n 定められたルールが他の手法より少なくアレンジが容易    実践的で経験主義\n  世界的に普及している\n  アジャイル開発とは アジャイルとスクラムの違い スクラムとはアジャイル開発手法のひとつ\n他にもXPとかがある\nアジャイルソフトウェア開発宣言 ここ にいろいろな言語で宣言されています\nこの宣言では以下のことを重要視している\n 個人と対話 動くソフトウェア 顧客との協調 変化への対応  スクラムとウォータフォールの違い   ウォータフォール\n 計画、設計、実装、テストが一方向に進む リリース直前の実装や仕様に漏れがあると最悪の場合プロジェクトがぽしゃる 運用・保守には強い。新規案件向けではない    スクラム\n 開発期間中に計画、設計、実装、テストのリサイクルを何度も回す 細かいスパンでリリースするので、大きな手戻りが少ない    スクラムで登場するロール（役割） あくまでテンプレの内容を紹介\n自分のチームに合わせて変えてOK（むしろカスタマイズすることが重要）\nプロダクトオーナー（PO）   役割\n プロダクトのビジネス価値に責任を持つ リリース判断をすることができる 優先度の判断役    求められる力\n 情報アウトプット（見える化、透明性） → 実現したいことをちゃんと伝える力 クライアントとチームを繋ぐハブ役    スクラムマスター（SM）   役割\n スクラム開発に関わる全ての人を支援し、成功に導く  POのビジネス的な相談を受けたり、開発チームの技術的な相談を受けたり などなど   スクラムの理論や価値を関係者全員に教え、理解してもらう 開発チームへの障害や外部干渉を取り除き、防ぐ    求められる力\n サーヴァントリーダシップ（奉仕型リーダー）  下からみんなを持ち上げるようなリーダー   理解と実行の話づくりと良きファシリテーター     SMが開発に加わるのはOK？\n  チームが良しとするならばOK。\n  はじめから参加することは基本的にない。\n 開発チーム   役割\n 具体的な開発を遂行 リリース可能なプロダクトバックログアイテムを完成させる 何をどのように作るか決定する（POは実現したいものを言うが、どうやって作り上げるかは開発チームに委ねる）    求められる力\n 主体性と協調性（ただ作るだけの存在にならない） → 受注体質はだめ 仮説や知識を理解し、サービス価値向上の施策を立案する    関係図  ランダムロールってうまくいく？\n  ランダムロール：SMがおらず、スプリントごとにランダムにロールを決定すること\n  ランダムロールは難しい。各ロールを理解が出来ていることが重要。\n  全員が「ロールの役割をチーム内で合意できている状態」になっていることが重要。\n  見切り発車は危険。チームが成熟しているとうまくいきそう。\n スクラムは「イベント」で構成されている 定義 イベントとはスプリント内に規則性を作り出すためのタイムボックスのこと\n→ 定義されていないMTGの必要性を最小限にできる\n目的 進むべき方向が間違っていないかを確認する\nイベントの種類 以下5つのイベントがある。\n1. スプリントプランニング   達成できるプロダクトバックログアイテムを約束する\n  開発チームとSMでやり、POに報告する\n  何をどのように作るか、どういう状態をゴールとするか決定する\n  チーム全員が同意していることが大事\n  二部制で実施\n 第一部：何を作るか 検討  どのくらいできるか どれをやるか   第二部：どう作るか 検討    2. デイリースクラム   開発チームが毎日やる短い打ち合わせ\n 15分以上やってはいけない    スプリントゴールとバックログの進捗の検査を行う\n  現在のスプリント終了までに期待される成果物を作成できるのか毎日把握しなければいけない\n  内容は開発チームが設定し、質問ベースで会話したり、議論ベースで会話してもよい\n  POとSMは参加しない\n 参加すると、開発チームからPO、SMに報告する場になってしまうから、開発チーム内での議論が弾まなくなる。 ただし、スクラム初心者のチームに関してはSMがファシリテーターとして参加することもある。    デイリースクラムは問題解決の場ではない\n この場では「こういう問題が発生した」という障害となる事柄を伝えるだけにする（その後当事者を集めたりしたらいい）    3. リファインメント   POによるプロダクトバックログアイテムの詳細化と優先順位の見直しや調整を行う\n  POと開発チームが参加し、ロードマップやサービスビジョンからプロダクトバックログアイテムの作成する\n 新しく増えたプロダクトバックログアイテムの優先度見直して、全体の並び替えを行う    時間は未定で、チームで決める\n  4. スプリントレビュー   スクラムチームとステークホルダーが強力し、成果物の検査・適応をする\n  開発チームがPOとステークホルダーに対して、完了した成果物のデモを行い、イベント参加者からの質問に答える\n  リリースするかどうかPOの判断に一任され、そこで出た不具合や新たな要求はプロダクトバックログに追加される\n  大事なことは動くものを見せること。そして、素直に話すこと（機能改善などについて思ったことを素直に話す）\n  5. レトロスペクティブ   日本語にすると「振り返り」\n  スプリントの検査を行い、改善計画を立てる\n  反省会ではないことを意識する。\n 反省会：悪かったことを言うだけで、次の行動を決めない状況    会話から出た項目に関して、その結果を確認するためのアクションを洗い出し、次回のスプリントバックログに含めなければいけない。\n  スクラムにおける成果物とは プロダクトバックログ（PBL） 定義 優先順位が決められた要求事項（プロダクトバックログアイテム（PBLI））が集まって一覧化されたもの\n責任者 POが責任を持つ\nライフサイクル ★調べて追記する予定\nスプリントバックログ（SBL） 定義 スプリントにおける開発チームのしごとを定義したタスクリスト\n責任者 開発チームが責任を持つ\nライフサイクル スプリントの間だけ存在する（スプリントごとに更新される）\nまとめ スクラムはあくまでフレームワークである。\n銀の弾丸ではない。\n","ref":"/tech-blog/blog/scrum_entry/"},{"title":"【Terraform + ECS + RDS】Terraform で ECS環境構築してみた","date":"","description":"","body":"Terraform とは 最近流行りの IaC です。\nつまり、コードベースでインフラリソースを管理するためのツールです。\n中でもTerraform はクラウドに特化した IaC ツールという立ち位置です。\nAWSやGCP, Azure などの他に様々なクラウドプラットフォーム に対応しています。\n（ちなみに、Vagrant 開発元の HashiCorp 社が開発しています）\n今回やること Terraform で AWS 上に下記のような環境を自動構築します。\nECS でデプロイされるサービスは ECR から引っ張ってくるようにします。\nそして、そのサービスは Aurora を使うシステムを想定しています。\n【⚠注意⚠】上記構成はお金が発生します！ まったくもって無料枠ではありません！\n【⚠注意⚠】今回独自ドメインを使用していますが、ドメイン取得に関しては省略しています。\n今回やる内容は… 僕が所属する会社の研修資料を参考に進めています。\n資料を作成してくださった@_y_ohgi さんに感謝。\n自動構築プロセス全体で使用する共通設定を定義 まず、 main.tf を作成し、以下のとおり共通設定を定義していきます。\n# AWS を利用することを明示 provider \u0026quot;aws\u0026quot; { # リージョンを設定 region = \u0026quot;ap-northeast-1\u0026quot; } # これから作成するリソースに付与する名前のプリフィックスを設定 # グローバル変数的な立ち位置で定義 variable \u0026quot;prefix\u0026quot; { default = \u0026quot;sample-project\u0026quot; }  provider で使用するクラウドを指定することができます。\nvariable は変数定義です。\n${var.prefix} と書くことで default で指定した内容が展開されます。\n（次の定義ファイルでも変数が出てくるので、そこで使いかたを見てみてください。）\nなお、変数定義を別ファイルに切り出す方法もあるようですが、今回はやりません。\n切り出す方法はこちら が参考になると思います。\nRoute53 の設定 route53_acm.tf を作成し、以下のとおり定義します。\n内部で ACM に関する定義も行っています。\n以降、クラウドプラットフォームに依存しない設定に関しては【解説】コメントで解説を行っています。\n各 resource の定義内容に関しては コメントにあるURLを参考にしてください。\n 英語ではありますが、公式ドキュメント がとても分かりやすいです\n # ドメイン名の設定 variable \u0026quot;domain\u0026quot; { description = \u0026quot;「Route53で管理するドメイン」 などの説明文\u0026quot; type = \u0026quot;string\u0026quot; # みなさんが持つドメイン名にしてください default = \u0026quot;example.com\u0026quot; } # Route53 Hosted Zone # https://www.terraform.io/docs/providers/aws/d/route53_zone.html # 【解説】data で始まっていますが、これは読み取り専用のリソースであることを示します。 # すでにクラウド上に存在するリソースの値を参照するために使用します。 data \u0026quot;aws_route53_zone\u0026quot; \u0026quot;main\u0026quot; { name = \u0026quot;${var.domain}\u0026quot; # 変数を展開しているところ、ここです private_zone = false } # ACM # https://www.terraform.io/docs/providers/aws/r/acm_certificate.html # 【解説】resource は作成するリソースを定義する場所です。 resource \u0026quot;aws_acm_certificate\u0026quot; \u0026quot;main\u0026quot; { domain_name = \u0026quot;${var.domain}\u0026quot; validation_method = \u0026quot;DNS\u0026quot; lifecycle { create_before_destroy = true } } # Route53 record # ACMによる検証用レコード # https://www.terraform.io/docs/providers/aws/r/route53_record.html resource \u0026quot;aws_route53_record\u0026quot; \u0026quot;validation\u0026quot; { depends_on = [\u0026quot;aws_acm_certificate.main\u0026quot;] zone_id = \u0026quot;${data.aws_route53_zone.main.id}\u0026quot; ttl = 60 name = \u0026quot;${aws_acm_certificate.main.domain_validation_options.0.resource_record_name}\u0026quot; type = \u0026quot;${aws_acm_certificate.main.domain_validation_options.0.resource_record_type}\u0026quot; records = [\u0026quot;${aws_acm_certificate.main.domain_validation_options.0.resource_record_value}\u0026quot;] } # ACM Validate # https://www.terraform.io/docs/providers/aws/r/acm_certificate_validation.html resource \u0026quot;aws_acm_certificate_validation\u0026quot; \u0026quot;main\u0026quot; { certificate_arn = \u0026quot;${aws_acm_certificate.main.arn}\u0026quot; validation_record_fqdns = [\u0026quot;${aws_route53_record.validation.0.fqdn}\u0026quot;] } # Route53 record # https://www.terraform.io/docs/providers/aws/r/route53_record.html resource \u0026quot;aws_route53_record\u0026quot; \u0026quot;main\u0026quot; { type = \u0026quot;A\u0026quot; name = \u0026quot;${var.domain}\u0026quot; zone_id = \u0026quot;${data.aws_route53_zone.main.id}\u0026quot; alias = { name = \u0026quot;${aws_lb.main.dns_name}\u0026quot; zone_id = \u0026quot;${aws_lb.main.zone_id}\u0026quot; evaluate_target_health = true } } # ALB Listener # https://www.terraform.io/docs/providers/aws/r/lb_listener.html resource \u0026quot;aws_lb_listener\u0026quot; \u0026quot;https\u0026quot; { load_balancer_arn = \u0026quot;${aws_lb.main.arn}\u0026quot; certificate_arn = \u0026quot;${aws_acm_certificate.main.arn}\u0026quot; port = \u0026quot;443\u0026quot; protocol = \u0026quot;HTTPS\u0026quot; default_action { type = \u0026quot;forward\u0026quot; target_group_arn = \u0026quot;${aws_lb_target_group.main.id}\u0026quot; } } # ALB Listener Rule # https://www.terraform.io/docs/providers/aws/r/lb_listener_rule.html resource \u0026quot;aws_lb_listener_rule\u0026quot; \u0026quot;http_to_https\u0026quot; { listener_arn = \u0026quot;${aws_lb_listener.main.arn}\u0026quot; priority = 99 action { type = \u0026quot;redirect\u0026quot; redirect { port = \u0026quot;443\u0026quot; protocol = \u0026quot;HTTPS\u0026quot; status_code = \u0026quot;HTTP_301\u0026quot; } } condition { field = \u0026quot;host-header\u0026quot; values = [\u0026quot;${var.domain}\u0026quot;] } } # Security Group Rule # https://www.terraform.io/docs/providers/aws/r/security_group_rule.html resource \u0026quot;aws_security_group_rule\u0026quot; \u0026quot;alb_https\u0026quot; { security_group_id = \u0026quot;${aws_security_group.alb.id}\u0026quot; type = \u0026quot;ingress\u0026quot; from_port = 443 to_port = 443 protocol = \u0026quot;tcp\u0026quot; cidr_blocks = [\u0026quot;0.0.0.0/0\u0026quot;] }  VPCの設定 vpc.tf を以下のとおり定義します。\nここで、 main.tf で定義した変数が大活躍します。\n# VPC # https://www.terraform.io/docs/providers/aws/r/vpc.html resource \u0026quot;aws_vpc\u0026quot; \u0026quot;main\u0026quot; { cidr_block = \u0026quot;10.0.0.0/16\u0026quot; tags = { Name = \u0026quot;${var.prefix}-vpc\u0026quot; } } # Public Subnet # https://www.terraform.io/docs/providers/aws/r/subnet.html resource \u0026quot;aws_subnet\u0026quot; \u0026quot;public_1a\u0026quot; { # 先程作成したVPCを参照し、そのVPC内にSubnetを立てる vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; # Subnetを作成するAZ availability_zone = \u0026quot;ap-northeast-1a\u0026quot; cidr_block = \u0026quot;10.0.1.0/24\u0026quot; tags = { Name = \u0026quot;${var.prefix}-public-1a\u0026quot; } } resource \u0026quot;aws_subnet\u0026quot; \u0026quot;public_1c\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; availability_zone = \u0026quot;ap-northeast-1c\u0026quot; cidr_block = \u0026quot;10.0.2.0/24\u0026quot; tags = { Name = \u0026quot;${var.prefix}-public-1c\u0026quot; } } resource \u0026quot;aws_subnet\u0026quot; \u0026quot;public_1d\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; availability_zone = \u0026quot;ap-northeast-1d\u0026quot; cidr_block = \u0026quot;10.0.3.0/24\u0026quot; tags = { Name = \u0026quot;${var.prefix}-public-1d\u0026quot; } } # Private Subnets resource \u0026quot;aws_subnet\u0026quot; \u0026quot;private_1a\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; availability_zone = \u0026quot;ap-northeast-1a\u0026quot; cidr_block = \u0026quot;10.0.10.0/24\u0026quot; tags = { Name = \u0026quot;${var.prefix}-private-1a\u0026quot; } } resource \u0026quot;aws_subnet\u0026quot; \u0026quot;private_1c\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; availability_zone = \u0026quot;ap-northeast-1c\u0026quot; cidr_block = \u0026quot;10.0.20.0/24\u0026quot; tags = { Name = \u0026quot;${var.prefix}-private-1c\u0026quot; } } resource \u0026quot;aws_subnet\u0026quot; \u0026quot;private_1d\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; availability_zone = \u0026quot;ap-northeast-1d\u0026quot; cidr_block = \u0026quot;10.0.30.0/24\u0026quot; tags = { Name = \u0026quot;${var.prefix}-private-1d\u0026quot; } } # Internet Gateway # https://www.terraform.io/docs/providers/aws/r/internet_gateway.html resource \u0026quot;aws_internet_gateway\u0026quot; \u0026quot;main\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; tags = { Name = \u0026quot;${var.prefix}-igw\u0026quot; } } # Elasti IP # NAT Gateway には1つの Elastic IP が必要なので作成 # https://www.terraform.io/docs/providers/aws/r/eip.html resource \u0026quot;aws_eip\u0026quot; \u0026quot;nat_1a\u0026quot; { vpc = true tags = { Name = \u0026quot;${var.prefix}-eip-for-natgw-1a\u0026quot; } } # NAT Gateway # https://www.terraform.io/docs/providers/aws/r/nat_gateway.html resource \u0026quot;aws_nat_gateway\u0026quot; \u0026quot;nat_1a\u0026quot; { subnet_id = \u0026quot;${aws_subnet.public_1a.id}\u0026quot; # NAT Gatewayを配置するSubnetを指定 allocation_id = \u0026quot;${aws_eip.nat_1a.id}\u0026quot; # 紐付けるElasti IP tags = { Name = \u0026quot;${var.prefix}-natgw-1a\u0026quot; } } resource \u0026quot;aws_eip\u0026quot; \u0026quot;nat_1c\u0026quot; { vpc = true tags = { Name = \u0026quot;${var.prefix}-eip-for-natgw-1c\u0026quot; } } resource \u0026quot;aws_nat_gateway\u0026quot; \u0026quot;nat_1c\u0026quot; { subnet_id = \u0026quot;${aws_subnet.public_1c.id}\u0026quot; allocation_id = \u0026quot;${aws_eip.nat_1c.id}\u0026quot; tags = { Name = \u0026quot;${var.prefix}-natgw-1c\u0026quot; } } resource \u0026quot;aws_eip\u0026quot; \u0026quot;nat_1d\u0026quot; { vpc = true tags = { Name = \u0026quot;${var.prefix}-eip-for-natgw-1d\u0026quot; } } resource \u0026quot;aws_nat_gateway\u0026quot; \u0026quot;nat_1d\u0026quot; { subnet_id = \u0026quot;${aws_subnet.public_1d.id}\u0026quot; allocation_id = \u0026quot;${aws_eip.nat_1d.id}\u0026quot; tags = { Name = \u0026quot;${var.prefix}-natgw-1d\u0026quot; } } # Route Table # https://www.terraform.io/docs/providers/aws/r/route_table.html resource \u0026quot;aws_route_table\u0026quot; \u0026quot;public\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; tags = { Name = \u0026quot;${var.prefix}-public-route-table\u0026quot; } } # Route # https://www.terraform.io/docs/providers/aws/r/route.html resource \u0026quot;aws_route\u0026quot; \u0026quot;public\u0026quot; { destination_cidr_block = \u0026quot;0.0.0.0/0\u0026quot; route_table_id = \u0026quot;${aws_route_table.public.id}\u0026quot; gateway_id = \u0026quot;${aws_internet_gateway.main.id}\u0026quot; } # Association # https://www.terraform.io/docs/providers/aws/r/route_table_association.html resource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;public_1a\u0026quot; { subnet_id = \u0026quot;${aws_subnet.public_1a.id}\u0026quot; route_table_id = \u0026quot;${aws_route_table.public.id}\u0026quot; } resource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;public_1c\u0026quot; { subnet_id = \u0026quot;${aws_subnet.public_1c.id}\u0026quot; route_table_id = \u0026quot;${aws_route_table.public.id}\u0026quot; } resource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;public_1d\u0026quot; { subnet_id = \u0026quot;${aws_subnet.public_1d.id}\u0026quot; route_table_id = \u0026quot;${aws_route_table.public.id}\u0026quot; } # Route Table (Private) # https://www.terraform.io/docs/providers/aws/r/route_table.html resource \u0026quot;aws_route_table\u0026quot; \u0026quot;private_1a\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; tags = { Name = \u0026quot;${var.prefix}--private-1a\u0026quot; } } resource \u0026quot;aws_route_table\u0026quot; \u0026quot;private_1c\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; tags = { Name = \u0026quot;${var.prefix}--private-1c\u0026quot; } } resource \u0026quot;aws_route_table\u0026quot; \u0026quot;private_1d\u0026quot; { vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; tags = { Name = \u0026quot;${var.prefix}--private-1d\u0026quot; } } # Route (Private) # https://www.terraform.io/docs/providers/aws/r/route.html resource \u0026quot;aws_route\u0026quot; \u0026quot;private_1a\u0026quot; { destination_cidr_block = \u0026quot;0.0.0.0/0\u0026quot; route_table_id = \u0026quot;${aws_route_table.private_1a.id}\u0026quot; nat_gateway_id = \u0026quot;${aws_nat_gateway.nat_1a.id}\u0026quot; } resource \u0026quot;aws_route\u0026quot; \u0026quot;private_1c\u0026quot; { destination_cidr_block = \u0026quot;0.0.0.0/0\u0026quot; route_table_id = \u0026quot;${aws_route_table.private_1c.id}\u0026quot; nat_gateway_id = \u0026quot;${aws_nat_gateway.nat_1c.id}\u0026quot; } resource \u0026quot;aws_route\u0026quot; \u0026quot;private_1d\u0026quot; { destination_cidr_block = \u0026quot;0.0.0.0/0\u0026quot; route_table_id = \u0026quot;${aws_route_table.private_1d.id}\u0026quot; nat_gateway_id = \u0026quot;${aws_nat_gateway.nat_1d.id}\u0026quot; } # Association (Private) # https://www.terraform.io/docs/providers/aws/r/route_table_association.html resource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;private_1a\u0026quot; { subnet_id = \u0026quot;${aws_subnet.private_1a.id}\u0026quot; route_table_id = \u0026quot;${aws_route_table.private_1a.id}\u0026quot; } resource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;private_1c\u0026quot; { subnet_id = \u0026quot;${aws_subnet.private_1c.id}\u0026quot; route_table_id = \u0026quot;${aws_route_table.private_1c.id}\u0026quot; } resource \u0026quot;aws_route_table_association\u0026quot; \u0026quot;private_1d\u0026quot; { subnet_id = \u0026quot;${aws_subnet.private_1d.id}\u0026quot; route_table_id = \u0026quot;${aws_route_table.private_1d.id}\u0026quot; }  ロードバランサの設定 次は ALB の定義を作成します。\nalb.tf に以下のとおり定義します。\n# SecurityGroup # https://www.terraform.io/docs/providers/aws/r/security_group.html resource \u0026quot;aws_security_group\u0026quot; \u0026quot;alb\u0026quot; { name = \u0026quot;${var.prefix}-alb\u0026quot; description = \u0026quot;${var.prefix} alb\u0026quot; vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; # セキュリティグループ内のリソースからインターネットへのアクセスを許可する egress { from_port = 0 to_port = 0 protocol = \u0026quot;-1\u0026quot; cidr_blocks = [\u0026quot;0.0.0.0/0\u0026quot;] } tags = { Name = \u0026quot;${var.prefix}-alb\u0026quot; } } # SecurityGroup Rule # https://www.terraform.io/docs/providers/aws/r/security_group.html resource \u0026quot;aws_security_group_rule\u0026quot; \u0026quot;alb_http\u0026quot; { security_group_id = \u0026quot;${aws_security_group.alb.id}\u0026quot; # セキュリティグループ内のリソースへインターネットからのアクセスを許可する type = \u0026quot;ingress\u0026quot; from_port = 80 to_port = 80 protocol = \u0026quot;tcp\u0026quot; cidr_blocks = [\u0026quot;0.0.0.0/0\u0026quot;] } # ALB # https://www.terraform.io/docs/providers/aws/d/lb.html resource \u0026quot;aws_lb\u0026quot; \u0026quot;main\u0026quot; { load_balancer_type = \u0026quot;application\u0026quot; name = \u0026quot;${var.prefix}\u0026quot; security_groups = [\u0026quot;${aws_security_group.alb.id}\u0026quot;] subnets = [\u0026quot;${aws_subnet.public_1a.id}\u0026quot;, \u0026quot;${aws_subnet.public_1c.id}\u0026quot;, \u0026quot;${aws_subnet.public_1d.id}\u0026quot;] } # Listener # https://www.terraform.io/docs/providers/aws/r/lb_listener.html resource \u0026quot;aws_lb_listener\u0026quot; \u0026quot;main\u0026quot; { # HTTPでのアクセスを受け付ける port = \u0026quot;80\u0026quot; protocol = \u0026quot;HTTP\u0026quot; # ALBのarnを指定します。 load_balancer_arn = \u0026quot;${aws_lb.main.arn}\u0026quot; # \u0026quot;ok\u0026quot; という固定レスポンスを設定する default_action { type = \u0026quot;fixed-response\u0026quot; fixed_response { content_type = \u0026quot;text/plain\u0026quot; status_code = \u0026quot;200\u0026quot; message_body = \u0026quot;ok\u0026quot; } } }  ECSの設定 ecs.tf はこんな感じです。\nresource \u0026quot;aws_iam_role\u0026quot; \u0026quot;ecs_task_execution_role\u0026quot; { name = \u0026quot;ecs_task_execution_role\u0026quot; assume_role_policy = \u0026lt;\u0026lt;EOF { \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Sid\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Principal\u0026quot;: { \u0026quot;Service\u0026quot;: [ \u0026quot;ecs-tasks.amazonaws.com\u0026quot; ] }, \u0026quot;Action\u0026quot;: \u0026quot;sts:AssumeRole\u0026quot; } ] } EOF } resource \u0026quot;aws_iam_role_policy_attachment\u0026quot; \u0026quot;ecs-task-execution-policy\u0026quot; { role = \u0026quot;${aws_iam_role.ecs_task_execution_role.name}\u0026quot; policy_arn = \u0026quot;arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\u0026quot; } resource \u0026quot;aws_iam_role_policy_attachment\u0026quot; \u0026quot;ecr-read-policy\u0026quot; { role = \u0026quot;${aws_iam_role.ecs_task_execution_role.name}\u0026quot; policy_arn = \u0026quot;arn:aws:iam::aws:policy/AmazonSSMReadOnlyAccess\u0026quot; } # Task Definition # https://www.terraform.io/docs/providers/aws/r/ecs_task_definition.html resource \u0026quot;aws_ecs_task_definition\u0026quot; \u0026quot;main\u0026quot; { family = \u0026quot;${var.prefix}\u0026quot; # データプレーンの選択 requires_compatibilities = [\u0026quot;FARGATE\u0026quot;] # ECSタスクが使用可能なリソースの上限 # タスク内のコンテナはこの上限内に使用するリソースを収める必要があり # メモリが上限に達した場合OOM Killer にタスクがキルされる cpu = \u0026quot;256\u0026quot; memory = \u0026quot;512\u0026quot; # ECSタスクのネットワークドライバ # Fargateを使用する場合は\u0026quot;awsvpc\u0026quot;決め打ち network_mode = \u0026quot;awsvpc\u0026quot; # ECRからDocker ImageをPULLするための権限 execution_role_arn = \u0026quot;${aws_iam_role.ecs_task_execution_role.arn}\u0026quot; # 起動するコンテナの定義 # 【解説1】JSONでコンテナを定義します # 【解説2】JSON内の environment で環境変数を設定します。 # environment ではデータベースのホストを設定しています。 # 機密情報（次の項目で設定します）として登録するか迷いましたが、 # 機密情報だとパラメータストアを経由する必要があり、 # 手動設定が必要になるので、環境変数にしました。 # プライベートサブネットに入ってるので大丈夫だと考えています。 # 【解説3】JSON内の secrets で機密情報を設定します。 # 今回はよく使いそうなものを適当に定義しました。 # 機密情報 は System Manager のパラメータストアから持ってきます。 container_definitions = \u0026lt;\u0026lt;EOL [ { \u0026quot;name\u0026quot;: \u0026quot;\u0026lt;your repository name\u0026gt;\u0026quot;, \u0026quot;image\u0026quot;: \u0026quot;\u0026lt;your image name\u0026gt;\u0026quot;, \u0026quot;portMappings\u0026quot;: [ { \u0026quot;containerPort\u0026quot;: 8080, \u0026quot;hostPort\u0026quot;: 8080 } ], \u0026quot;environment\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;MYSQL_HOST\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;${aws_rds_cluster.this.endpoint}\u0026quot; } ], \u0026quot;secrets\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;MYSQL_PASSWORD\u0026quot;, \u0026quot;valueFrom\u0026quot;: \u0026quot;arn:aws:ssm:ap-northeast-1:910114278227:parameter/MYSQL_PASSWORD\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;MYSQL_USER\u0026quot;, \u0026quot;valueFrom\u0026quot;: \u0026quot;arn:aws:ssm:ap-northeast-1:910114278227:parameter/MYSQL_USER\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;MYSQL_DATABASE\u0026quot;, \u0026quot;valueFrom\u0026quot;: \u0026quot;arn:aws:ssm:ap-northeast-1:910114278227:parameter/MYSQL_DATABASE\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;AWS_ACCESS_KEY\u0026quot;, \u0026quot;valueFrom\u0026quot;: \u0026quot;arn:aws:ssm:ap-northeast-1:910114278227:parameter/ACCESS_KEY\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;AWS_SECRET_KEY\u0026quot;, \u0026quot;valueFrom\u0026quot;: \u0026quot;arn:aws:ssm:ap-northeast-1:910114278227:parameter/SECRET_KEY\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;S3_BUCKET_NAME\u0026quot;, \u0026quot;valueFrom\u0026quot;: \u0026quot;arn:aws:ssm:ap-northeast-1:910114278227:parameter/S3_BUCKET_NAME\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;AUTH_SECRET\u0026quot;, \u0026quot;valueFrom\u0026quot;: \u0026quot;arn:aws:ssm:ap-northeast-1:910114278227:parameter/AUTH_SECRET\u0026quot; } ] } ] EOL } # ECS Cluster # https://www.terraform.io/docs/providers/aws/r/ecs_cluster.html resource \u0026quot;aws_ecs_cluster\u0026quot; \u0026quot;main\u0026quot; { name = \u0026quot;${var.prefix}\u0026quot; } # ELB Target Group # https://www.terraform.io/docs/providers/aws/r/lb_target_group.html resource \u0026quot;aws_lb_target_group\u0026quot; \u0026quot;main\u0026quot; { name = \u0026quot;${var.prefix}\u0026quot; # ターゲットグループを作成するVPC vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; # ALBからECSタスクのコンテナへトラフィックを振り分ける設定 port = 8080 protocol = \u0026quot;HTTP\u0026quot; target_type = \u0026quot;ip\u0026quot; # コンテナへの死活監視設定 health_check = { port = 8080 path = \u0026quot;/health\u0026quot; } } # ALB Listener Rule # https://www.terraform.io/docs/providers/aws/r/lb_listener_rule.html resource \u0026quot;aws_lb_listener_rule\u0026quot; \u0026quot;main\u0026quot; { # ルールを追加するリスナー listener_arn = \u0026quot;${aws_lb_listener.main.arn}\u0026quot; # 受け取ったトラフィックをターゲットグループへ受け渡す action { type = \u0026quot;forward\u0026quot; target_group_arn = \u0026quot;${aws_lb_target_group.main.id}\u0026quot; } # ターゲットグループへ受け渡すトラフィックの条件 condition { field = \u0026quot;path-pattern\u0026quot; values = [\u0026quot;*\u0026quot;] } } # SecurityGroup # https://www.terraform.io/docs/providers/aws/r/security_group.html resource \u0026quot;aws_security_group\u0026quot; \u0026quot;ecs\u0026quot; { name = \u0026quot;${var.prefix}-ecs\u0026quot; description = \u0026quot;${var.prefix} ecs\u0026quot; # セキュリティグループを配置するVPC vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; # セキュリティグループ内のリソースからインターネットへのアクセス許可設定 # 今回の場合DockerHubへのPullに使用する。 egress { from_port = 0 to_port = 0 protocol = \u0026quot;-1\u0026quot; cidr_blocks = [\u0026quot;0.0.0.0/0\u0026quot;] } tags = { Name = \u0026quot;${var.prefix}-ecs\u0026quot; } } # SecurityGroup Rule # https://www.terraform.io/docs/providers/aws/r/security_group.html resource \u0026quot;aws_security_group_rule\u0026quot; \u0026quot;ecs\u0026quot; { security_group_id = \u0026quot;${aws_security_group.ecs.id}\u0026quot; # インターネットからセキュリティグループ内のリソースへのアクセス許可設定 type = \u0026quot;ingress\u0026quot; # TCPでの80ポートへのアクセスを許可する from_port = 80 to_port = 8080 protocol = \u0026quot;tcp\u0026quot; # 同一VPC内からのアクセスのみ許可 cidr_blocks = [\u0026quot;10.0.0.0/16\u0026quot;] } # ECS Service # https://www.terraform.io/docs/providers/aws/r/ecs_service.html resource \u0026quot;aws_ecs_service\u0026quot; \u0026quot;main\u0026quot; { name = \u0026quot;${var.prefix}\u0026quot; # 依存関係の記述。 # \u0026quot;aws_lb_listener_rule.main\u0026quot; リソースの作成が完了するのを待ってから当該リソースの作成を開始する。 # \u0026quot;depends_on\u0026quot; は \u0026quot;aws_ecs_service\u0026quot; リソース専用のプロパティではなく、Terraformのシンタックスのため他の\u0026quot;resource\u0026quot;でも使用可能 depends_on = [\u0026quot;aws_lb_listener_rule.main\u0026quot;] # 当該ECSサービスを配置するECSクラスターの指定 cluster = \u0026quot;${aws_ecs_cluster.main.name}\u0026quot; # データプレーンとしてFargateを使用する launch_type = \u0026quot;FARGATE\u0026quot; # ECSタスクの起動数を定義 desired_count = \u0026quot;1\u0026quot; # 起動するECSタスクのタスク定義 task_definition = \u0026quot;${aws_ecs_task_definition.main.arn}\u0026quot; # ECSタスクへ設定するネットワークの設定 network_configuration = { # タスクの起動を許可するサブネット subnets = [\u0026quot;${aws_subnet.private_1a.id}\u0026quot;, \u0026quot;${aws_subnet.private_1c.id}\u0026quot;, \u0026quot;${aws_subnet.private_1d.id}\u0026quot;] # タスクに紐付けるセキュリティグループ security_groups = [\u0026quot;${aws_security_group.ecs.id}\u0026quot;] } # ECSタスクの起動後に紐付けるELBターゲットグループ load_balancer = [ { target_group_arn = \u0026quot;${aws_lb_target_group.main.arn}\u0026quot; container_name = \u0026quot;\u0026lt;your container name\u0026gt;\u0026quot; container_port = \u0026quot;8080\u0026quot; }, ] }  機密情報を渡すところに関しては こちら の記事が分かりやすいです。\n機密情報として設定する値は System Manager のパラメータストアにセットする必要があります。\nRDSの設定 最後に rds.tf を以下のとおり定義します。\n# SSM Parameter data source # https://www.terraform.io/docs/providers/aws/d/ssm_parameter.html data \u0026quot;aws_ssm_parameter\u0026quot; \u0026quot;database_name\u0026quot; { name = \u0026quot;MYSQL_DATABASE\u0026quot; } data \u0026quot;aws_ssm_parameter\u0026quot; \u0026quot;database_user\u0026quot; { name = \u0026quot;MYSQL_USER\u0026quot; } data \u0026quot;aws_ssm_parameter\u0026quot; \u0026quot;database_password\u0026quot; { name = \u0026quot;MYSQL_PASSWORD\u0026quot; } # 【解説】locals は名前のとおりローカル変数です。 # variables だと `${}` 展開できないのでこちらを使用しました。 # 他にやり方があれば教えてほしいです。 locals { name = \u0026quot;${var.prefix}-rds-mysql\u0026quot; } resource \u0026quot;aws_security_group\u0026quot; \u0026quot;this\u0026quot; { name = \u0026quot;${local.name}\u0026quot; description = \u0026quot;${local.name}\u0026quot; vpc_id = \u0026quot;${aws_vpc.main.id}\u0026quot; egress { from_port = 0 to_port = 0 protocol = \u0026quot;-1\u0026quot; cidr_blocks = [\u0026quot;0.0.0.0/0\u0026quot;] } tags = { Name = \u0026quot;${local.name}\u0026quot; } } resource \u0026quot;aws_security_group_rule\u0026quot; \u0026quot;mysql\u0026quot; { security_group_id = \u0026quot;${aws_security_group.this.id}\u0026quot; type = \u0026quot;ingress\u0026quot; from_port = 3306 to_port = 3306 protocol = \u0026quot;tcp\u0026quot; cidr_blocks = [\u0026quot;10.0.0.0/16\u0026quot;] } resource \u0026quot;aws_db_subnet_group\u0026quot; \u0026quot;this\u0026quot; { name = \u0026quot;${local.name}\u0026quot; description = \u0026quot;${local.name}\u0026quot; subnet_ids = [ \u0026quot;${aws_subnet.private_1a.id}\u0026quot;, \u0026quot;${aws_subnet.private_1c.id}\u0026quot;, \u0026quot;${aws_subnet.private_1d.id}\u0026quot;, ] } # RDS Cluster # https://www.terraform.io/docs/providers/aws/r/rds_cluster.html resource \u0026quot;aws_rds_cluster\u0026quot; \u0026quot;this\u0026quot; { cluster_identifier = \u0026quot;${local.name}\u0026quot; db_subnet_group_name = \u0026quot;${aws_db_subnet_group.this.name}\u0026quot; vpc_security_group_ids = [\u0026quot;${aws_security_group.this.id}\u0026quot;] engine = \u0026quot;aurora-mysql\u0026quot; port = \u0026quot;3306\u0026quot; database_name = \u0026quot;${data.aws_ssm_parameter.database_name.value}\u0026quot; master_username = \u0026quot;${data.aws_ssm_parameter.database_user.value}\u0026quot; master_password = \u0026quot;${data.aws_ssm_parameter.database_password.value}\u0026quot; # RDSインスタンス削除時のスナップショットの取得強制を無効化 skip_final_snapshot = true # 使用する Parameter Group を指定 db_cluster_parameter_group_name = \u0026quot;${aws_rds_cluster_parameter_group.this.name}\u0026quot; } # RDS Cluster Instance # https://www.terraform.io/docs/providers/aws/r/rds_cluster_instance.html resource \u0026quot;aws_rds_cluster_instance\u0026quot; \u0026quot;this\u0026quot; { identifier = \u0026quot;${local.name}\u0026quot; cluster_identifier = \u0026quot;${aws_rds_cluster.this.id}\u0026quot; engine = \u0026quot;aurora-mysql\u0026quot; instance_class = \u0026quot;db.t3.small\u0026quot; } # RDS Cluster Parameter Group # https://www.terraform.io/docs/providers/aws/r/rds_cluster_parameter_group.html # 日本時間に変更 \u0026amp; 日本語対応のために文字コードを変更 resource \u0026quot;aws_rds_cluster_parameter_group\u0026quot; \u0026quot;this\u0026quot; { name = \u0026quot;${local.name}\u0026quot; family = \u0026quot;aurora-mysql5.7\u0026quot; parameter { name = \u0026quot;time_zone\u0026quot; value = \u0026quot;Asia/Tokyo\u0026quot; } parameter { name = \u0026quot;character_set_client\u0026quot; value = \u0026quot;utf8mb4\u0026quot; } parameter { name = \u0026quot;character_set_connection\u0026quot; value = \u0026quot;utf8mb4\u0026quot; } parameter { name = \u0026quot;character_set_database\u0026quot; value = \u0026quot;utf8mb4\u0026quot; } parameter { name = \u0026quot;character_set_results\u0026quot; value = \u0026quot;utf8mb4\u0026quot; } parameter { name = \u0026quot;character_set_server\u0026quot; value = \u0026quot;utf8mb4\u0026quot; } } # terraform applyコマンド完了時にコンソールにエンドポイントを表示 # 【解説】もしエンドポイントも機密情報として扱うのであれば # ここで表示されたエンドポイントをパラメータストアに格納すればよい。 # 今回は紹介のために使用。 output \u0026quot;rds_endpoint\u0026quot; { value = \u0026quot;${aws_rds_cluster.this.endpoint}\u0026quot; }  テスト 上記で作成してきた tfファイルたちを同じディレクトリに格納し、\nそのディレクトリ内で下記コマンドを実行します。\nAWS_ACCESS_KEY_ID=\u0026lt;your access key\u0026gt; AWS_SECRET_ACCESS_KEY=\u0026lt;your secret access key\u0026gt; terraform apply\nアクセスキーとシークレットキーは IAM から取得してください。\nterraform コマンドが入ってない人は brew やらなんやらでインストールお願いします。\n実行して（かなり時間がかかりますが）下記のように出力されたら成功です！\n削除もやってみましょう。\nAWS_ACCESS_KEY_ID=\u0026lt;your access key\u0026gt; AWS_SECRET_ACCESS_KEY=\u0026lt;your secret access key\u0026gt; terraform destroy\nこちらもかなり時間がかかりますが、下記のようにリソースが削除されると思います。\ntfファイルの実行順 tfファイル内で作成したリソースから取得した値を他のリソースで使用する場面がありました。\nここで気になるのが tfファイルの実行順番です。\n実行順番次第では、取得したい値がまだできていないということも起こりそうです。\nこれに関して、結論から言うと僕たちが順番を考える必要はありません。\ntfファイルを適当にディレクトリに突っ込んだだけですが、\nterraform 側でよしなに順番を決めてやってくれます。\nすごい。\nまとめ Terraformすごい。\n自動でここまでできてしまう。\nしかも、コードで定義するからバージョン管理できる。\n差分チェックできる。\n「分かる、こいつ強い。」\n今回はファイル分割しただけですが、モジュール分割とかもできるようなので今後やっていきます。\n","ref":"/tech-blog/blog/terraform_ecs/"},{"title":"【Android + Kotlin + Firebase】Androidアプリにプッシュ通知を実装してみた","date":"","description":"","body":"僕がひっかかった場所は 「つまづきポイント」 という章にまとめているので\nなにか困ったときはそこを一度見てみてください。\ntl;dr  Firebase使ってAndroidアプリにプッシュ通知を実装した フォアグラウンドとバックグラウンドで表示方法が異なる めちゃくちゃ簡単  開発環境  macOS Mojave 10.14.4 Android Studio 3.4.1 Gradle 3.4.1 Java 1.8.0_202 Kotlin 1.3.21  Firebaseに登録 Firebaseを使用するためには登録が必要です。\nGoogleアカウントを持っている方なら公式サイト から簡単に登録できます\nFirebaseにプロジェクト作成 プロジェクト登録ページ でプロジェクトを登録します。\nプロジェクト名は特に指定はありません。ご自由にどうぞ。\nアプリ情報を登録する プロジェクト選択後のホーム画面より 「Project Overview」 をクリック。\n画面の指示に従って進めていてください。\nデバッグ用の署名証明書 SHA-1 の取得方法   以下コマンドを実行\nMac/Linux\nkeytool -list -v \\ -alias androiddebugkey -keystore ~/.android/debug.keystore  Windows\nkeytool -list -v \\ -alias androiddebugkey -keystore %USERPROFILE%\\.android\\debug.keystore    パスワード入力\nパスワードは android です。\n  表示される SHA-1 をメモ\n   ひととおり作業が進むと、↓このような画面が表示されます。\n自分の環境では、登録したアプリがFirebaseと通信できているかのチェックに少し時間がかかりました。\nエミュレータでもちゃんと通信してくれるか不安だったのですが大丈夫でした。\nFirebase 関連のライブラリを追加 アプリ情報の登録工程において、 app/build.gradle を触ったと思いますが、加えて、以下の追記が必要です。\ndependencies { // ... 省略 implementation 'com.google.firebase:firebase-messaging:18.0.0' }  バージョン17.1.0 以降に関して、 こちらの記事 にあるとおり、大きな変更が加わっています。\n注意しましょう。\n通知時の見た目の設定（バックグラウンド動作時） PUSH通知の見た目はバックグラウンドとフォアグラウンドで違います。\nフォアグラウンドでのPUSH通知は自分のアプリの処理を通りますが、\nバックグラウンドではアプリで定義した処理を通りません。\nまずはバックグラウンドの見た目を設定していきます。\nAndroidManifest.xml に下記のとおり追記してください。\n\u0026lt;application // ... 省略 \u0026gt; // ... 省略 \u0026lt;meta-data android:name=\u0026quot;com.google.firebase.messaging.default_notification_channel_id\u0026quot; android:value=\u0026quot;@string/channel_id\u0026quot;/\u0026gt; \u0026lt;meta-data android:name=\u0026quot;com.google.firebase.messaging.default_notification_icon\u0026quot; android:resource=\u0026quot;@drawable/ic_logo\u0026quot; /\u0026gt; \u0026lt;meta-data android:name=\u0026quot;com.google.firebase.messaging.default_notification_color\u0026quot; android:resource=\u0026quot;@color/background\u0026quot; /\u0026gt; // ... 省略  ここでチャンネルIDと通知アイコン、色を決定します。\n各自で自由に設定してください。\n チャンネルID は Android 8.0（API レベル 26）以降で設定が必須となりました。\n  チャンネルを指定することで、ユーザーが任意の通知チャンネルを無効にすることが可能になります。\n  参考サイト   ★ Android 8.0 未満であれば気にしなくて大丈夫です。\n 動作テスト 以上でバックグラウンドでの通知は受け取れるようになりました。\nCloud Messaging 画面に行き、「Send your first message」から通知を作成します。\n  通知のタイトルとメッセージを設定します。\n  ターゲットは自分のアプリを選択してください。\n  スケジュールは Now です。\n  今回はコンバージョンイベントはなにも触りません。\n  その他のオプションはチャンネルIDだけ設定します（Android8.0以上の人のみ）\n  「確認」 \u0026gt; 「公開」 で通知が送られます。\n  Android側で通知を受け取れているか確認しましょう。\n注意としては、現状バックグラウンドでの処理しか記述していないので\nアプリを開いていると通知を受け取れません。\nアプリを閉じた状態で通知を送りましょう。\nすると…\n通知が来ましたね！ 音もついています。\n\u0026lt;img src=\u0026quot;https://yyh-gl.github.io/tech-blog/img/tech-blog/2019/05/android_push/bar.png\u0026quot; width=\u0026quot;250\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;https://yyh-gl.github.io/tech-blog/img/tech-blog/2019/05/android_push/notification_center.png\u0026quot; width=\u0026quot;250\u0026quot;\u0026gt;   ステータスバーにもアイコンが表示されています（鳥のマークです）。\nでも、アプリ立ち上げた状態（フォアグラウンド）だと通知来ないですよね？\n表示できるようにしていきましょう。\n通知時の見た目の設定（フォアグラウンド動作時） 各自の適当な場所に以下の Service を作成してください。\npackage \u0026lt;パッケージ名\u0026gt; import android.app.Notification import android.app.NotificationChannel import android.app.NotificationManager import android.app.PendingIntent import android.content.Context import android.content.Intent import android.media.RingtoneManager import android.os.Build import androidx.core.app.NotificationCompat import androidx.core.app.NotificationCompat.PRIORITY_MAX import com.google.firebase.messaging.FirebaseMessagingService import com.google.firebase.messaging.RemoteMessage import java.util.* class PushNotificationListenerService: FirebaseMessagingService() { // 新しいトークンが生成された時の処理 // 中でサーバにトークンを送信する処理などを定義 override fun onNewToken(p0: String?) { super.onNewToken(p0) // チャンネルidを設定 addChannelId() } // 通知を受信したときの処理 override fun onMessageReceived(message: RemoteMessage?) { super.onMessageReceived(message) // 今回は通知からタイトルと本文を取得 val title: String = message?.notification?.title.toString() val text: String = message?.notification?.body.toString() // 通知表示 sendNotification(title, text) } // 通知表示 および 見た目の設定 private fun sendNotification(title: String, text: String) { // 通知タップ時に遷移するアクティビティを指定 val intent = Intent(this, AllTimelineActivity::class.java) intent.addFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP) // 何度も遷移しないようにする（1度だけ！） val pendingIntent: PendingIntent = PendingIntent.getActivity(this,0, intent, PendingIntent.FLAG_ONE_SHOT) // 通知メッセージのスタイルを設定（改行表示に対応） val inboxStyle = NotificationCompat.InboxStyle() val messageArray: List\u0026lt;String\u0026gt; = text.split(\u0026quot;\\n\u0026quot;) for (msg: String in messageArray) { inboxStyle.addLine(msg) } // 通知音の設定 val defaultSoundUri = RingtoneManager.getDefaultUri(RingtoneManager.TYPE_NOTIFICATION) // 通知の見た目を設定 val notificationBuilder = NotificationCompat.Builder(this, resources.getString(R.string.channel_id)) .setContentTitle(title) .setContentText(text) // ステータスバーに表示されるアイコン .setSmallIcon(R.drawable.ic_notification_icon) // 上で設定したpendingIntentを設定 .setContentIntent(pendingIntent) // 優先度を最大化 .setPriority(PRIORITY_MAX) // 通知音を出すように設定 .setSound(defaultSoundUri) // 通知を実施 // UUIDを付与することで各通知をユニーク化 val notificationManager: NotificationManager = getSystemService(Context.NOTIFICATION_SERVICE) as NotificationManager val uuid = UUID.randomUUID().hashCode() notificationManager.notify(uuid, notificationBuilder.build()) // Android 8.0 以上はチャンネル設定 必須 // strings.xml に channel_id を指定してください if (Build.VERSION.SDK_INT \u0026gt;= Build.VERSION_CODES.O) { notificationBuilder.setChannelId(resources.getString(R.string.channel_id)) } } // チャンネルの設定 private fun addChannelId() { if (Build.VERSION.SDK_INT \u0026gt;= Build.VERSION_CODES.O) { val manager = getSystemService(Context.NOTIFICATION_SERVICE) as NotificationManager // ヘッドアップ通知を出す場合はチャンネルの重要度を最大にする必要がある val channel = NotificationChannel( resources.getString(R.string.channel_id), resources.getString(R.string.channel_name), NotificationManager.IMPORTANCE_HIGH ) // ロック画面における表示レベル channel.lockscreenVisibility = Notification.VISIBILITY_PUBLIC // チャンネル登録 manager.createNotificationChannel(channel) } } }  上記コードは 本サイト を参考にしました。\n古いバージョンの情報部分を書き換えたりしています。\nAndroidManifest を修正 ↑で実装した Service をマニフェストに登録し、使えるようにします。\nAndroidManifest.xml に以下の設定を追記します。\n\u0026lt;application // ... 省略 \u0026gt; \u0026lt;service android:name=\u0026quot;.PushNotificationListenerService\u0026quot;\u0026gt; \u0026lt;intent-filter\u0026gt; \u0026lt;action android:name=\u0026quot;com.google.firebase.MESSAGING_EVENT\u0026quot; /\u0026gt; \u0026lt;/intent-filter\u0026gt; \u0026lt;/service\u0026gt; // ... 省略 \u0026lt;/application\u0026gt;  android:name は各自のディレクトリ構成とファイル名に合わせて変更してください。\n動作テスト 以上でフォアグラウンドにおける通知の設定が完了しました。\n通知を受け取れるかテストしてみましょう。\nバックグラウンドでのテストと同様の手順で Cloud Messaging から通知を送ります。\nすると…\n無事表示できましたね！\nステータスバーにもアイコンが出ています。\n アプリ画面は見せれないので隠しています\n  ちょっとフォアグラウンドなのか分かりづらいと思いますが、 フォアグラウンドです。\n つまづきポイント バックグラウンドとフォアグラウンドどちらにおいても、通知がうまく表示されないときがありました。\n具体的には\n そもそも通知がこない フォアグラウンドにて画面上部から通知がぴこって出てこない  などです。\n原因ですが、僕の結論は エミュレータでテストしていたこと です。\nエミュレータで通知を受け取れない状況において、実機でも通知を受け取ってみたところ、\n実機では正常に通知を受け取ることができました。\nみなさんもエミュレータでテストするさいはお気をつけください。\n（それにしてもなんで無理だったんだろうか… また調べてみよう）\nまとめ PUSH通知実装いかかがだったでしょうか？\n僕的にはとても簡単で驚きしかありませんでした。\nFirebaseさまさまですね。\n実際の業務に使えるかと言われると、また話が違ってくるのかもしれませんが、、、\n参考サイト  公式ドキュメント  【Android】FCMを使ったpush通知の実装方法 - 株式会社Villness（ヴィルネス）   ","ref":"/tech-blog/blog/android_push/"},{"title":"【エンジニアリング組織論への招待】メンタリングの技術","date":"","description":"","body":"概要 今回は、広木 大地さんが書かれた 『エンジニアリング組織論への招待 不確実性に向き合う思考と組織のリファクタリング』 という本から、\n2章「メンタリングの技術」についてまとめます。\n（初投稿の内容が技術系じゃなくてチームマネジメント系かよとか言わないでくださいね）\n最初に覚えておいてほしいこと メンタリングは、自律的な人材を育むために行う。\nそのために、下記3点の状態にメンティ自身からなれるように導く。\n 自分の気がつかなかった問題に気がつくようになる 認知の歪みによる感情と問題の癒着を切り離せる 答えではなく、次の一手を生み出す行動が取れるようになる  これらがとても重要です。\n以下いろいろな話が出てきますが、結局は上記3点の状態を実現するための方法です。\nここをしっかりと意識して読んでいただければ、\nより一層理解が深まると思います。\n以下まとめ （★マークは個人的解釈・感想です）\nそもそもメンタリングとは  相手を上から押し付けるような教育方法ではない 相手の考え方を少しずつ変えることで、問題解決の力を育む手法  対話を通じて、以下の2点を行い、相手を成長させる。\n 歪んだ認知を補正 次の行動を促進  メンタリングと聞くと、\n大学で何年も学ばないと身に着けられないような技術であると思いがちだが、\n体得すればだれでもできるようになる。\nエンジニアリングにおけるメンタリングの重要性 エンジニアリングは知識が全てではない エンジニアリングでは技術的な課題がよく取り上げられるが、\n技術的な課題というのは心理的な課題と密接に関係している。\n例えば、\n ソフトウェア開発はチームプレイ   ★ 技術的な課題解決だけでなく、人間関係とかもあるってことかな\n  各個人の開発における問題解決は、自分自身との対話によって制御するもの   ★ 自身を制すものがエラーを制す\n 上記のようにエンジニアリングには心理的な課題も存在する。\nプロダクト開発では 不確実性を排除する ことがとても重要である。\nしたがって、不確実性のひとつである心理的な課題は排除すべき対象である。\n ★ だから、メンタリングが重要なんですね。\n メンタリングは 自ら考える人材を作る ためのテクニック 自立型人材と依存型人材 自ら考える人材を自立型人材、そうでない人材を依存型人材とすると、\nそれぞれ下記のような特徴がある。\n 自立型人材  自ら問題を発見し、解決することができる 問題について、自分ごととして捉えている 問題の根本的原因は自分にあると考える  改善のために行動できる     依存型人材  問題を与えられてから考える 問題と解決策を渡されてから動ける 問題の根本的原因は他人にあると考える  改善のために行動できず、他人のせいにしてしまう      両人材の境界線 多くの人は時には自立型人材、しかし、ある場面では依存型人材になってしまう。\nそれが普通である。\n大事なのは、 上司と部下という関係における期待値を合わせておくこと。\nつまり、上司が 「ここまでは自律的に考えるのが自分の仕事だ」と考える期待値と、\n部下の「ここまでは自律的に考えるのが自分の仕事だ」と考える2つの期待値が一致させておくことが重要ということ。\n ★ 自分的にはここがとても大事だと思った。全部自律的に考えるなんて無理だと思う。人間だもの。でも、上司と部下、さらには企業と社員の関係性はこの期待値を合わせることがとても重要だと思う。\n したがって、2つの期待値に差異があるままに、\n上司は部下を自律的でないと判断するのは誤っているし、\n部下も上司を理不尽なことを言う人と判断してはいけない。\nコンフォートゾーン 人は与えられた役割に対して、自分の思考を閉じてしまうという特徴を持つ。\nそして、与えられた役割の中で、自分自身が心地よくいられる思考や行動の範囲のことを\nコンフォートゾーンという。\n例えば、与えられた仕事は自律的に完璧にこなす人も、\n選挙は他の人が投票してくれるからいいやと依存的になるなど。\n ★ 難しいことを言っているように聞こえるが、 結局のところ、自分の役職や割り当てられたタスクの範囲内の仕事はしっかりとやるが、 範囲外のところに関しては一切やらない、ってことだと思う。\n 人はコンフォートゾーンをなかなか変えることができない。\nコンフォートゾーンが変わる瞬間 自立型 → 依存型 例えば、自律的にいろいろな提案をして熱意に燃えていた人が、\n何度も提案を却下され、熱意を失い、\n最終的に何をしても無駄だと考えるようになった結果、\n依存型人材になることが考えられる。\nこのように負のフィードバックリサイクルの結果、\n生まれてしまう無気力を「学習性無気力」という。\n依存型 → 自立型 逆に、自ら動いた結果、評価されたり、周囲からの尊敬を集めるなど、\n正のフィードバックの中に「自律的に動くことは楽しい」といった気持ちが芽生え、\n自立型人材になることが考えられる。\nこのとき感じた「自律的に動くことは楽しい」という気持ちを「自己効力感」という。\n ★ つまり、正のフィードバックサイクルがしっかりと回れば、自立型人材が増えてくるのか…どうすれば正のフィードバックサイクルを回せれるようになるんだろう。\n 無意識に可能性を狭めてしまう人々 人は誰しも自分自身の思考の範囲を無意識に狭めてしまい、\nその結果最適な解決策が見えなくなってしまう。\nすなわち、閉じた世界の中での合理性（限定合理性）に人々は縛られている。\n人は閉じた世界の中で考えることは「心地よい」と考える。\n ★ 与えられた仕事以外に変に手を出したら、やっかいごとが増えるし、 だったら、何もしないでおこうってなるよね\n メンタリングによる世界（可能性）の拡張 メンタリングとは、対話によって思考の範囲を限定する枠を取り外し、\nその人が自らの力で問題解決できるように促す方法である。\nメンタリングを行う人は、自律的な思考を行うことの快感（自己効力感）が、\n依存的な思考を行う快感（コンフォートゾーン）を上回るように導く。\n効果的なメンターとメンティの関係性  メンター：メンタリングする人\n  メンティ：メンタリングを受ける人\n 以下の3点が守れている上で行うメンタリングが最も効果的\n（頭文字をとって HRT（ハート）と呼ばれる）\n 謙虚（Humility）：お互いに弱さを見せられる 敬意（Respect）：お互いに敬意を持っている 信頼（Trust）：お互いにメンティ（自身）の成長期待をもっている  形だけのメンタリング制度は不要 形だけのメンタリングは、\nメンターが「なにか課題を指摘する」場になってしまうことが多い。\n理想のメンタリングは、課題に一緒に向き合い成長を支援するというコミットが必要。\nそれがメンティに伝わらなければ、メンター自体が成長を阻害する可能性が出てくる。\n成長の手助けにおいて重要なこと メンターがメンティの成長を手助けするためには、次の3点をしっかりやることが必要。\n 課題を認識させる  「課題があるよ」ではなく、「これは大丈夫？」と聞くことで、メンティ自身に課題を発見させる   課題解決へのヒントを与える  課題解決までの道のりを一気にではなく、一歩ずつ確実に歩いている実感を与える   課題解決したくなるようにする  小さな成長実感に加えて、大きな目標達成やゴールの認識を合わせる    他者説得 ではなく 自己説得 メンタリングとティーチング（直接物事を教えること）を比べて優れている点は、\nメンティに応用力がつくことである。\nメンタリングでは、メンティが考え、自ら知識を獲得しることを促すため、応用力が身につく。\nよって、メンタリングは人に与えられた説得による知識（他者説得）よりも、\n自ら気づいたこと（自己説得）を重視する。\nメンターによる自己説得の促進 メンターは答えを言うのではなく質問を繰り返す。\nそして、それらの質問からメンティ自身が答えを導き出す。\nこれが重要。\n「考える」と「悩む」の違い 「考える」と「悩む」はどちらも問題に直面しているときに起こる行動であるが以下のような違いがある。\n考える 問題に対して「次にやるべき行動」がはっきりしているため、\nホワイトボードに課題を書き出し頭を整理するなどといった問題解決のための行動を取ることができる。\n悩む 問題に対して「次にやるべき行動」がはっきりしていないため、\n基本的には手が止まってしまう。\n手が止まっている状況が続くようであれば、それは悩んでいる人である。\nメンティが行動できていないときに、\nメンターは 「悩み」を聞き出し、気づきを促して「考える」に変える 必要がある。\nメンタリングの基本技術 「傾聴」 よく悩み相談で「話したらすっきりした」という感想がでるのは、\n人が話をするときは、必ず話すことを整理する必要があるため、\n人に話すことで自然と頭の中が整理できるからである。\nつまり、何に困っているのかが明確になり、次にやるべきことが見えてくる。\n ★「悩む」から「考える」に変わるということですね。\n  もしかして、悩み相談ってメンタリングしてるだけ…？\n 傾聴 悩み相談の例のように、人の話を聞いてあげることで、その人の問題を解決することが可能。\nしかし、「ただ話を聞くこと」と「傾聴」には違いがある。\n  ただ話を聞くこと\n 特に目的というものはなく、自分の意識を出してしまいがち  自分の意見を言う 自分の興味のあることを質問する 自分に興味のないことには興味がなさそうな素振りをする      傾聴\n 相手の思考が整理され、前向きに考えられるように支援することが目的  相手の感情への共感を言動で表す 相手の話の内容を可視化する 相手の思考の盲点を探索しながら質問をする      話を聞くのが上手い人とは、 相手の立場になって話を聞くことができる真摯さがある人です。\n傾聴で重要な要素  しぐさ・うなずき・座り方 表情 あいづち 気が付かない信号を指摘してもらう （★ 細かな気遣いをしようってことですかね）  PCでメモを取る前に一言いっておくなど    共感と同感の違い 同感は相手と同じ気持ちになること。\n共感とは相手を理解すること。\n傾聴で重要なのは共感であり、「なるほど、だからあなたは今そのような感情なのですね」と\n相手を理解してあげることが大事。\n ★ めちゃくちゃなるほどって思った。\n  確かに話を聞くのがうまい人はよく共感してくれる。\n 問題の可視化と明晰化 問題の可視化と明晰化は、メンターとメンティの対話を通じて、\n簡単な問題に変換するためのテクニックである。\n可視化 傾聴によりある程度問題の形が見えてきたら、次は問題を可視化する。\n問題の可視化により、メンティは自分が抱えている問題を客観視することができる。\n明晰化 可視化の過程で、感情的に固執してしまっている要素を引き剥がし、\n本来の問題が何であるのかをはっきりさせる。\n可視化と明晰化のテクニック ・ 事実と意見を分ける 可視化対象は事実だけでよい\n・ フォーカスポイントを作る 難しい問題も問題の範囲を限定し、ひとつずつ対処していく\n・ 比較可能な問題に変換 複数の選択肢がある場合に「比較する軸」を示してあげることで、解決可能な問題に変える\n認知フレームとリフレミング 認知フレーム 人は物事を認知する枠組みを持っており、その枠組の中でしか情報を処理できない。\n例えば、家の鍵をなくしたとき。本当はポケットに入っているのに、焦りから見つけることができない。\nこのような認知の枠組みを 認知フレーム という。\nこの認知フレームが邪魔して、問題を解けない問題化してしまう人が多い。\nこのようなときには、後述するリフレミングにより認知フレームを変える必要がある。\n ★ 認知フレームを変えることで、「解けない問題」を「解ける問題」に変換可能\n リフレミング 認知フレームは簡単に変えることが可能である。\n例えば、先ほどの鍵をなくしたときの例で、鍵が緑色だとしたら、\n「今、あなたの周りにある緑色のものを探してください」といえば、\nさっきまで気にしていなかった緑色のものが目に入ってくるようになり、鍵が見つかるだろう。\nこのように、対話によって認知フレームは変えることが可能であり、\n対話による認知フレームの変更をリフレーミングという。\n情報の非対称性の解消 情報の非対称性とは下記のような状況のことをいう。\n 自分は分かっているが、相手は分かっていない 相手は分かっているかもしれないけど、自分はわかっていない  これを解消するには、\n 自分が持つ情報を相手に伝える 相手が持つ情報を自分が聞く  ということをしっかりする。\n（上記の行動はあたりまえのことですが、\n「上司は優秀な人だから分かっているに違いない」といった認知フレームが邪魔してなかなかできません。）\n課題の分離 1つの課題に見えても、本当は複数の課題の集合体であることがある。\nこのときメンターはメンティの思考の範囲をクリアに限定してあげる。\nつまり、うまく問題を分割してあげることが大事\n心理的安全性 心理的安全性とは 下記2つが守られている状況\n 対人リスクを取っても問題ないという信念がチームで共有されている 自分のキャリアやステータス、セルフイメージにネガティブな影響を与える恐れがなく、自分を表現し働くことができる   ★ 対人リスクを積極的に取れる環境が大事なんですね\n メンタリングを行ううえで、メンターとメンティ間の心理的安全性はとても重要。\n心理的安全性が高まるとどうなるのか 心理的安全性を高めると次のような影響がチームに現れる。\n 率直に話すようになる 考えが明晰になる 意義ある対立が後押しされる 失敗が緩和される  失敗の報告がしやすくなる   イノベーションが促される  今までの前提にとらわれず、創造的な意見が出る   組織内の障害でなく目標に集中できるようになる  組織内の理不尽を気にする必要がなくなる   責任感が向上する  心理的安全性と責任 メンタリングにおいて重要なのは ラーニングゾーン である。\nラーニングゾーンとは、対人リスクを取りつつ、発展的議論ができる状況。\nメンターはメンティをラーニングゾーンに導くことが大事。\n自己主張と同調圧力 アメリカでは、初頭教育から自己主張をしっかりすることが推奨されており、\n自分の考えをしっかりと話す週間が身についている。\n一方で、日本はできる限り周囲と同調しようとする。\nつまり、同調圧力が強い民族である。\n同調圧力の強いグループでは、意見が対立することを「仲が悪い」と捉えがちである。\nこのような雰囲気が蔓延すると、心理的安全性を脅かさないために意見を殺してしまう。\nこのような状況は生産性が下がってしまう原因になりがちなので改善が必要である。\n ★ 日本人には同調圧力がしみついてしまっているから、この雰囲気を取り除くのはとても難しそう\n メンタリングにおける心理的安全性 メンターとメンティは心理的安全性が高い、\nつまり対人リスクを積極的に取れる関係性であることが望ましい。\nしたがって、メンタリングを効果的にするために下記のことを実施する。\n メンティの弱さ、メンティの失敗を開示してもらう メンターの弱さ、メンターの失敗を開示する  メンターは完璧な人間じゃなくてよい。\n「こういう失敗をしたけど、そこからこういうことを学び、こうしたらうまくいって成長できた」\nという姿を見せればよい。\nこのような見せ方（伝え方）を ストーリーテリング という。\nアクノレッジメント（承認） メンターはメンティを「承認」してあげることが大事。\n承認とは、メンティがした行動に対して、理解し、受け入れ、感謝を伝えることであり、\n褒めることではない。\nアクノレッジメントの種類  存在承認  相手の存在を承認する（例：あいさつ や 頑張っている様子を見て、肩を叩いて励ます など） 傾聴も相手の存在を承認するひとつの方法   行動承認  行動に対して承認する（例：「結論から話すようになった」と言う）   結果承認  「褒める」に近いが、より広い範囲で承認を捉えて伝える（例：「〜〜はすごい成果だね」と言う）    つまり、あいさつや無視しない、感謝を伝えるなどといった当たり前のことしかない。\n当たり前をきちんとしようという話。\n結果が出ないと承認できない？ 「結果が出ないと承認できない」というのは間違いである。\n結果よりも行動、行動だけでなく存在への承認が重要。\nストーリーテリング ストーリーテリングの定義を明文化すると、メンターからメンティに対しての自己開示と表現できる。\nストーリーテリングで重要なのは、メンティに「メンターも自分と同じ人間である」という理解を獲得すること。\nストーリーテリングの注意点 過去の自慢話にならないようにする。\nそのために、以下のことをしっかりとやる。\n 包み隠さず事実を伝える その時の感情を伝える 伝えたい価値観を明確にする 返報性の原理を利用する  返報性原理：相手になにか施してもらったら、それに対して自分も何かお返しをしたくなる心理 メンターは自己開示することで、メンティが自己開示したくなるようにする     ★ 自己開示って自慢話（武勇伝）になりがちだから気をつけないと\n 「Youメッセージ」と「Iメッセージ」 Youメッセージとは、主語が「あなた」のメッセージ。\nIメッセージとは、主語が「わたし」のメッセージ。\nYouメッセージは相手に誤解を生みやすいメッセージである。\n例えば、「なぜ（あなたは）遅れたの？」と伝えたときに、\n限外に「なぜ説明もなく遅れたの？」と責めるようなニュアンスが生まれてしまう。\nこれをIメッセージに変えると、「連絡がなかったから、（わたしは）心配したよ」となり、\n責めるニュアンスは減り、存在を承認している。\nジョハリの窓 成長とは開放の窓を広げる（つまり、未知の窓=自分に出会う）こと。\nメンティはフィードバックを受けることで、\n盲点の窓（自分が分かっていないこと）を開放の窓（自分が分かっていること）に変えることが可能。\nさらに、メンティの自己開示により秘密の窓（自分だけが分かっていること）を\n盲点の窓（自分も他人も分かっていること）にに変えることが可能。\nメンターは「ストーリーテリング」や「アクノレッジメント」、\n「傾聴」、「リフレーミング」により、メンティがフィードバックを受けやすく、\n自己開示された状態へと導く。\n内心は見えないが、行動は見える メンタリングの最終工程は「これからどうするか」である。\nそのときに注意すべきは、内心的な要素を介入させないことである。\n他人の内心は絶対に見えないので、内心からその人が次の目標に向けたアクションを\nちゃんと起こせているかなんてことは絶対に判断できない。\n大事なのは次の目標に向けて 行動を起こせているか である。\nしたがって、メンターは 次の行動を促す ような指導をしなければいけない。\n ★ 内心は見えない。まさにそのとおり。でも、現代にはまだまだ根性論とか存在しますよね。気をつけないと。\n SMARTな行動 「これからどうするか」について、メンターとメンティの認識を合わせる必要がある。\nこのとき注意すべきなのが、\n「自分の言葉は自分の思ったように相手に伝わっているはず」と思わないことである。\n絶対に正しく伝わらない。\nメンターとメンティ間で認識の差異を生まないためには、SMART原則 を意識するとよい。\n Specific（具体的な）：抽象的な表現は使わない Measureable（測定可能な）：次の行動が行われたかどうか、どのように確認するか決める Achievable（到達可能な）：達成可能な目標だけを設定する Related（関連した）：メンティの課題と目標行動の関係性をメンティ自身が説明できるようにする Time-Bound（時間制限のある）：期限を定める  能力と習慣をコントロールする 人の成長は上図のように「行動・習慣・能力・成果」の4つの事柄のループである。\nこの4つの要素のうち基本的にコントロールできるのは「行動と習慣」のみである。\nしたがって、メンタリングでは行動と習慣の成長を促す。\n ★ 行動が習慣化するところまで見てあげることが大事なんですね\n 成長は行動変化の先にある 結局のところ成長は行動しないと起き得ない。\nでは、なぜ行動できないのか。\nそれは「行動を促進する力」より「行動を阻害する力」が勝っているからである。\nメンターは行動を促進する力を強めるために下記のような行動を行うべきである。\n フィードバックの機会を増やす 適切に承認する 「行動を阻害する要因」は環境や構造を変えるための行動に変換してあげる  適切な目標を決める  自分の気がつかなかった問題に気がつくようになる 認知の歪みによる感情と問題の癒着を切り離せる 答えではなく、次の一手を生み出す行動が取れるようになる  メンタリングのゴールである上記3点の状態に導くためには、\n適切なゴール設定が必要である。\nゴールを設定することで、認知フレームに変化が起き、見えなかったものが見えてくる。\nただし、闇雲にゴールを決めればよいわけではない。\n後述するゴールのレベルが伴っていないといけない。\nゴールのレベル ゴールには下記のとおりレベルがある。\n レベル0 願望：漠然と思っているレベルのゴール  例：お金持ちだったらなぁ   レベル1 義務：達成しなければならないと誰かに押し付けられたゴール  例：お金持ちにならないといけない   レベル2 欲求：達成したいと自分で思って決めたゴール  例：お金持ちになりたい   レベル3 意思：達成しようと決意をもって決めたゴール  例：お金持ちになるぞ   レベル4 必然：達成しているという確信をもって行動できているゴール  例：お金持ちになっている    はじめは漠然とした夢であっても、レベルが上がっていくとともに\n夢がはっきりとし、次に取るべき行動が明確になってくる。\nレベル3では行動が変わり始める。\nレベル4まで上がってくると、継続的な行動、つまり習慣が変化し始める。\nメンターはレベルを上げる手助けを行う。\nセルフマスタリー ゴールの設定、すなわち、未来の自分を設定し、\n未来の自分から見て自身をメンタリングすることを「セルフマスタリー」という。\nつまり、将来の自分から見て、今の自分に足りないものを見つけ、\nそこを補うように行動することである。\nメンタリングは、このセルフマスタリーを会得することで完結する。\nメンティがセルフマスタリーを会得すれば、もうメンターは必要ない。\n自走可能＝自立可能な人材の誕生である。\n 以下感想\n結局のところ、人が成長するにはその人自身が行動を起こすしかないわけですが、\n「じゃあどうやって行動を促すのか」といったことはあまり考えたことがありませんでした。\n本書は、論理的にどうやって行動を起こせるように導くのか、\nその手法を事細かに説明されており、説得力のある内容でした。\n今回は2章の「メンタリングの技術」だけを読みましたが、\n今後他の章に関してもまとめて記事にしたいと思います。\n","ref":"/tech-blog/blog/engineering_organization_theory_mentoring/"},{"title":"Hello Wolrd","date":"","description":"【一文まとめ】技術ブログはじめます","body":"技術ブログはじめます 不定期で学んだことをアウトプットしていきます。\nサーバサイドのネタを中心に、フロントやインフラ（クラウド）の話も書いていく予定です。\nまさかり大歓迎です。\n自己紹介 19新卒として社会人1年目を始めたエンジニアです。\n学生時代はインターンやアルバイトで\nECサービスやスマホゲームのバックエンドなどを開発していました。\n現在は、フルスタックエンジニア目指して、日々修行中。\n（メインはサーバサイド）\n学んだことをアウトプットする場として\n本ブログを始めました。\n頑張ります\n","ref":"/tech-blog/blog/hello_world/"},{"title":"Contact","date":"","description":"","body":"","ref":"/tech-blog/contact/_index.fr/"}]